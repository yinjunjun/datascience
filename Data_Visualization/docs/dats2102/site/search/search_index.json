{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Home Welcome to Data Visualiztion for Data Science (DATS 2102) Weekly Modules Week 1 - Getting Started Week 2 - Language of Graphs Week 3 - Distributions and Variations Week 4 - Wrangling with Pandas Week 5 - Perception and Principles Week 6 - Comparisons Mid-term - Mid-term Project Week 7 - Text, Labels, and Tables Data Sources Please find useful and recommended data sources from the data sources page","title":"Home"},{"location":"#home","text":"Welcome to Data Visualiztion for Data Science (DATS 2102)","title":"Home"},{"location":"#weekly-modules","text":"Week 1 - Getting Started Week 2 - Language of Graphs Week 3 - Distributions and Variations Week 4 - Wrangling with Pandas Week 5 - Perception and Principles Week 6 - Comparisons Mid-term - Mid-term Project Week 7 - Text, Labels, and Tables","title":"Weekly Modules"},{"location":"#data-sources","text":"Please find useful and recommended data sources from the data sources page","title":"Data Sources"},{"location":"course_modules/","text":"DATS 2102 \u2014 Data Visualization for Data Science Week 1 \u2014 Getting Started Focus: Course introduction, importance of data visualization in data science, and environment setup. Learning Objectives: - Understand visualization\u2019s role in data analysis and communication. - Install Python, Jupyter, and core libraries. - Execute basic code and create markdown cells in Jupyter. - Produce first bar and scatter plots. Datasets: Seaborn penguins , small CSVs (population, GDP). Core Libraries: pandas, matplotlib, seaborn. Lecture Topics: - What is data visualization and why it matters. - Overview of course structure and expectations. - Introduction to JupyterLab workflow. In-Class Activities: Load dataset, inspect data, create bar and scatter plots. Homework: Set up environment, explore CSV, produce two labeled plots with captions. Week 2 \u2014 Language of Graphs Focus: Visual encodings, tidy data principles, grammar of graphics. Learning Objectives: - Identify and apply core visual encodings (position, color, shape, size). - Reshape data into tidy format. - Use seaborn and altair for multi-encoding charts. Datasets: Seaborn tips , Gapminder data. Core Libraries: pandas, seaborn, altair. Lecture Topics: - Mapping data to visual attributes. - Tidy data and why it matters. - Grammar of graphics overview. In-Class Activities: Reshape and plot categorical vs. numerical data. Homework: Create three visualizations using different encoding strategies, with explanations. Week 3 \u2014 Distributions & Variation Focus: Visualizing univariate distributions and variation. Learning Objectives: - Choose appropriate distribution plots. - Understand and apply binning, kernel density estimation, ECDF. Datasets: Flight delay data, iris dataset. Core Libraries: seaborn, matplotlib. Lecture Topics: - When to use histograms vs. KDEs vs. box/violin plots. - Understanding variability and spread. In-Class Activities: Compare multiple distribution plot types. Homework: Explore and visualize distributions in two datasets with narrative. Week 4 \u2014 Wrangling with pandas Focus: Data cleaning, transformation, and preparation for visualization. Learning Objectives: - Select, filter, group, summarize, and reshape data. - Work with datetime and categorical data. Datasets: NYC taxi trips sample, COVID-19 data. Core Libraries: pandas, matplotlib. Lecture Topics: - Data import and export. - Common data wrangling operations. In-Class Activities: Group data by category and visualize aggregates. Homework: Clean a messy dataset and create three informative charts. Week 5 \u2014 Perception & Principles Focus: Visual perception theory and chart design principles. Learning Objectives: - Apply Cleveland\u2013McGill perceptual rankings. - Recognize and fix misleading visualizations. Datasets: Simulated comparison datasets. Core Libraries: seaborn, matplotlib. Lecture Topics: - How humans perceive visual encodings. - Common design pitfalls. In-Class Activities: Redesign poor visualizations. Homework: Select a misleading chart, redesign it, and explain improvements. Week 6 \u2014 Comparisons Focus: Comparing categories, groups, and time series. Learning Objectives: - Create grouped bar charts, dot plots, slope charts. - Use small multiples effectively. Datasets: World Bank indicators. Core Libraries: seaborn, matplotlib, plotly. Lecture Topics: - Designing fair comparisons. - Aligning scales and baselines. In-Class Activities: Build comparison visuals using small multiples. Homework: Compare groups in chosen dataset using 2+ visualization types. Week 7 \u2014 Text, Labels, & Tables Focus: Enhancing visuals with annotations and well-formatted tables. Learning Objectives: - Apply direct labeling and meaningful captions. - Create clear and concise tables. Datasets: Sports statistics. Core Libraries: matplotlib, seaborn, pandas. Lecture Topics: - Annotating charts for storytelling. - Formatting tables for clarity. In-Class Activities: Annotate key data points in charts. Homework: Create a labeled and captioned visual from dataset of choice. Week 8 \u2014 Mapping I Focus: Fundamentals of geographic data visualization. Learning Objectives: - Create choropleth maps and understand coordinate reference systems. - Join spatial and tabular datasets. Datasets: US states shapefile, population data. Core Libraries: geopandas, mapclassify, folium. Lecture Topics: - Spatial joins. - Map classification schemes. In-Class Activities: Produce a choropleth map from joined datasets. Homework: Create thematic map for a real-world topic. Week 9 \u2014 Color & Accessibility Focus: Effective and inclusive color usage in visualization. Learning Objectives: - Choose appropriate color palettes. - Apply accessibility best practices. Datasets: From previous assignments. Core Libraries: seaborn, matplotlib, colorcet. Lecture Topics: - Sequential, diverging, qualitative palettes. - Colorblind-safe schemes. In-Class Activities: Recolor existing charts for better accessibility. Homework: Revise a prior visualization with improved color design. Week 10 \u2014 Relationships & Modeling Focus: Visualizing relationships and model fit. Learning Objectives: - Plot scatterplots with regression lines. - Visualize residuals and model diagnostics. Datasets: Housing prices dataset. Core Libraries: seaborn, statsmodels, matplotlib. Lecture Topics: - Visualizing correlation and causation. - Checking model assumptions visually. In-Class Activities: Fit and visualize a simple regression. Homework: Analyze and visualize a bivariate relationship with commentary. Week 11 \u2014 Uncertainty Focus: Representing uncertainty in data visualizations. Learning Objectives: - Add error bars and confidence intervals. - Visualize sampling variability. Datasets: Polling data. Core Libraries: seaborn, matplotlib. Lecture Topics: - Why uncertainty matters. - Techniques for communicating uncertainty. In-Class Activities: Compare plots with and without uncertainty intervals. Homework: Visualize uncertainty in selected dataset. Week 12 \u2014 Visualization for ML/NLP Focus: Visualizing machine learning and NLP outputs. Learning Objectives: - Plot feature importance, confusion matrices, and ROC curves. - Visualize topic clusters and word clouds. Datasets: IMDB reviews, classification dataset. Core Libraries: scikit-learn, matplotlib, seaborn, wordcloud, bertopic. Lecture Topics: - Visualization in the ML workflow. - Visualizing high-dimensional data. In-Class Activities: Train a small model, visualize predictions. Homework: Create three ML-related visualizations from a chosen dataset. Weeks 13\u201314 \u2014 Final Project Workshops Focus: Final project preparation, peer review, and refinement. Learning Objectives: - Integrate multiple visualization techniques into one narrative. - Polish charts for professional presentation. Datasets: Student-chosen. In-Class Activities: Peer feedback, troubleshooting, improving visuals. Homework: Finalize and submit project with report and reproducible code.","title":"Modules"},{"location":"course_modules/#dats-2102-data-visualization-for-data-science","text":"","title":"DATS 2102 \u2014 Data Visualization for Data Science"},{"location":"course_modules/#week-1-getting-started","text":"Focus: Course introduction, importance of data visualization in data science, and environment setup. Learning Objectives: - Understand visualization\u2019s role in data analysis and communication. - Install Python, Jupyter, and core libraries. - Execute basic code and create markdown cells in Jupyter. - Produce first bar and scatter plots. Datasets: Seaborn penguins , small CSVs (population, GDP). Core Libraries: pandas, matplotlib, seaborn. Lecture Topics: - What is data visualization and why it matters. - Overview of course structure and expectations. - Introduction to JupyterLab workflow. In-Class Activities: Load dataset, inspect data, create bar and scatter plots. Homework: Set up environment, explore CSV, produce two labeled plots with captions.","title":"Week 1 \u2014 Getting Started"},{"location":"course_modules/#week-2-language-of-graphs","text":"Focus: Visual encodings, tidy data principles, grammar of graphics. Learning Objectives: - Identify and apply core visual encodings (position, color, shape, size). - Reshape data into tidy format. - Use seaborn and altair for multi-encoding charts. Datasets: Seaborn tips , Gapminder data. Core Libraries: pandas, seaborn, altair. Lecture Topics: - Mapping data to visual attributes. - Tidy data and why it matters. - Grammar of graphics overview. In-Class Activities: Reshape and plot categorical vs. numerical data. Homework: Create three visualizations using different encoding strategies, with explanations.","title":"Week 2 \u2014 Language of Graphs"},{"location":"course_modules/#week-3-distributions-variation","text":"Focus: Visualizing univariate distributions and variation. Learning Objectives: - Choose appropriate distribution plots. - Understand and apply binning, kernel density estimation, ECDF. Datasets: Flight delay data, iris dataset. Core Libraries: seaborn, matplotlib. Lecture Topics: - When to use histograms vs. KDEs vs. box/violin plots. - Understanding variability and spread. In-Class Activities: Compare multiple distribution plot types. Homework: Explore and visualize distributions in two datasets with narrative.","title":"Week 3 \u2014 Distributions &amp; Variation"},{"location":"course_modules/#week-4-wrangling-with-pandas","text":"Focus: Data cleaning, transformation, and preparation for visualization. Learning Objectives: - Select, filter, group, summarize, and reshape data. - Work with datetime and categorical data. Datasets: NYC taxi trips sample, COVID-19 data. Core Libraries: pandas, matplotlib. Lecture Topics: - Data import and export. - Common data wrangling operations. In-Class Activities: Group data by category and visualize aggregates. Homework: Clean a messy dataset and create three informative charts.","title":"Week 4 \u2014 Wrangling with pandas"},{"location":"course_modules/#week-5-perception-principles","text":"Focus: Visual perception theory and chart design principles. Learning Objectives: - Apply Cleveland\u2013McGill perceptual rankings. - Recognize and fix misleading visualizations. Datasets: Simulated comparison datasets. Core Libraries: seaborn, matplotlib. Lecture Topics: - How humans perceive visual encodings. - Common design pitfalls. In-Class Activities: Redesign poor visualizations. Homework: Select a misleading chart, redesign it, and explain improvements.","title":"Week 5 \u2014 Perception &amp; Principles"},{"location":"course_modules/#week-6-comparisons","text":"Focus: Comparing categories, groups, and time series. Learning Objectives: - Create grouped bar charts, dot plots, slope charts. - Use small multiples effectively. Datasets: World Bank indicators. Core Libraries: seaborn, matplotlib, plotly. Lecture Topics: - Designing fair comparisons. - Aligning scales and baselines. In-Class Activities: Build comparison visuals using small multiples. Homework: Compare groups in chosen dataset using 2+ visualization types.","title":"Week 6 \u2014 Comparisons"},{"location":"course_modules/#week-7-text-labels-tables","text":"Focus: Enhancing visuals with annotations and well-formatted tables. Learning Objectives: - Apply direct labeling and meaningful captions. - Create clear and concise tables. Datasets: Sports statistics. Core Libraries: matplotlib, seaborn, pandas. Lecture Topics: - Annotating charts for storytelling. - Formatting tables for clarity. In-Class Activities: Annotate key data points in charts. Homework: Create a labeled and captioned visual from dataset of choice.","title":"Week 7 \u2014 Text, Labels, &amp; Tables"},{"location":"course_modules/#week-8-mapping-i","text":"Focus: Fundamentals of geographic data visualization. Learning Objectives: - Create choropleth maps and understand coordinate reference systems. - Join spatial and tabular datasets. Datasets: US states shapefile, population data. Core Libraries: geopandas, mapclassify, folium. Lecture Topics: - Spatial joins. - Map classification schemes. In-Class Activities: Produce a choropleth map from joined datasets. Homework: Create thematic map for a real-world topic.","title":"Week 8 \u2014 Mapping I"},{"location":"course_modules/#week-9-color-accessibility","text":"Focus: Effective and inclusive color usage in visualization. Learning Objectives: - Choose appropriate color palettes. - Apply accessibility best practices. Datasets: From previous assignments. Core Libraries: seaborn, matplotlib, colorcet. Lecture Topics: - Sequential, diverging, qualitative palettes. - Colorblind-safe schemes. In-Class Activities: Recolor existing charts for better accessibility. Homework: Revise a prior visualization with improved color design.","title":"Week 9 \u2014 Color &amp; Accessibility"},{"location":"course_modules/#week-10-relationships-modeling","text":"Focus: Visualizing relationships and model fit. Learning Objectives: - Plot scatterplots with regression lines. - Visualize residuals and model diagnostics. Datasets: Housing prices dataset. Core Libraries: seaborn, statsmodels, matplotlib. Lecture Topics: - Visualizing correlation and causation. - Checking model assumptions visually. In-Class Activities: Fit and visualize a simple regression. Homework: Analyze and visualize a bivariate relationship with commentary.","title":"Week 10 \u2014 Relationships &amp; Modeling"},{"location":"course_modules/#week-11-uncertainty","text":"Focus: Representing uncertainty in data visualizations. Learning Objectives: - Add error bars and confidence intervals. - Visualize sampling variability. Datasets: Polling data. Core Libraries: seaborn, matplotlib. Lecture Topics: - Why uncertainty matters. - Techniques for communicating uncertainty. In-Class Activities: Compare plots with and without uncertainty intervals. Homework: Visualize uncertainty in selected dataset.","title":"Week 11 \u2014 Uncertainty"},{"location":"course_modules/#week-12-visualization-for-mlnlp","text":"Focus: Visualizing machine learning and NLP outputs. Learning Objectives: - Plot feature importance, confusion matrices, and ROC curves. - Visualize topic clusters and word clouds. Datasets: IMDB reviews, classification dataset. Core Libraries: scikit-learn, matplotlib, seaborn, wordcloud, bertopic. Lecture Topics: - Visualization in the ML workflow. - Visualizing high-dimensional data. In-Class Activities: Train a small model, visualize predictions. Homework: Create three ML-related visualizations from a chosen dataset.","title":"Week 12 \u2014 Visualization for ML/NLP"},{"location":"course_modules/#weeks-1314-final-project-workshops","text":"Focus: Final project preparation, peer review, and refinement. Learning Objectives: - Integrate multiple visualization techniques into one narrative. - Polish charts for professional presentation. Datasets: Student-chosen. In-Class Activities: Peer feedback, troubleshooting, improving visuals. Homework: Finalize and submit project with report and reproducible code.","title":"Weeks 13\u201314 \u2014 Final Project Workshops"},{"location":"syllabus/","text":"DATS 2102: Data Visualization for Data Science Instructor : Junjun Yin Email : j.yin@gwu.edu Semester : Fall 2025 Dates : 08/25/25 \u2013 12/08/25 Class Time : Tuesday & Thursday Office Hours : (Details in Blackboard) Office Location : 2036 H St NW, Room 309 Course Description This course introduces students to the core principles and practices of data visualization within the context of data science. Students will learn how to collect, process, analyze, and communicate data-driven insights using effective and ethical visualization techniques. Emphasis will be placed on hands-on programming with Python\u2019s visualization ecosystem ( pandas , matplotlib , seaborn , plotly , altair , geopandas ) and applying best practices for clarity, accuracy, and storytelling. The course will cover visualization theory, design principles, and practical skills, including geographic data mapping and visualizing results from machine learning models. By the end of the semester, students will be able to produce high-quality visualizations that effectively communicate data insights to diverse audiences. Course Prerequisites DATS 1001 and STAT 1051/1053/1111/1127, or permission of the instructor. Learning Outcomes As a result of completing this course, students will be able to: 1. Process and tidy real-world data using pandas . 2. Apply visual perception and design principles to create truthful, clear graphics. 3. Visualize univariate, bivariate, and multivariate patterns; compare groups effectively. 4. Map and analyze geographic data using geopandas , contextily , and folium / plotly . 5. Visualize relationships and communicate model context and uncertainty. 6. Build interactive, annotated visuals and simple data stories/dashboards. 7. Apply visualization to ML & NLP tasks (feature importance, confusion matrices/ROC, word clouds, BERTopic topic maps, embedding plots). Course Workload This is a 3-credit course. Students are expected to engage in 2.5 hours of direct instruction and a minimum of 5 hours of independent learning each week, for a combined minimum total of 7.5 hours per week or 112.5 hours over the semester. Required Tools and Texts Tools : Anaconda (or Python 3.10+), JupyterLab, VS Code, Sublime Text, PyCharm, Google Colab, or other tools that support Python programming and visualization. Core Libraries : pandas, numpy, matplotlib, seaborn, altair, plotly, geopandas, mapclassify, contextily, folium, scikit-learn, umap-learn, sentence-transformers, bertopic, wordcloud. Documentation & Guides : - Matplotlib - Seaborn - Plotly - Altair - GeoPandas - Pandas Texts : No required textbook. Recommended: Fundamentals of Data Visualization by Claus O. Wilke (available free online) and Storytelling with Data by Cole Nussbaumer Knaflic. Weekly Topics & Schedule Week Topic Description 1 Getting Started Python setup, Jupyter, pandas basics, first plot with matplotlib. 2 Language of Graphs Encodings, tidy data, seaborn & altair grammar. 3 Distributions & Variation Hist/KDE/violin/ECDF, binning & outliers. 4 Wrangling with pandas select/filter/mutate/groupby/merge, reshape, dates. 5 Perception & Principles Cleveland\u2013McGill, preattentive features, clutter. 6 Comparisons Bars/dots/small multiples, ordering & baselines, log scales. 7 Text, Labels, & Tables Direct labeling, captions, tables. 8 Mapping I Choropleths, CRS, spatial joins, geopandas, mapclassify, folium. 9 Color & Accessibility Sequential/diverging/qualitative palettes, pitfalls. 10 Relationships & Modeling Scatter/line, smoothing, statsmodels, model checks. 11 Uncertainty Error bars, intervals, bootstrap visuals. 12 Visualization for ML/NLP Feature importance, confusion/ROC-PR, word clouds, BERTopic, UMAP embeddings. 13\u201314 Final Project Workshops Scoping, refinement, narrative. Assignments & Grading Assignment Weight Weekly Notebooks & Exercises 40% Mid-Semester Visualization Project 15% Final Project 25% Participation & Peer Feedback 10% Quizzes (2 total) 10% Final Project The final project will synthesize the skills learned throughout the course. Students will: - Propose a project idea by Week 9. - Develop a prototype by Week 13. - Submit the final project by December 8. Requirements: - Multiple well-designed visualizations with an accompanying narrative. - At least one map or ML/NLP visualization. - Accessibility considerations (color choice, labeling, alt text). - A reproducible Jupyter Notebook and any necessary datasets or data sources. Projects will be graded on clarity, creativity, technical proficiency, and adherence to visualization best practices. University Policies Academic Integrity Code Academic integrity is an essential part of the educational process, and all members of the GW community take these matters very seriously. As the instructor of record for this course, my role is to provide clear expectations and uphold them in all assessments. Violations of academic integrity occur when students fail to cite research sources properly, engage in unauthorized collaboration, falsify data, and otherwise violate the Code of Academic Integrity. If you have any questions about whether particular academic practices or resources are permitted, you should ask me for clarification. If you are reported for an academic integrity violation, you should contact Conflict Education and Student Accountability (CESA) to learn more about your rights and options. Consequences can range from failure of assignment to expulsion from the University and may include a transcript notation. More info: students.gwu.edu/code-academic-integrity or cesa@gwu.edu. University policy on observance of religious holidays Students must notify faculty during the first week of the semester, or as early as possible, but no later than three weeks prior to the absence, of their intention to be absent for religious observance. See details at provost.gwu.edu/policies-procedures-and-guidelines . Use of Electronic Course Materials and Class Recordings Students are encouraged to use electronic course materials for private personal use in connection with their academic program of study. These materials should not be shared or used for non-course related purposes unless express permission is granted by the instructor. Academic Support Academic Commons Academic Commons is the central location for academic support resources for GW students. To schedule a peer tutoring session for a variety of courses visit go.gwu.edu/tutoring . Visit academiccommons.gwu.edu for study skills tips, finding help with research, and connecting with other campus resources. For questions email academiccommons@gwu.edu. GW Writing Center GW Writing Center cultivates confident writers in the University community by facilitating collaborative, critical, and inclusive conversations at all stages of the writing process. Working alongside peer mentors, writers develop strategies to write independently in academic and public settings. Appointments can be booked online at gwu.mywconline.com . Disability Support Services (DSS) Any student who may need an accommodation based on the potential impact of a disability should contact Disability Support Services at disabilitysupport.gwu.edu to establish eligibility and coordinate reasonable accommodations. Student Health Center The Student Health Center (SHC) offers medical, counseling/psychological, and psychiatric services to GW students. More information about the SHC is available at healthcenter.gwu.edu . Students experiencing a medical or mental health emergency on campus should contact GW Emergency Services at 202-994-6111, or off campus at 911. GW Campus Emergency Information GW Emergency Services : 202-994-6111 For situation-specific instructions, refer to GW\u2019s Emergency Procedures guide. GW Alert GW Alert is an emergency notification system that sends alerts to the GW community. GW requests students, faculty, and staff maintain current contact information by logging on to alert.gwu.edu . Alerts are sent via email, text, social media, and other means, including the Guardian app. Protective Actions GW prescribes four protective actions that can be issued by university officials depending on the type of emergency. All GW community members are expected to follow directions according to the specified protective action: Shelter, Evacuate, Secure, and Lockdown. Learn more at safety.gwu.edu/gw-standard-emergency-statuses .","title":"Syllabus"},{"location":"syllabus/#dats-2102-data-visualization-for-data-science","text":"Instructor : Junjun Yin Email : j.yin@gwu.edu Semester : Fall 2025 Dates : 08/25/25 \u2013 12/08/25 Class Time : Tuesday & Thursday Office Hours : (Details in Blackboard) Office Location : 2036 H St NW, Room 309","title":"DATS 2102: Data Visualization for Data Science"},{"location":"syllabus/#course-description","text":"This course introduces students to the core principles and practices of data visualization within the context of data science. Students will learn how to collect, process, analyze, and communicate data-driven insights using effective and ethical visualization techniques. Emphasis will be placed on hands-on programming with Python\u2019s visualization ecosystem ( pandas , matplotlib , seaborn , plotly , altair , geopandas ) and applying best practices for clarity, accuracy, and storytelling. The course will cover visualization theory, design principles, and practical skills, including geographic data mapping and visualizing results from machine learning models. By the end of the semester, students will be able to produce high-quality visualizations that effectively communicate data insights to diverse audiences.","title":"Course Description"},{"location":"syllabus/#course-prerequisites","text":"DATS 1001 and STAT 1051/1053/1111/1127, or permission of the instructor.","title":"Course Prerequisites"},{"location":"syllabus/#learning-outcomes","text":"As a result of completing this course, students will be able to: 1. Process and tidy real-world data using pandas . 2. Apply visual perception and design principles to create truthful, clear graphics. 3. Visualize univariate, bivariate, and multivariate patterns; compare groups effectively. 4. Map and analyze geographic data using geopandas , contextily , and folium / plotly . 5. Visualize relationships and communicate model context and uncertainty. 6. Build interactive, annotated visuals and simple data stories/dashboards. 7. Apply visualization to ML & NLP tasks (feature importance, confusion matrices/ROC, word clouds, BERTopic topic maps, embedding plots).","title":"Learning Outcomes"},{"location":"syllabus/#course-workload","text":"This is a 3-credit course. Students are expected to engage in 2.5 hours of direct instruction and a minimum of 5 hours of independent learning each week, for a combined minimum total of 7.5 hours per week or 112.5 hours over the semester.","title":"Course Workload"},{"location":"syllabus/#required-tools-and-texts","text":"Tools : Anaconda (or Python 3.10+), JupyterLab, VS Code, Sublime Text, PyCharm, Google Colab, or other tools that support Python programming and visualization. Core Libraries : pandas, numpy, matplotlib, seaborn, altair, plotly, geopandas, mapclassify, contextily, folium, scikit-learn, umap-learn, sentence-transformers, bertopic, wordcloud. Documentation & Guides : - Matplotlib - Seaborn - Plotly - Altair - GeoPandas - Pandas Texts : No required textbook. Recommended: Fundamentals of Data Visualization by Claus O. Wilke (available free online) and Storytelling with Data by Cole Nussbaumer Knaflic.","title":"Required Tools and Texts"},{"location":"syllabus/#weekly-topics-schedule","text":"Week Topic Description 1 Getting Started Python setup, Jupyter, pandas basics, first plot with matplotlib. 2 Language of Graphs Encodings, tidy data, seaborn & altair grammar. 3 Distributions & Variation Hist/KDE/violin/ECDF, binning & outliers. 4 Wrangling with pandas select/filter/mutate/groupby/merge, reshape, dates. 5 Perception & Principles Cleveland\u2013McGill, preattentive features, clutter. 6 Comparisons Bars/dots/small multiples, ordering & baselines, log scales. 7 Text, Labels, & Tables Direct labeling, captions, tables. 8 Mapping I Choropleths, CRS, spatial joins, geopandas, mapclassify, folium. 9 Color & Accessibility Sequential/diverging/qualitative palettes, pitfalls. 10 Relationships & Modeling Scatter/line, smoothing, statsmodels, model checks. 11 Uncertainty Error bars, intervals, bootstrap visuals. 12 Visualization for ML/NLP Feature importance, confusion/ROC-PR, word clouds, BERTopic, UMAP embeddings. 13\u201314 Final Project Workshops Scoping, refinement, narrative.","title":"Weekly Topics &amp; Schedule"},{"location":"syllabus/#assignments-grading","text":"Assignment Weight Weekly Notebooks & Exercises 40% Mid-Semester Visualization Project 15% Final Project 25% Participation & Peer Feedback 10% Quizzes (2 total) 10%","title":"Assignments &amp; Grading"},{"location":"syllabus/#final-project","text":"The final project will synthesize the skills learned throughout the course. Students will: - Propose a project idea by Week 9. - Develop a prototype by Week 13. - Submit the final project by December 8. Requirements: - Multiple well-designed visualizations with an accompanying narrative. - At least one map or ML/NLP visualization. - Accessibility considerations (color choice, labeling, alt text). - A reproducible Jupyter Notebook and any necessary datasets or data sources. Projects will be graded on clarity, creativity, technical proficiency, and adherence to visualization best practices.","title":"Final Project"},{"location":"syllabus/#university-policies","text":"Academic Integrity Code Academic integrity is an essential part of the educational process, and all members of the GW community take these matters very seriously. As the instructor of record for this course, my role is to provide clear expectations and uphold them in all assessments. Violations of academic integrity occur when students fail to cite research sources properly, engage in unauthorized collaboration, falsify data, and otherwise violate the Code of Academic Integrity. If you have any questions about whether particular academic practices or resources are permitted, you should ask me for clarification. If you are reported for an academic integrity violation, you should contact Conflict Education and Student Accountability (CESA) to learn more about your rights and options. Consequences can range from failure of assignment to expulsion from the University and may include a transcript notation. More info: students.gwu.edu/code-academic-integrity or cesa@gwu.edu. University policy on observance of religious holidays Students must notify faculty during the first week of the semester, or as early as possible, but no later than three weeks prior to the absence, of their intention to be absent for religious observance. See details at provost.gwu.edu/policies-procedures-and-guidelines . Use of Electronic Course Materials and Class Recordings Students are encouraged to use electronic course materials for private personal use in connection with their academic program of study. These materials should not be shared or used for non-course related purposes unless express permission is granted by the instructor.","title":"University Policies"},{"location":"syllabus/#academic-support","text":"Academic Commons Academic Commons is the central location for academic support resources for GW students. To schedule a peer tutoring session for a variety of courses visit go.gwu.edu/tutoring . Visit academiccommons.gwu.edu for study skills tips, finding help with research, and connecting with other campus resources. For questions email academiccommons@gwu.edu. GW Writing Center GW Writing Center cultivates confident writers in the University community by facilitating collaborative, critical, and inclusive conversations at all stages of the writing process. Working alongside peer mentors, writers develop strategies to write independently in academic and public settings. Appointments can be booked online at gwu.mywconline.com . Disability Support Services (DSS) Any student who may need an accommodation based on the potential impact of a disability should contact Disability Support Services at disabilitysupport.gwu.edu to establish eligibility and coordinate reasonable accommodations. Student Health Center The Student Health Center (SHC) offers medical, counseling/psychological, and psychiatric services to GW students. More information about the SHC is available at healthcenter.gwu.edu . Students experiencing a medical or mental health emergency on campus should contact GW Emergency Services at 202-994-6111, or off campus at 911.","title":"Academic Support"},{"location":"syllabus/#gw-campus-emergency-information","text":"GW Emergency Services : 202-994-6111 For situation-specific instructions, refer to GW\u2019s Emergency Procedures guide. GW Alert GW Alert is an emergency notification system that sends alerts to the GW community. GW requests students, faculty, and staff maintain current contact information by logging on to alert.gwu.edu . Alerts are sent via email, text, social media, and other means, including the Guardian app. Protective Actions GW prescribes four protective actions that can be issued by university officials depending on the type of emergency. All GW community members are expected to follow directions according to the specified protective action: Shelter, Evacuate, Secure, and Lockdown. Learn more at safety.gwu.edu/gw-standard-emergency-statuses .","title":"GW Campus Emergency Information"},{"location":"ds/data_sources_module/","text":"Data Sources (Weeks 1\u20134) This module provides a consolidated list of recommended data sources from Weeks 1\u20134. Students are encouraged to explore these datasets for hands-on exercises, projects, and further exploration in data visualization. Week 1 \u2013 Introduction to Data Visualization Gapminder Data : Global socio-economic and health indicators over time. Our World in Data : Extensive datasets on global development, environment, health, and society. Week 2 \u2013 Visual Encodings and Principles FiveThirtyEight Datasets : Curated datasets behind FiveThirtyEight\u2019s data journalism articles. UN Data : Official UN datasets on demographics, economics, and development. Week 3 \u2013 Distributions and Comparisons Iris Dataset (UCI ML Repository) : Classic dataset of flower measurements, widely used for visualization demos. Airline Flight Delay Data (Synthetic Example) : U.S. Bureau of Transportation Statistics flight data, often used for delay analysis. Week 4 \u2013 Data Wrangling and Joins TidyTuesday Datasets : Weekly datasets for data wrangling and visualization practice. U.S. Census Data : Demographic, housing, and economic data from the U.S. Census Bureau. Additional References ColorBrewer 2.0 : Color palette selection tool, including colorblind-friendly options. Real Python: ggplot in Python : Tutorial on the grammar of graphics approach in Python.","title":"Data Sources (Weeks 1\u20134)"},{"location":"ds/data_sources_module/#data-sources-weeks-14","text":"This module provides a consolidated list of recommended data sources from Weeks 1\u20134. Students are encouraged to explore these datasets for hands-on exercises, projects, and further exploration in data visualization.","title":"Data Sources (Weeks 1\u20134)"},{"location":"ds/data_sources_module/#week-1-introduction-to-data-visualization","text":"Gapminder Data : Global socio-economic and health indicators over time. Our World in Data : Extensive datasets on global development, environment, health, and society.","title":"Week 1 \u2013 Introduction to Data Visualization"},{"location":"ds/data_sources_module/#week-2-visual-encodings-and-principles","text":"FiveThirtyEight Datasets : Curated datasets behind FiveThirtyEight\u2019s data journalism articles. UN Data : Official UN datasets on demographics, economics, and development.","title":"Week 2 \u2013 Visual Encodings and Principles"},{"location":"ds/data_sources_module/#week-3-distributions-and-comparisons","text":"Iris Dataset (UCI ML Repository) : Classic dataset of flower measurements, widely used for visualization demos. Airline Flight Delay Data (Synthetic Example) : U.S. Bureau of Transportation Statistics flight data, often used for delay analysis.","title":"Week 3 \u2013 Distributions and Comparisons"},{"location":"ds/data_sources_module/#week-4-data-wrangling-and-joins","text":"TidyTuesday Datasets : Weekly datasets for data wrangling and visualization practice. U.S. Census Data : Demographic, housing, and economic data from the U.S. Census Bureau.","title":"Week 4 \u2013 Data Wrangling and Joins"},{"location":"ds/data_sources_module/#additional-references","text":"ColorBrewer 2.0 : Color palette selection tool, including colorblind-friendly options. Real Python: ggplot in Python : Tutorial on the grammar of graphics approach in Python.","title":"Additional References"},{"location":"weekly/mid_term_project/","text":"Mid-Term Project \u2014 DATS 2102: Data Visualization for Data Science A project assignment for the first half of the course (Weeks 1\u20136). \ud83c\udfaf Objectives By mid-semester, you will: Apply foundational data visualization techniques (Weeks 1\u20136). Demonstrate mastery of: environment setup & reproducible notebooks, tidy data principles & visual encodings, distributions & variation, wrangling with pandas, perception-based design principles, fair and effective comparisons. Produce a mini data story using 2\u20133 datasets. \ud83d\udcd6 Project Description Select a real-world dataset (from provided sources or external datasets of interest). Using the tools and concepts learned in the first six weeks, create a narrative notebook that: Introduces the dataset and research question(s). Cleans, reshapes, and prepares the data for visualization, demonstrating core pandas wrangling: selection/filtering, sorting, grouping + aggregation, joins/merges, and tidy reshaping. Produces at least 6\u20138 visualizations , including: At least one distribution plot (histogram/KDE/boxplot/ECDF). At least one comparison plot (dot plot, slope chart, or small multiples). At least one of your own visualizations revised and improved by reflecting on perception principles , showing how thoughtful design choices enhance clarity and fairness. At least one visualization with clear text/labels/annotations . Applies best practices for choice of color, scales, and labeling . Provides a written narrative explaining insights, choices, and design considerations. \ud83d\udce6 Deliverables Jupyter Notebook with all code, markdown explanations, and charts. Rendered HTML file (via Quarto). A short reflective essay (300\u2013500 words) addressing: What challenges did you face in cleaning/visualizing the data? How did perception/design principles guide your choices? Which visualization best communicates your main insight, and why? \ud83d\udcca Suggested Datasets Seaborn sample datasets Gapminder Our World in Data Open Data DC FiveThirtyEight Data \ud83d\uddd3\ufe0f Timeline Final Submission (October 19): Completed notebook, HTML export, and reflection. \ud83e\uddfe Grading Rubric (20 pts total) Data Wrangling & Preparation (4 pts): Appropriate cleaning, filtering, and reshaping. Variety of Visualizations (5 pts): Includes required chart types; demonstrates range. Application of Principles (4 pts): Perception, scales, baselines, labeling. Narrative & Reflection (4 pts): Clear storyline; thoughtful discussion of design choices. Technical Quality (3 pts): The notebook runs cleanly, is reproducible, and is well-organized. \u2705 Submission Checklist Before submitting, make sure: -","title":"Mid-Term Project \u2014 DATS 2102: Data Visualization for Data Science"},{"location":"weekly/mid_term_project/#mid-term-project-dats-2102-data-visualization-for-data-science","text":"A project assignment for the first half of the course (Weeks 1\u20136).","title":"Mid-Term Project \u2014 DATS 2102: Data Visualization for Data Science"},{"location":"weekly/mid_term_project/#objectives","text":"By mid-semester, you will: Apply foundational data visualization techniques (Weeks 1\u20136). Demonstrate mastery of: environment setup & reproducible notebooks, tidy data principles & visual encodings, distributions & variation, wrangling with pandas, perception-based design principles, fair and effective comparisons. Produce a mini data story using 2\u20133 datasets.","title":"\ud83c\udfaf Objectives"},{"location":"weekly/mid_term_project/#project-description","text":"Select a real-world dataset (from provided sources or external datasets of interest). Using the tools and concepts learned in the first six weeks, create a narrative notebook that: Introduces the dataset and research question(s). Cleans, reshapes, and prepares the data for visualization, demonstrating core pandas wrangling: selection/filtering, sorting, grouping + aggregation, joins/merges, and tidy reshaping. Produces at least 6\u20138 visualizations , including: At least one distribution plot (histogram/KDE/boxplot/ECDF). At least one comparison plot (dot plot, slope chart, or small multiples). At least one of your own visualizations revised and improved by reflecting on perception principles , showing how thoughtful design choices enhance clarity and fairness. At least one visualization with clear text/labels/annotations . Applies best practices for choice of color, scales, and labeling . Provides a written narrative explaining insights, choices, and design considerations.","title":"\ud83d\udcd6 Project Description"},{"location":"weekly/mid_term_project/#deliverables","text":"Jupyter Notebook with all code, markdown explanations, and charts. Rendered HTML file (via Quarto). A short reflective essay (300\u2013500 words) addressing: What challenges did you face in cleaning/visualizing the data? How did perception/design principles guide your choices? Which visualization best communicates your main insight, and why?","title":"\ud83d\udce6 Deliverables"},{"location":"weekly/mid_term_project/#suggested-datasets","text":"Seaborn sample datasets Gapminder Our World in Data Open Data DC FiveThirtyEight Data","title":"\ud83d\udcca Suggested Datasets"},{"location":"weekly/mid_term_project/#timeline","text":"Final Submission (October 19): Completed notebook, HTML export, and reflection.","title":"\ud83d\uddd3\ufe0f Timeline"},{"location":"weekly/mid_term_project/#grading-rubric-20-pts-total","text":"Data Wrangling & Preparation (4 pts): Appropriate cleaning, filtering, and reshaping. Variety of Visualizations (5 pts): Includes required chart types; demonstrates range. Application of Principles (4 pts): Perception, scales, baselines, labeling. Narrative & Reflection (4 pts): Clear storyline; thoughtful discussion of design choices. Technical Quality (3 pts): The notebook runs cleanly, is reproducible, and is well-organized.","title":"\ud83e\uddfe Grading Rubric (20 pts total)"},{"location":"weekly/mid_term_project/#submission-checklist","text":"Before submitting, make sure: -","title":"\u2705 Submission Checklist"},{"location":"weekly/module_week_1_getting_started/","text":"Week 1 \u2014 Getting Started A Quarto/Panel-style module page for DATS 2102, implemented in Python/Jupyter. \ud83d\udcd6 Background & Motivation Data visualization is the bridge between raw data and human understanding. In data science, visualizations are not just decorative \u2014 they are powerful analytical tools that help reveal patterns, outliers, and trends that might remain hidden in tables or statistical summaries. Well-designed visualizations can: Tell compelling, evidence-based stories that influence decision-making. Make complex concepts easier to grasp for diverse audiences. Identify and expose errors or inconsistencies in data during the exploratory stage. Enable collaboration between technical and non-technical stakeholders. Applications span across domains: Public health: Tracking disease spread with interactive dashboards. Climate science: Mapping temperature anomalies over decades. Business analytics: Visualizing customer behavior or sales performance. Machine learning: Understanding model performance through ROC curves, feature importance charts, or clustering visualizations. As data science projects grow in size and complexity, the ability to craft clear, truthful, and impactful visuals becomes as important as building the models themselves. \ud83d\udd0e Learning Objectives Set up a reliable Python environment for data visualization. Navigate Jupyter Notebook/Lab and basic notebook hygiene (headings, code vs. markdown, restart & run all). Load and inspect tabular data with pandas . Produce the first charts with matplotlib and seaborn . \ud83d\udcda Readings & Resources JupyterLab User Guide Python Tutorial Pandas Matplotlib Pyplot Seaborn Tutorials Sample Data Sources for Practice: Seaborn Built-in Datasets Kaggle Datasets FiveThirtyEight Data Our World in Data Open Data DC UCI Machine Learning Repository data.gov GeoPandas Sample Datasets Social Explorer \ud83d\udee0\ufe0f Setup Checklist Install Anaconda or Miniconda. Create/activate environment: bash conda create -n dataviz python=3.12 -y conda activate dataviz Install libraries (CPU-friendly baseline): bash pip install pandas numpy matplotlib seaborn plotly altair geopandas Launch JupyterLab : bash jupyter lab (Optional) IDEs you can use: VS Code, PyCharm, Sublime Text; or run in Google Colab. Troubleshooting If geopandas fails on Windows, try conda install -c conda-forge geopandas . If Jupyter can\u2019t see the env, run: python -m ipykernel install --user --name dataviz --display-name \"Python (dataviz)\" . \ud83e\udded Lecture Outline Session 1 (75 minutes) Course overview & syllabus tour (15 min) Why visualization in data science? (truthfulness, clarity, audience) (15 min) Environment setup: conda + Jupyter walkthrough, troubleshooting (30 min) First dataset in pandas : load CSV \u2192 DataFrame \u2192 quick EDA (15 min) Session 2 (75 minutes) Recap + Q&A on environment setup (10 min) Notebook workflow: cells, markdown, restart & run all, saving (20 min) Basic plotting: matplotlib bar/line; seaborn scatter/histogram (30 min) Guided practice with penguins dataset: scatterplot, pairplot activity (15 min) Sample data 1 ( customers_1000.csv ); Sample data 2 ( life_journey_data.csv ), Sample data 3 ( unemployment-x ) Check out the detailed instructions in a Notebook and download the week1_session2.ipynb \ud83d\udcbb Starter Notebook Snippets Load a tiny dataset ( download the tab-separated file (tsv) version ) import pandas as pd cities = pd.DataFrame({ \"city\": [\"DC\", \"NY\", \"LA\", \"Chicago\", \"Houston\"], \"population\": [712_816, 8_336_817, 3_898_747, 2_746_388, 2_304_580] }) cities.head() First charts (matplotlib \u2192 seaborn) import matplotlib.pyplot as plt import seaborn as sns # Matplotlib bar chart plt.bar(cities[\"city\"], cities[\"population\"]) plt.title(\"Population by City\") plt.xlabel(\"City\"); plt.ylabel(\"Population\") plt.show() # Seaborn bar chart sns.barplot(data=cities, x=\"city\", y=\"population\") plt.title(\"Population by City (Seaborn)\") plt.show() Quick EDA helpers cities.describe(include=\"all\") print(\"Missing values by column:\\n\", cities.isna().sum()) \ud83e\uddea In-Class Activity Using seaborn.load_dataset(\"penguins\") : Make a scatterplot of flipper_length_mm vs body_mass_g colored by species . Add axis labels, a title, and a legend with a better title. Try a seaborn.pairplot to see relationships across multiple variables. Hints penguins = sns.load_dataset(\"penguins\").dropna() ax = sns.scatterplot(data=penguins, x=\"flipper_length_mm\", y=\"body_mass_g\", hue=\"species\") ax.set(title=\"Penguins: Flipper vs Body Mass\", xlabel=\"Flipper length (mm)\", ylabel=\"Body mass (g)\") \ud83c\udfe0 Homework (Due before Week 2) Set up your environment and confirm you can open/run notebooks. Import a CSV of your choice and submit one notebook that includes: A short markdown description of the dataset (source, what, who, when). Top 5 rows, .info() , and .describe() . One bar or histogram plot, and one scatter plot. A brief paragraph reflecting on one insight + one limitation of the data. Export notebook to HTML ( File \u2192 Save and Export Notebook As ) and upload both .ipynb and .html . Rubric (10 pts) Reproducible environment & clean notebook structure (2) Correct loading/inspection & basic EDA (3) Two charts with sensible labels/titles (3) Insight + limitation reflection (2) \ud83e\udde9 Optional Extensions Try the same chart in both matplotlib and seaborn ; note the pros/cons you observe. Install altair (a declarative statistical visualization library for Python, built on top of Vega-Lite, useful for creating interactive charts with minimal code) and create the same scatterplot with tooltips. If you\u2019re comfortable with maps, test your geopandas install ( geopandas.datasets.get_path('naturalearth_lowres') ). \u2705 Submission Checklist This section, for example, lists everything you should verify before submitting your work for Week 1.","title":"Week 1 \u2014 Getting Started"},{"location":"weekly/module_week_1_getting_started/#week-1-getting-started","text":"A Quarto/Panel-style module page for DATS 2102, implemented in Python/Jupyter.","title":"Week 1 \u2014 Getting Started"},{"location":"weekly/module_week_1_getting_started/#background-motivation","text":"Data visualization is the bridge between raw data and human understanding. In data science, visualizations are not just decorative \u2014 they are powerful analytical tools that help reveal patterns, outliers, and trends that might remain hidden in tables or statistical summaries. Well-designed visualizations can: Tell compelling, evidence-based stories that influence decision-making. Make complex concepts easier to grasp for diverse audiences. Identify and expose errors or inconsistencies in data during the exploratory stage. Enable collaboration between technical and non-technical stakeholders. Applications span across domains: Public health: Tracking disease spread with interactive dashboards. Climate science: Mapping temperature anomalies over decades. Business analytics: Visualizing customer behavior or sales performance. Machine learning: Understanding model performance through ROC curves, feature importance charts, or clustering visualizations. As data science projects grow in size and complexity, the ability to craft clear, truthful, and impactful visuals becomes as important as building the models themselves.","title":"\ud83d\udcd6 Background &amp; Motivation"},{"location":"weekly/module_week_1_getting_started/#learning-objectives","text":"Set up a reliable Python environment for data visualization. Navigate Jupyter Notebook/Lab and basic notebook hygiene (headings, code vs. markdown, restart & run all). Load and inspect tabular data with pandas . Produce the first charts with matplotlib and seaborn .","title":"\ud83d\udd0e Learning Objectives"},{"location":"weekly/module_week_1_getting_started/#readings-resources","text":"JupyterLab User Guide Python Tutorial Pandas Matplotlib Pyplot Seaborn Tutorials Sample Data Sources for Practice: Seaborn Built-in Datasets Kaggle Datasets FiveThirtyEight Data Our World in Data Open Data DC UCI Machine Learning Repository data.gov GeoPandas Sample Datasets Social Explorer","title":"\ud83d\udcda Readings &amp; Resources"},{"location":"weekly/module_week_1_getting_started/#setup-checklist","text":"Install Anaconda or Miniconda. Create/activate environment: bash conda create -n dataviz python=3.12 -y conda activate dataviz Install libraries (CPU-friendly baseline): bash pip install pandas numpy matplotlib seaborn plotly altair geopandas Launch JupyterLab : bash jupyter lab (Optional) IDEs you can use: VS Code, PyCharm, Sublime Text; or run in Google Colab. Troubleshooting If geopandas fails on Windows, try conda install -c conda-forge geopandas . If Jupyter can\u2019t see the env, run: python -m ipykernel install --user --name dataviz --display-name \"Python (dataviz)\" .","title":"\ud83d\udee0\ufe0f Setup Checklist"},{"location":"weekly/module_week_1_getting_started/#lecture-outline","text":"","title":"\ud83e\udded Lecture Outline"},{"location":"weekly/module_week_1_getting_started/#session-1-75-minutes","text":"Course overview & syllabus tour (15 min) Why visualization in data science? (truthfulness, clarity, audience) (15 min) Environment setup: conda + Jupyter walkthrough, troubleshooting (30 min) First dataset in pandas : load CSV \u2192 DataFrame \u2192 quick EDA (15 min)","title":"Session 1 (75 minutes)"},{"location":"weekly/module_week_1_getting_started/#session-2-75-minutes","text":"Recap + Q&A on environment setup (10 min) Notebook workflow: cells, markdown, restart & run all, saving (20 min) Basic plotting: matplotlib bar/line; seaborn scatter/histogram (30 min) Guided practice with penguins dataset: scatterplot, pairplot activity (15 min) Sample data 1 ( customers_1000.csv ); Sample data 2 ( life_journey_data.csv ), Sample data 3 ( unemployment-x ) Check out the detailed instructions in a Notebook and download the week1_session2.ipynb","title":"Session 2 (75 minutes)"},{"location":"weekly/module_week_1_getting_started/#starter-notebook-snippets","text":"","title":"\ud83d\udcbb Starter Notebook Snippets"},{"location":"weekly/module_week_1_getting_started/#load-a-tiny-dataset-download-the-tab-separated-file-tsv-version","text":"import pandas as pd cities = pd.DataFrame({ \"city\": [\"DC\", \"NY\", \"LA\", \"Chicago\", \"Houston\"], \"population\": [712_816, 8_336_817, 3_898_747, 2_746_388, 2_304_580] }) cities.head()","title":"Load a tiny dataset (download the tab-separated file (tsv) version)"},{"location":"weekly/module_week_1_getting_started/#first-charts-matplotlib-seaborn","text":"import matplotlib.pyplot as plt import seaborn as sns # Matplotlib bar chart plt.bar(cities[\"city\"], cities[\"population\"]) plt.title(\"Population by City\") plt.xlabel(\"City\"); plt.ylabel(\"Population\") plt.show() # Seaborn bar chart sns.barplot(data=cities, x=\"city\", y=\"population\") plt.title(\"Population by City (Seaborn)\") plt.show()","title":"First charts (matplotlib \u2192 seaborn)"},{"location":"weekly/module_week_1_getting_started/#quick-eda-helpers","text":"cities.describe(include=\"all\") print(\"Missing values by column:\\n\", cities.isna().sum())","title":"Quick EDA helpers"},{"location":"weekly/module_week_1_getting_started/#in-class-activity","text":"Using seaborn.load_dataset(\"penguins\") : Make a scatterplot of flipper_length_mm vs body_mass_g colored by species . Add axis labels, a title, and a legend with a better title. Try a seaborn.pairplot to see relationships across multiple variables. Hints penguins = sns.load_dataset(\"penguins\").dropna() ax = sns.scatterplot(data=penguins, x=\"flipper_length_mm\", y=\"body_mass_g\", hue=\"species\") ax.set(title=\"Penguins: Flipper vs Body Mass\", xlabel=\"Flipper length (mm)\", ylabel=\"Body mass (g)\")","title":"\ud83e\uddea In-Class Activity"},{"location":"weekly/module_week_1_getting_started/#homework-due-before-week-2","text":"Set up your environment and confirm you can open/run notebooks. Import a CSV of your choice and submit one notebook that includes: A short markdown description of the dataset (source, what, who, when). Top 5 rows, .info() , and .describe() . One bar or histogram plot, and one scatter plot. A brief paragraph reflecting on one insight + one limitation of the data. Export notebook to HTML ( File \u2192 Save and Export Notebook As ) and upload both .ipynb and .html . Rubric (10 pts) Reproducible environment & clean notebook structure (2) Correct loading/inspection & basic EDA (3) Two charts with sensible labels/titles (3) Insight + limitation reflection (2)","title":"\ud83c\udfe0 Homework (Due before Week 2)"},{"location":"weekly/module_week_1_getting_started/#optional-extensions","text":"Try the same chart in both matplotlib and seaborn ; note the pros/cons you observe. Install altair (a declarative statistical visualization library for Python, built on top of Vega-Lite, useful for creating interactive charts with minimal code) and create the same scatterplot with tooltips. If you\u2019re comfortable with maps, test your geopandas install ( geopandas.datasets.get_path('naturalearth_lowres') ).","title":"\ud83e\udde9 Optional Extensions"},{"location":"weekly/module_week_1_getting_started/#submission-checklist","text":"This section, for example, lists everything you should verify before submitting your work for Week 1.","title":"\u2705 Submission Checklist"},{"location":"weekly/module_week_2_language_of_graphs/","text":"Week 2 \u2014 Language of Graphs Understanding encodings, tidy data, and the grammar of graphics with Python. This module will deepen your ability to think critically about how information is mapped visually and how choices in data structure affect the clarity of your analysis. \ud83d\udcd6 Background & Motivation The \"language\" of data visualization comes from how we map variables to visual elements: position, shape, color, size, and scale. Mastering these encodings allows you to choose the right chart type and present information clearly. This week also introduces the concept of tidy data, a standard way of structuring datasets to facilitate easier analysis and visualization. Beyond technical correctness, understanding these principles ensures that your work communicates insights effectively. Choosing the right encoding is about audience, purpose, and the kind of story you want your data to tell. For example, using color to differentiate categories can make a chart intuitive, but overusing it can lead to confusion. Similarly, reshaping data into tidy form streamlines your workflow and makes your notebooks reproducible and easier to understand for others. The combined skill set of visual encodings and tidy data practices represents the foundation for nearly every visualization you will create later in the course. \ud83d\udd0e Learning Objectives Identify and apply core visual encodings (position, color, shape, size). Reshape datasets into tidy form for plotting. Create multi-encoding plots using seaborn and Altair\u2019s grammar of graphics. Critically evaluate when and why to use specific encodings. \ud83d\udcda Readings & Resources The Grammar of Graphics (Wilkinson) \u2014 conceptual foundation for how data maps to visuals. Seaborn Categorical Plots \u2014 useful introduction to encoding categorical variables. Altair Tutorials \u2014 practice with grammar of graphics in Python. Tidy Data by Hadley Wickham \u2014 essential reading for organizing datasets. ggplot-style Visualization in Python (Real Python) \u2014 practical tutorial for using ggplot concepts in Python. ColorBrewer2 \u2014 an interactive tool for choosing effective and accessible color schemes. Sample Data Sources for Practice: Seaborn Tips Dataset \u2014 classic dataset for learning encodings. Gapminder Data via Plotly Express \u2014 long-term country-level indicators. Our World in Data \u2014 a wide range of curated datasets. Gapminder \u2014 global development indicators with interactive visualization resources. \ud83d\udee0\ufe0f Setup Checklist Make sure your environment includes: pip install pandas numpy matplotlib seaborn altair plotly First make sure the virtual environment is properly created and activated. Then confirm you can import these libraries in a notebook and render a simple chart before class. \ud83e\udded Lecture Outline Session 1 (75 min \u2014 Theory Focus) Why tidy data matters in visualization workflows (10 min) Core visual encodings: position, shape, color, size, and scale, with conceptual discussion and examples from research/literature (25 min) Grammar of graphics overview: key ideas from Wilkinson and tidy data principles (20 min) Class discussion: When encodings clarify vs. when they clutter (20 min) Session 2 (75 min \u2014 Hands-on Focus) Seaborn\u2019s approach to categorical vs. continuous data with live coding (20 min) Altair grammar of graphics in Python with interactive demos (25 min) Guided exercise: create multiple encodings in one chart, reflect on readability (20 min) Workshop and Q&A: applying tidy reshaping and encodings to provided datasets (10 min) You can refer to the Web page and download the Jupyter Notebook \ud83d\udcbb Notebook Snippets Load example dataset import seaborn as sns import pandas as pd # Load tips dataset tips = sns.load_dataset(\"tips\") tips.head() Seaborn scatterplot with multiple encodings sns.scatterplot( data=tips, x=\"total_bill\", y=\"tip\", hue=\"day\", style=\"time\", size=\"size\", palette=\"deep\", sizes=(20, 200) ) Tidy data example # Pivot from wide to long (tidy) df_wide = pd.DataFrame({ 'name': ['Alice', 'Bob'], 'math': [90, 80], 'english': [85, 78] }) df_tidy = df_wide.melt(id_vars='name', var_name='subject', value_name='score') Altair example import altair as alt alt.Chart(tips).mark_point().encode( x='total_bill', y='tip', color='day', shape='time', size='size' ) \ud83e\uddea In-Class Activity Using the gapminder dataset (via plotly.express.data.gapminder() ), create: A scatterplot of GDP per capita vs. life expectancy. Encode continent as color and year as an animation frame. Discuss: What does each encoding reveal? Which encoding is most effective at showing inequality? How does animation enhance or hinder interpretation? Hints import plotly.express as px gap = px.data.gapminder() px.scatter( gap, x=\"gdpPercap\", y=\"lifeExp\", color=\"continent\", size=\"pop\", hover_name=\"country\", animation_frame=\"year\", log_x=True ) \ud83c\udfe0 Homework (Due next Thursday, Sept 11) Pick one dataset from the sample sources or bring your own. Create three different charts using at least three distinct encodings. For each chart, include: A brief description of what the chart shows. Why did you choose those encodings, and how did they help interpretation? One limitation or challenge in readability. Submit .ipynb and .html to Blackboard (You can zip the files together). Rubric (10 pts) Correct application of tidy data principles (2) Effective and varied use of encodings (4) Chart clarity, proper labeling, and interpretability (2) Justification of choices and discussion of limitations (2) \ud83e\udde9 Optional Extensions Use Altair to add interactive tooltips for deeper exploration. Compare the same visualization in Seaborn and Altair and note trade-offs. Explore plotly.express for creating interactive dashboards. Experiment with using two vs. three encodings in the same chart; evaluate which is clearer. \u2705 Submission Checklist Before submitting, make sure: Your assignment has fulfilled all the basic requirements listed above. The visualizations in the Notebook and HTML are well displayed.","title":"Week 2 \u2014 Language of Graphs"},{"location":"weekly/module_week_2_language_of_graphs/#week-2-language-of-graphs","text":"Understanding encodings, tidy data, and the grammar of graphics with Python. This module will deepen your ability to think critically about how information is mapped visually and how choices in data structure affect the clarity of your analysis.","title":"Week 2 \u2014 Language of Graphs"},{"location":"weekly/module_week_2_language_of_graphs/#background-motivation","text":"The \"language\" of data visualization comes from how we map variables to visual elements: position, shape, color, size, and scale. Mastering these encodings allows you to choose the right chart type and present information clearly. This week also introduces the concept of tidy data, a standard way of structuring datasets to facilitate easier analysis and visualization. Beyond technical correctness, understanding these principles ensures that your work communicates insights effectively. Choosing the right encoding is about audience, purpose, and the kind of story you want your data to tell. For example, using color to differentiate categories can make a chart intuitive, but overusing it can lead to confusion. Similarly, reshaping data into tidy form streamlines your workflow and makes your notebooks reproducible and easier to understand for others. The combined skill set of visual encodings and tidy data practices represents the foundation for nearly every visualization you will create later in the course.","title":"\ud83d\udcd6 Background &amp; Motivation"},{"location":"weekly/module_week_2_language_of_graphs/#learning-objectives","text":"Identify and apply core visual encodings (position, color, shape, size). Reshape datasets into tidy form for plotting. Create multi-encoding plots using seaborn and Altair\u2019s grammar of graphics. Critically evaluate when and why to use specific encodings.","title":"\ud83d\udd0e Learning Objectives"},{"location":"weekly/module_week_2_language_of_graphs/#readings-resources","text":"The Grammar of Graphics (Wilkinson) \u2014 conceptual foundation for how data maps to visuals. Seaborn Categorical Plots \u2014 useful introduction to encoding categorical variables. Altair Tutorials \u2014 practice with grammar of graphics in Python. Tidy Data by Hadley Wickham \u2014 essential reading for organizing datasets. ggplot-style Visualization in Python (Real Python) \u2014 practical tutorial for using ggplot concepts in Python. ColorBrewer2 \u2014 an interactive tool for choosing effective and accessible color schemes. Sample Data Sources for Practice: Seaborn Tips Dataset \u2014 classic dataset for learning encodings. Gapminder Data via Plotly Express \u2014 long-term country-level indicators. Our World in Data \u2014 a wide range of curated datasets. Gapminder \u2014 global development indicators with interactive visualization resources.","title":"\ud83d\udcda Readings &amp; Resources"},{"location":"weekly/module_week_2_language_of_graphs/#setup-checklist","text":"Make sure your environment includes: pip install pandas numpy matplotlib seaborn altair plotly First make sure the virtual environment is properly created and activated. Then confirm you can import these libraries in a notebook and render a simple chart before class.","title":"\ud83d\udee0\ufe0f Setup Checklist"},{"location":"weekly/module_week_2_language_of_graphs/#lecture-outline","text":"","title":"\ud83e\udded Lecture Outline"},{"location":"weekly/module_week_2_language_of_graphs/#session-1-75-min-theory-focus","text":"Why tidy data matters in visualization workflows (10 min) Core visual encodings: position, shape, color, size, and scale, with conceptual discussion and examples from research/literature (25 min) Grammar of graphics overview: key ideas from Wilkinson and tidy data principles (20 min) Class discussion: When encodings clarify vs. when they clutter (20 min)","title":"Session 1 (75 min \u2014 Theory Focus)"},{"location":"weekly/module_week_2_language_of_graphs/#session-2-75-min-hands-on-focus","text":"Seaborn\u2019s approach to categorical vs. continuous data with live coding (20 min) Altair grammar of graphics in Python with interactive demos (25 min) Guided exercise: create multiple encodings in one chart, reflect on readability (20 min) Workshop and Q&A: applying tidy reshaping and encodings to provided datasets (10 min)","title":"Session 2 (75 min \u2014 Hands-on Focus)"},{"location":"weekly/module_week_2_language_of_graphs/#you-can-refer-to-the-web-page-and-download-the-jupyter-notebook","text":"","title":"You can refer to the Web page and download the Jupyter Notebook"},{"location":"weekly/module_week_2_language_of_graphs/#notebook-snippets","text":"","title":"\ud83d\udcbb Notebook Snippets"},{"location":"weekly/module_week_2_language_of_graphs/#load-example-dataset","text":"import seaborn as sns import pandas as pd # Load tips dataset tips = sns.load_dataset(\"tips\") tips.head()","title":"Load example dataset"},{"location":"weekly/module_week_2_language_of_graphs/#seaborn-scatterplot-with-multiple-encodings","text":"sns.scatterplot( data=tips, x=\"total_bill\", y=\"tip\", hue=\"day\", style=\"time\", size=\"size\", palette=\"deep\", sizes=(20, 200) )","title":"Seaborn scatterplot with multiple encodings"},{"location":"weekly/module_week_2_language_of_graphs/#tidy-data-example","text":"# Pivot from wide to long (tidy) df_wide = pd.DataFrame({ 'name': ['Alice', 'Bob'], 'math': [90, 80], 'english': [85, 78] }) df_tidy = df_wide.melt(id_vars='name', var_name='subject', value_name='score')","title":"Tidy data example"},{"location":"weekly/module_week_2_language_of_graphs/#altair-example","text":"import altair as alt alt.Chart(tips).mark_point().encode( x='total_bill', y='tip', color='day', shape='time', size='size' )","title":"Altair example"},{"location":"weekly/module_week_2_language_of_graphs/#in-class-activity","text":"Using the gapminder dataset (via plotly.express.data.gapminder() ), create: A scatterplot of GDP per capita vs. life expectancy. Encode continent as color and year as an animation frame. Discuss: What does each encoding reveal? Which encoding is most effective at showing inequality? How does animation enhance or hinder interpretation? Hints import plotly.express as px gap = px.data.gapminder() px.scatter( gap, x=\"gdpPercap\", y=\"lifeExp\", color=\"continent\", size=\"pop\", hover_name=\"country\", animation_frame=\"year\", log_x=True )","title":"\ud83e\uddea In-Class Activity"},{"location":"weekly/module_week_2_language_of_graphs/#homework-due-next-thursday-sept-11","text":"Pick one dataset from the sample sources or bring your own. Create three different charts using at least three distinct encodings. For each chart, include: A brief description of what the chart shows. Why did you choose those encodings, and how did they help interpretation? One limitation or challenge in readability. Submit .ipynb and .html to Blackboard (You can zip the files together). Rubric (10 pts) Correct application of tidy data principles (2) Effective and varied use of encodings (4) Chart clarity, proper labeling, and interpretability (2) Justification of choices and discussion of limitations (2)","title":"\ud83c\udfe0 Homework (Due next Thursday, Sept 11)"},{"location":"weekly/module_week_2_language_of_graphs/#optional-extensions","text":"Use Altair to add interactive tooltips for deeper exploration. Compare the same visualization in Seaborn and Altair and note trade-offs. Explore plotly.express for creating interactive dashboards. Experiment with using two vs. three encodings in the same chart; evaluate which is clearer.","title":"\ud83e\udde9 Optional Extensions"},{"location":"weekly/module_week_2_language_of_graphs/#submission-checklist","text":"Before submitting, make sure: Your assignment has fulfilled all the basic requirements listed above. The visualizations in the Notebook and HTML are well displayed.","title":"\u2705 Submission Checklist"},{"location":"weekly/module_week_3_distributions_variation/","text":"Week 3 \u2014 Distributions & Variation Exploring distributions, variation, and choices in single-variable visualization. \ud83d\udcd6 Background & Motivation Understanding how data is distributed is the foundation of exploratory data analysis. Whether we want to know if flight delays cluster around certain times or if iris flower species differ in petal length, distribution plots reveal the shape, spread, and potential outliers. Poorly chosen or misinterpreted plots can obscure variation and mislead conclusions. Distributions are more than just \u201cshapes of data\u201d. They tell us about central tendency (where the bulk of data lies), spread (how much variation exists), skewness (whether data is lopsided), and outliers (values that are unusual or extreme). These insights form the basis for both descriptive statistics and inferential modeling. For data scientists, knowing how to visualize distributions effectively is an essential skill for diagnosing problems, preparing data, and communicating results. \ud83d\udd0e Learning Objectives Choose and interpret appropriate distribution plots. Apply binning strategies and kernel density estimation. Construct and read empirical cumulative distribution functions (ECDFs). Compare plots to understand spread, skewness, and outliers. Critically evaluate the strengths and weaknesses of each distribution visualization technique. \ud83d\udcda Readings & Resources Seaborn Distribution Plots \u2014 practical guide to histograms, KDEs, and more. Matplotlib Histograms \u2014 documentation for histogram basics. EDA Concepts \u2014 blog overview of exploratory data analysis. Fundamentals of Data Visualization \u2014 chapter on histograms and density plots. Sample Data Sources: Flight delay data (US DOT Bureau of Transportation Statistics) Iris dataset ( seaborn.load_dataset('iris') ) Titanic dataset (Kaggle / Seaborn) COVID-19 case data (Our World in Data) \ud83d\udee0\ufe0f Setup Checklist Ensure you can run: pip install seaborn matplotlib pandas Check that you can load the iris dataset and render a histogram before class. \ud83e\udded Lecture Outline Session 1 (75 min) Motivation: Why study distributions? Examples from real-world datasets (10 min) Histograms & binning choices: impact of bin width on interpretation (20 min) Kernel density estimation: intuition, bandwidth selection, pros/cons (25 min) Hands-on with iris dataset: plot histograms and KDEs for sepal/petal features (20 min) Session 2 (75 min) Recap & troubleshooting from Session 1 (10 min) Boxplots & violin plots: comparing categories and visualizing spread (25 min) ECDF: cumulative view of distributions, why it\u2019s useful (20 min) Workshop: students choose dataset, produce 2\u20133 distribution plots, peer feedback (20 min) You can refer to the Jupyter Notebook template \ud83d\udcbb Starter Notebook Snippets import seaborn as sns import matplotlib.pyplot as plt iris = sns.load_dataset('iris') # Histogram sns.histplot(iris['sepal_length'], bins=20, kde=False) # KDE sns.kdeplot(iris['sepal_length'], fill=True) # Boxplot by species sns.boxplot(data=iris, x='species', y='sepal_length') # ECDF def ecdf(data): x = np.sort(data) y = np.arange(1, len(x)+1) / len(x) return x, y import numpy as np x, y = ecdf(iris['sepal_length']) plt.plot(x, y, marker='.', linestyle='none') plt.xlabel('Sepal length') plt.ylabel('ECDF') \ud83e\uddea In-Class Activity Compare histogram vs. KDE of flight delay data. Which communicates central tendency more clearly? Which better shows multimodality? Plot boxplot of iris petal length by species. Discuss: how does this compare to histograms? Construct ECDFs for sepal width. What does it reveal about spread and skewness? Group work: each team selects a dataset and produces multiple distribution plots, then explains which is most effective. \ud83c\udfe0 Homework (Due next Thursday, Sept 18) Select two datasets (one provided + one of your choice). For each dataset: Produce at least 3 distribution plots (histogram, KDE, ECDF, box/violin). Interpret shape, spread, skew, and outliers in markdown. Reflect on the pros/cons of each visualization type. Add at least one annotated chart highlighting a key pattern. Submit .ipynb and .html as a zip file. Rubric (10 pts) Correct use of multiple plot types (4) Clear interpretation and discussion (3) Labeling, annotations, and readability (2) Reproducibility (1) \ud83e\udde9 Optional Extensions Experiment with different bin sizes in histograms and compare results. Overlay histogram and KDE to show complementarity. Use sns.pairplot to examine multiple distributions and correlations. Compare distributions across groups using facet plots. Try violin plots with split by category. \u2705 Submission Checklist Before submitting, make sure: Your assignment has fulfilled all the basic requirements listed above. The visualizations in the Notebook and HTML are well displayed.","title":"Week 3 \u2014 Distributions &amp; Variation"},{"location":"weekly/module_week_3_distributions_variation/#week-3-distributions-variation","text":"Exploring distributions, variation, and choices in single-variable visualization.","title":"Week 3 \u2014 Distributions &amp; Variation"},{"location":"weekly/module_week_3_distributions_variation/#background-motivation","text":"Understanding how data is distributed is the foundation of exploratory data analysis. Whether we want to know if flight delays cluster around certain times or if iris flower species differ in petal length, distribution plots reveal the shape, spread, and potential outliers. Poorly chosen or misinterpreted plots can obscure variation and mislead conclusions. Distributions are more than just \u201cshapes of data\u201d. They tell us about central tendency (where the bulk of data lies), spread (how much variation exists), skewness (whether data is lopsided), and outliers (values that are unusual or extreme). These insights form the basis for both descriptive statistics and inferential modeling. For data scientists, knowing how to visualize distributions effectively is an essential skill for diagnosing problems, preparing data, and communicating results.","title":"\ud83d\udcd6 Background &amp; Motivation"},{"location":"weekly/module_week_3_distributions_variation/#learning-objectives","text":"Choose and interpret appropriate distribution plots. Apply binning strategies and kernel density estimation. Construct and read empirical cumulative distribution functions (ECDFs). Compare plots to understand spread, skewness, and outliers. Critically evaluate the strengths and weaknesses of each distribution visualization technique.","title":"\ud83d\udd0e Learning Objectives"},{"location":"weekly/module_week_3_distributions_variation/#readings-resources","text":"Seaborn Distribution Plots \u2014 practical guide to histograms, KDEs, and more. Matplotlib Histograms \u2014 documentation for histogram basics. EDA Concepts \u2014 blog overview of exploratory data analysis. Fundamentals of Data Visualization \u2014 chapter on histograms and density plots. Sample Data Sources: Flight delay data (US DOT Bureau of Transportation Statistics) Iris dataset ( seaborn.load_dataset('iris') ) Titanic dataset (Kaggle / Seaborn) COVID-19 case data (Our World in Data)","title":"\ud83d\udcda Readings &amp; Resources"},{"location":"weekly/module_week_3_distributions_variation/#setup-checklist","text":"Ensure you can run: pip install seaborn matplotlib pandas Check that you can load the iris dataset and render a histogram before class.","title":"\ud83d\udee0\ufe0f Setup Checklist"},{"location":"weekly/module_week_3_distributions_variation/#lecture-outline","text":"","title":"\ud83e\udded Lecture Outline"},{"location":"weekly/module_week_3_distributions_variation/#session-1-75-min","text":"Motivation: Why study distributions? Examples from real-world datasets (10 min) Histograms & binning choices: impact of bin width on interpretation (20 min) Kernel density estimation: intuition, bandwidth selection, pros/cons (25 min) Hands-on with iris dataset: plot histograms and KDEs for sepal/petal features (20 min)","title":"Session 1 (75 min)"},{"location":"weekly/module_week_3_distributions_variation/#session-2-75-min","text":"Recap & troubleshooting from Session 1 (10 min) Boxplots & violin plots: comparing categories and visualizing spread (25 min) ECDF: cumulative view of distributions, why it\u2019s useful (20 min) Workshop: students choose dataset, produce 2\u20133 distribution plots, peer feedback (20 min)","title":"Session 2 (75 min)"},{"location":"weekly/module_week_3_distributions_variation/#you-can-refer-to-the-jupyter-notebook-template","text":"","title":"You can refer to the Jupyter Notebook template"},{"location":"weekly/module_week_3_distributions_variation/#starter-notebook-snippets","text":"import seaborn as sns import matplotlib.pyplot as plt iris = sns.load_dataset('iris') # Histogram sns.histplot(iris['sepal_length'], bins=20, kde=False) # KDE sns.kdeplot(iris['sepal_length'], fill=True) # Boxplot by species sns.boxplot(data=iris, x='species', y='sepal_length') # ECDF def ecdf(data): x = np.sort(data) y = np.arange(1, len(x)+1) / len(x) return x, y import numpy as np x, y = ecdf(iris['sepal_length']) plt.plot(x, y, marker='.', linestyle='none') plt.xlabel('Sepal length') plt.ylabel('ECDF')","title":"\ud83d\udcbb Starter Notebook Snippets"},{"location":"weekly/module_week_3_distributions_variation/#in-class-activity","text":"Compare histogram vs. KDE of flight delay data. Which communicates central tendency more clearly? Which better shows multimodality? Plot boxplot of iris petal length by species. Discuss: how does this compare to histograms? Construct ECDFs for sepal width. What does it reveal about spread and skewness? Group work: each team selects a dataset and produces multiple distribution plots, then explains which is most effective.","title":"\ud83e\uddea In-Class Activity"},{"location":"weekly/module_week_3_distributions_variation/#homework-due-next-thursday-sept-18","text":"Select two datasets (one provided + one of your choice). For each dataset: Produce at least 3 distribution plots (histogram, KDE, ECDF, box/violin). Interpret shape, spread, skew, and outliers in markdown. Reflect on the pros/cons of each visualization type. Add at least one annotated chart highlighting a key pattern. Submit .ipynb and .html as a zip file. Rubric (10 pts) Correct use of multiple plot types (4) Clear interpretation and discussion (3) Labeling, annotations, and readability (2) Reproducibility (1)","title":"\ud83c\udfe0 Homework (Due next Thursday, Sept 18)"},{"location":"weekly/module_week_3_distributions_variation/#optional-extensions","text":"Experiment with different bin sizes in histograms and compare results. Overlay histogram and KDE to show complementarity. Use sns.pairplot to examine multiple distributions and correlations. Compare distributions across groups using facet plots. Try violin plots with split by category.","title":"\ud83e\udde9 Optional Extensions"},{"location":"weekly/module_week_3_distributions_variation/#submission-checklist","text":"Before submitting, make sure: Your assignment has fulfilled all the basic requirements listed above. The visualizations in the Notebook and HTML are well displayed.","title":"\u2705 Submission Checklist"},{"location":"weekly/module_week_4_wrangling_with_pandas/","text":"Week 4 \u2014 Wrangling with pandas Learning how to clean, transform, and prepare data for effective visualization. \ud83d\udcd6 Background & Motivation Data visualization is only as good as the data behind it. Most real-world datasets are messy, requiring cleaning and transformation before they can be meaningfully visualized. Pandas is the cornerstone Python library for data wrangling, providing flexible tools to reshape, aggregate, and join datasets. This week introduces practical techniques for preparing data that will allow you to build more accurate and insightful visualizations. \ud83d\udd0e Learning Objectives Select, filter, group, summarize, and reshape data in pandas. Work with datetime and categorical data types. Join and merge datasets for richer analysis. Prepare clean datasets ready for visualization. \ud83d\udcda Readings & Resources Pandas User Guide 10 Minutes to pandas Working with Text Data Time Series / Date Functionality Sample Data Sources: NYC Taxi trips sample (NYC Open Data) COVID-19 data (Johns Hopkins University) \ud83d\udee0\ufe0f Setup Checklist Ensure you can run: pip install pandas matplotlib seaborn \ud83e\udded Lecture Outline Session 1 (75 min \u2014 Theory Focus) Introduction to pandas DataFrames & Series (15 min) Selection and filtering operations (20 min) GroupBy and aggregation (20 min) Intro to joining and merging: concepts and syntax (15 min) Hands-on with NYC Taxi dataset (20 min). Download the files from here Session 2 (75 min - Hands-On) Recap & troubleshooting (10 min) Reshaping data: pivot, melt, stack/unstack (25 min) Working with datetime and categorical variables (20 min) Merging and joining multiple datasets (20 min) Download the Jupyter Notebook and the additional population table for the session. Download the complete Jupyter Notebook . Remember to have other files ready for the notebook. \ud83d\udcbb Starter Notebook Snippets import pandas as pd # Load dataset trips = pd.read_csv(\"nyc_taxi_sample.csv\") # Filter rows filtered = trips[trips[\"passenger_count\"] > 2] # Group and aggregate agg = trips.groupby(\"passenger_count\")[\"fare_amount\"].mean() # Reshape with melt df_wide = pd.DataFrame({ 'id': [1, 2], 'math': [90, 80], 'english': [85, 78] }) df_tidy = df_wide.melt(id_vars='id', var_name='subject', value_name='score') # Parse dates trips['pickup_datetime'] = pd.to_datetime(trips['pickup_datetime']) \ud83e\uddea In-Class Activity Use the COVID-19 dataset to: Filter by one country and visualize new cases over time. Group data by month and compare monthly averages. Reshape the dataset to tidy form and create a plot. \ud83c\udfe0 Homework (Due next Thursday, Sept 25) Select a dataset with at least 5 columns. Perform the following in a notebook: Clean and filter the dataset. Apply at least 2 groupby operations with aggregations. Reshape the dataset at least once (pivot, melt, etc.). Create 3 visualizations from the cleaned dataset. Submit .ipynb and .html . Rubric (10 pts) Correct wrangling operations applied (4) Creativity in reshaping & grouping (2) Clear and readable plots (2) Reproducibility (2) \ud83e\udde9 Optional Extensions Merge two datasets to add richer context. Explore pandas string operations to clean messy text. Create a time series plot with rolling averages. \u2705 Submission Checklist Before submitting, make sure: Your assignment has fulfilled all the basic requirements listed above. The operations and visualizations in the Jupyter notebook are correct. Use Quarto to render the notebook and ensure the content is displayed well.","title":"Week 4 \u2014 Wrangling with pandas"},{"location":"weekly/module_week_4_wrangling_with_pandas/#week-4-wrangling-with-pandas","text":"Learning how to clean, transform, and prepare data for effective visualization.","title":"Week 4 \u2014 Wrangling with pandas"},{"location":"weekly/module_week_4_wrangling_with_pandas/#background-motivation","text":"Data visualization is only as good as the data behind it. Most real-world datasets are messy, requiring cleaning and transformation before they can be meaningfully visualized. Pandas is the cornerstone Python library for data wrangling, providing flexible tools to reshape, aggregate, and join datasets. This week introduces practical techniques for preparing data that will allow you to build more accurate and insightful visualizations.","title":"\ud83d\udcd6 Background &amp; Motivation"},{"location":"weekly/module_week_4_wrangling_with_pandas/#learning-objectives","text":"Select, filter, group, summarize, and reshape data in pandas. Work with datetime and categorical data types. Join and merge datasets for richer analysis. Prepare clean datasets ready for visualization.","title":"\ud83d\udd0e Learning Objectives"},{"location":"weekly/module_week_4_wrangling_with_pandas/#readings-resources","text":"Pandas User Guide 10 Minutes to pandas Working with Text Data Time Series / Date Functionality Sample Data Sources: NYC Taxi trips sample (NYC Open Data) COVID-19 data (Johns Hopkins University)","title":"\ud83d\udcda Readings &amp; Resources"},{"location":"weekly/module_week_4_wrangling_with_pandas/#setup-checklist","text":"Ensure you can run: pip install pandas matplotlib seaborn","title":"\ud83d\udee0\ufe0f Setup Checklist"},{"location":"weekly/module_week_4_wrangling_with_pandas/#lecture-outline","text":"","title":"\ud83e\udded Lecture Outline"},{"location":"weekly/module_week_4_wrangling_with_pandas/#session-1-75-min-theory-focus","text":"Introduction to pandas DataFrames & Series (15 min) Selection and filtering operations (20 min) GroupBy and aggregation (20 min) Intro to joining and merging: concepts and syntax (15 min) Hands-on with NYC Taxi dataset (20 min). Download the files from here","title":"Session 1 (75 min \u2014 Theory Focus)"},{"location":"weekly/module_week_4_wrangling_with_pandas/#session-2-75-min-hands-on","text":"Recap & troubleshooting (10 min) Reshaping data: pivot, melt, stack/unstack (25 min) Working with datetime and categorical variables (20 min) Merging and joining multiple datasets (20 min) Download the Jupyter Notebook and the additional population table for the session. Download the complete Jupyter Notebook . Remember to have other files ready for the notebook.","title":"Session 2 (75 min - Hands-On)"},{"location":"weekly/module_week_4_wrangling_with_pandas/#starter-notebook-snippets","text":"import pandas as pd # Load dataset trips = pd.read_csv(\"nyc_taxi_sample.csv\") # Filter rows filtered = trips[trips[\"passenger_count\"] > 2] # Group and aggregate agg = trips.groupby(\"passenger_count\")[\"fare_amount\"].mean() # Reshape with melt df_wide = pd.DataFrame({ 'id': [1, 2], 'math': [90, 80], 'english': [85, 78] }) df_tidy = df_wide.melt(id_vars='id', var_name='subject', value_name='score') # Parse dates trips['pickup_datetime'] = pd.to_datetime(trips['pickup_datetime'])","title":"\ud83d\udcbb Starter Notebook Snippets"},{"location":"weekly/module_week_4_wrangling_with_pandas/#in-class-activity","text":"Use the COVID-19 dataset to: Filter by one country and visualize new cases over time. Group data by month and compare monthly averages. Reshape the dataset to tidy form and create a plot.","title":"\ud83e\uddea In-Class Activity"},{"location":"weekly/module_week_4_wrangling_with_pandas/#homework-due-next-thursday-sept-25","text":"Select a dataset with at least 5 columns. Perform the following in a notebook: Clean and filter the dataset. Apply at least 2 groupby operations with aggregations. Reshape the dataset at least once (pivot, melt, etc.). Create 3 visualizations from the cleaned dataset. Submit .ipynb and .html . Rubric (10 pts) Correct wrangling operations applied (4) Creativity in reshaping & grouping (2) Clear and readable plots (2) Reproducibility (2)","title":"\ud83c\udfe0 Homework (Due next Thursday, Sept 25)"},{"location":"weekly/module_week_4_wrangling_with_pandas/#optional-extensions","text":"Merge two datasets to add richer context. Explore pandas string operations to clean messy text. Create a time series plot with rolling averages.","title":"\ud83e\udde9 Optional Extensions"},{"location":"weekly/module_week_4_wrangling_with_pandas/#submission-checklist","text":"Before submitting, make sure: Your assignment has fulfilled all the basic requirements listed above. The operations and visualizations in the Jupyter notebook are correct. Use Quarto to render the notebook and ensure the content is displayed well.","title":"\u2705 Submission Checklist"},{"location":"weekly/module_week_5_perception_principles/","text":"Week 5 \u2014 Perception & Principles Applying visual perception theory and design principles to create effective, truthful, and clear visualizations. \ud83d\udcd6 Background & Motivation Even when the data is clean and the chart type is appropriate, design decisions can make the difference between clarity and confusion. Human perception imposes limits on how well we can decode visual information. By understanding principles from perceptual psychology, we can design graphics that communicate more effectively and avoid misleading audiences. This week introduces concepts like Cleveland & McGill\u2019s hierarchy of graphical perception, preattentive attributes, Gestalt principles, and common pitfalls in chart design. These theoretical foundations provide guidance for making practical design decisions in your visualizations. \ud83d\udd0e Learning Objectives Understand how human perception shapes data interpretation. Apply the Cleveland\u2013McGill perceptual rankings to select more effective encodings. Identify and use preattentive features to guide viewer attention. Recognize and correct misleading design practices. \ud83d\udcda Readings & Resources Cleveland & McGill (1984): Graphical Perception Fundamentals of Data Visualization \u2014 Chapters on perception and design. Data Visualization Society: Design Principles The Gestalt Principles Sample Data Sources: Simulated datasets designed to illustrate perception issues. Any dataset from previous weeks (for redesign exercises). \ud83d\udee0\ufe0f Setup Checklist Ensure your environment includes: pip install seaborn matplotlib pandas \ud83e\udded Lecture Outline Session 1 (75 min \u2014 Theory Focus) Motivation: Why perception matters in visualization (10 min) Cleveland\u2013McGill hierarchy of graphical perception (20 min) Preattentive attributes (color, shape, position, orientation) (20 min) Gestalt principles and visual grouping (15 min) Misleading charts and design pitfalls (10 min) Session 2 (75 min \u2014 Hands-on Focus) Recap & discussion of theory (10 min) Redesign bad charts into effective versions (30 min) Guided exercise: compare encodings using simulated data (20 min) Workshop: students bring prior homework plots and improve them (15 min) Download the Jupyter Notebook \ud83d\udcbb Starter Notebook Snippets import pandas as pd import matplotlib.pyplot as plt import seaborn as sns # Example of a misleading bar chart values = [5, 10, 15] labels = ['A', 'B', 'C'] plt.bar(labels, values) plt.ylim(4, 16) # Misleading y-axis range plt.title(\"Misleading Bar Chart\") plt.show() # Redesigned chart with zero baseline plt.bar(labels, values) plt.ylim(0, 16) plt.title(\"Improved Bar Chart\") plt.show() \ud83e\uddea In-Class Activity Critique provided \"poorly-designed\" charts and redesign them. Use preattentive attributes to highlight important data points. Compare multiple encoding strategies for the same dataset. \ud83c\udfe0 Homework (Due next Friday, Oct 3) Find a poorly designed chart (for example, a truncated y-axis bar chart from a news article, a rainbow-colored heatmap in a research paper, or an infographic with distorted area encodings). Recreate the chart faithfully in Python. Redesign the chart applying perception & design principles. Write a short reflection (200+ words) describing: Why the original was misleading or ineffective. What principles guided your redesign? How your redesign improves comprehension. Submit .ipynb and .html . Rubric (10 pts) Accurate reproduction of the original chart (2) Effective redesign applying principles (4) Clear reflection linking to theory (2) Visual clarity and labeling (2) \ud83e\udde9 Optional Extensions Experiment with alternative encodings and compare effectiveness. Conduct a quick peer survey: which design is easier to interpret? Try adding annotations or highlights using preattentive cues. \u2705 Submission Checklist Before submitting, make sure: Your assignment has fulfilled all the basic requirements listed above. The visualizations and your reflections in the Jupyter notebook are properly organized and displayed. Use Quarto to render the notebook into HTML and zip the files for submission.","title":"Week 5 \u2014 Perception &amp; Principles"},{"location":"weekly/module_week_5_perception_principles/#week-5-perception-principles","text":"Applying visual perception theory and design principles to create effective, truthful, and clear visualizations.","title":"Week 5 \u2014 Perception &amp; Principles"},{"location":"weekly/module_week_5_perception_principles/#background-motivation","text":"Even when the data is clean and the chart type is appropriate, design decisions can make the difference between clarity and confusion. Human perception imposes limits on how well we can decode visual information. By understanding principles from perceptual psychology, we can design graphics that communicate more effectively and avoid misleading audiences. This week introduces concepts like Cleveland & McGill\u2019s hierarchy of graphical perception, preattentive attributes, Gestalt principles, and common pitfalls in chart design. These theoretical foundations provide guidance for making practical design decisions in your visualizations.","title":"\ud83d\udcd6 Background &amp; Motivation"},{"location":"weekly/module_week_5_perception_principles/#learning-objectives","text":"Understand how human perception shapes data interpretation. Apply the Cleveland\u2013McGill perceptual rankings to select more effective encodings. Identify and use preattentive features to guide viewer attention. Recognize and correct misleading design practices.","title":"\ud83d\udd0e Learning Objectives"},{"location":"weekly/module_week_5_perception_principles/#readings-resources","text":"Cleveland & McGill (1984): Graphical Perception Fundamentals of Data Visualization \u2014 Chapters on perception and design. Data Visualization Society: Design Principles The Gestalt Principles Sample Data Sources: Simulated datasets designed to illustrate perception issues. Any dataset from previous weeks (for redesign exercises).","title":"\ud83d\udcda Readings &amp; Resources"},{"location":"weekly/module_week_5_perception_principles/#setup-checklist","text":"Ensure your environment includes: pip install seaborn matplotlib pandas","title":"\ud83d\udee0\ufe0f Setup Checklist"},{"location":"weekly/module_week_5_perception_principles/#lecture-outline","text":"","title":"\ud83e\udded Lecture Outline"},{"location":"weekly/module_week_5_perception_principles/#session-1-75-min-theory-focus","text":"Motivation: Why perception matters in visualization (10 min) Cleveland\u2013McGill hierarchy of graphical perception (20 min) Preattentive attributes (color, shape, position, orientation) (20 min) Gestalt principles and visual grouping (15 min) Misleading charts and design pitfalls (10 min)","title":"Session 1 (75 min \u2014 Theory Focus)"},{"location":"weekly/module_week_5_perception_principles/#session-2-75-min-hands-on-focus","text":"Recap & discussion of theory (10 min) Redesign bad charts into effective versions (30 min) Guided exercise: compare encodings using simulated data (20 min) Workshop: students bring prior homework plots and improve them (15 min) Download the Jupyter Notebook","title":"Session 2 (75 min \u2014 Hands-on Focus)"},{"location":"weekly/module_week_5_perception_principles/#starter-notebook-snippets","text":"import pandas as pd import matplotlib.pyplot as plt import seaborn as sns # Example of a misleading bar chart values = [5, 10, 15] labels = ['A', 'B', 'C'] plt.bar(labels, values) plt.ylim(4, 16) # Misleading y-axis range plt.title(\"Misleading Bar Chart\") plt.show() # Redesigned chart with zero baseline plt.bar(labels, values) plt.ylim(0, 16) plt.title(\"Improved Bar Chart\") plt.show()","title":"\ud83d\udcbb Starter Notebook Snippets"},{"location":"weekly/module_week_5_perception_principles/#in-class-activity","text":"Critique provided \"poorly-designed\" charts and redesign them. Use preattentive attributes to highlight important data points. Compare multiple encoding strategies for the same dataset.","title":"\ud83e\uddea In-Class Activity"},{"location":"weekly/module_week_5_perception_principles/#homework-due-next-friday-oct-3","text":"Find a poorly designed chart (for example, a truncated y-axis bar chart from a news article, a rainbow-colored heatmap in a research paper, or an infographic with distorted area encodings). Recreate the chart faithfully in Python. Redesign the chart applying perception & design principles. Write a short reflection (200+ words) describing: Why the original was misleading or ineffective. What principles guided your redesign? How your redesign improves comprehension. Submit .ipynb and .html . Rubric (10 pts) Accurate reproduction of the original chart (2) Effective redesign applying principles (4) Clear reflection linking to theory (2) Visual clarity and labeling (2)","title":"\ud83c\udfe0 Homework (Due next Friday, Oct 3)"},{"location":"weekly/module_week_5_perception_principles/#optional-extensions","text":"Experiment with alternative encodings and compare effectiveness. Conduct a quick peer survey: which design is easier to interpret? Try adding annotations or highlights using preattentive cues.","title":"\ud83e\udde9 Optional Extensions"},{"location":"weekly/module_week_5_perception_principles/#submission-checklist","text":"Before submitting, make sure: Your assignment has fulfilled all the basic requirements listed above. The visualizations and your reflections in the Jupyter notebook are properly organized and displayed. Use Quarto to render the notebook into HTML and zip the files for submission.","title":"\u2705 Submission Checklist"},{"location":"weekly/module_week_6_comparisons/","text":"Week 6 \u2014 Comparisons Designing fair and effective comparisons across categories, groups, and time. \ud83d\udcd6 Background & Motivation Most insight in data science comes from comparing things: groups, treatments, time periods, geographies, and models. Good comparison graphics make differences and similarities immediately legible without misleading the audience. This week focuses on selecting the right comparison design (bars, dot plots, slope charts, small multiples), aligning scales and baselines, and avoiding visual pitfalls that distort comparisons. \ud83d\udd0e Learning Objectives Choose appropriate designs for category and time comparisons (grouped bars, dot plots, slope charts, small multiples). Align scales, baselines, and axes to ensure fair comparisons. Normalize data (per capita, percent change, index to baseline) when appropriate. Use faceting and small multiples to reduce clutter and increase clarity. Add clear annotations and ordering to emphasize key contrasts. \ud83d\udcda Readings & Resources Fundamentals of Data Visualization \u2014 chapters on comparisons & small multiples. Seaborn: Categorical plots , FacetGrid Matplotlib: bar charts , subplots ColorBrewer: Choosing palettes Sample Data Sources: World Bank indicators (e.g., GDP per capita, life expectancy) Gapminder (country-level indicators) Sports/team statistics (season-by-season comparisons) \ud83d\udee0\ufe0f Setup Checklist Ensure your environment includes: pip install pandas numpy matplotlib seaborn plotly First, ensure that the virtual environment is properly created and activated. Then confirm you can import these libraries and render a simple chart before class. \ud83e\udded Lecture Outline Session 1 (75 min \u2014 Theory Focus) When to compare? Framing questions and choosing the right comparison graphic (10 min) Bars vs. dot plots: perceptual accuracy and overplotting concerns (15 min) Slope charts for before/after and rank changes (15 min) Scale, baseline, and normalization (indexing to 100, percent change, per\u2011capita) (20 min) Small multiples and faceting; ordering and labeling for clarity (15 min) Download the Jupyter Notebook and data used in lecture from this webpage Session 2 (75 min \u2014 Hands-on Focus) Live coding: grouped bars \u2192 dot plot refactor (15 min) Build a slope chart for a before/after dataset (20 min) Create a small multiples view with FacetGrid (20 min) Mini\u2011workshop: add annotations, reorder categories, and test alternative scales (20 min) Download the Jupyter Notebook for this session. \ud83d\udcbb Starter Notebook Snippets Dot plot vs. grouped bars import pandas as pd import seaborn as sns import matplotlib.pyplot as plt sns.set_theme(style=\"whitegrid\") # toy data: mean score by group and condition df = pd.DataFrame({ \"group\": [\"A\",\"A\",\"B\",\"B\",\"C\",\"C\"], \"condition\": [\"Control\",\"Treatment\"]*3, \"score\": [72, 78, 65, 74, 81, 85] }) # Grouped bars sns.catplot(data=df, kind=\"bar\", x=\"group\", y=\"score\", hue=\"condition\") plt.title(\"Grouped Bars\") # Dot plot (often clearer for two conditions) sns.catplot(data=df, kind=\"point\", x=\"group\", y=\"score\", hue=\"condition\", dodge=True) plt.title(\"Dot Plot Comparison\") Slope chart (before/after) import numpy as np before = pd.Series([72, 65, 81], index=[\"A\",\"B\",\"C\"]).rename(\"before\") after = pd.Series([78, 74, 85], index=[\"A\",\"B\",\"C\"]).rename(\"after\") long = pd.concat([before, after], axis=1).reset_index().melt(id_vars=\"index\", var_name=\"time\", value_name=\"score\") long = long.rename(columns={\"index\":\"group\"}) plt.figure(figsize=(6,4)) for g, sub in long.groupby(\"group\"): xs = [0, 1] ys = sub.sort_values(\"time\")[\"score\"].values plt.plot(xs, ys, marker=\"o\") plt.text(0-0.03, ys[0], g, ha=\"right\", va=\"center\") plt.xticks([0,1],[\"Before\",\"After\"]) plt.title(\"Slope Chart \u2014 Before vs After\") plt.ylabel(\"Score\") plt.grid(axis='y', alpha=.3) plt.tight_layout() Small multiples with FacetGrid # Using Gapminder-like structure peng = sns.load_dataset(\"penguins\").dropna() fg = sns.FacetGrid(peng, col=\"species\", height=3, sharey=True) fg.map_dataframe(sns.scatterplot, x=\"flipper_length_mm\", y=\"body_mass_g\", alpha=.7) fg.set_axis_labels(\"Flipper length (mm)\", \"Body mass (g)\") fg.set_titles(col_template=\"{col_name}\") Normalization (indexing to a baseline) # Index each group to its first time value wide = pd.DataFrame({\"t\":[1,2,3,4], \"A\":[100,110,108,120], \"B\":[100,98,105,112]}) base = wide.loc[0, [\"A\",\"B\"]] indexed = wide[[\"A\",\"B\"]].divide(base) * 100 indexed[\"t\"] = wide[\"t\"] indexed_m = indexed.melt(\"t\", var_name=\"series\", value_name=\"index\") sns.lineplot(data=indexed_m, x=\"t\", y=\"index\", hue=\"series\") plt.axhline(100, color=\"k\", lw=.8) plt.ylabel(\"Index (baseline=100)\") plt.title(\"Indexed Comparison\") \ud83e\uddea In-Class Activity Convert a cluttered grouped\u2011bar chart into a dot plot and explain which communicates differences more clearly. Build a slope chart for a before/after dataset and annotate the largest change. Create small multiples with FacetGrid to compare subgroups on the same scale. Try at least one normalization (percent change or index to baseline) and discuss how it changes the interpretation. \ud83c\udfe0 Homework (Due next Thursday, Oct 9) Select a dataset with at least two groups and either two conditions or multiple time points. Produce the following: One dot plot (or refactor from grouped bars) with thoughtful ordering and labels. One slope chart showing before/after or the earliest vs. the latest comparison. One small\u2011multiples chart (faceted) on a shared y\u2011scale. At least one normalized view (percent change or index to baseline). Add concise annotations and a brief (200\u2013300 words) discussion of which design best supports your comparison question and why. Submit .ipynb and .html . Rubric (10 pts) Appropriate chart choices for comparison tasks (3) Scale/baseline alignment and normalization where needed (3) Clear labeling, ordering, and annotations (2) Reproducibility and code quality (2) \ud83e\udde9 Optional Extensions Use plotly.express to build an interactive small multiples or animation (e.g., by year). Explore ranked dot plots (ordered by value) and slopegraphs with many categories. Add confidence intervals or error bars for group comparisons. \u2705 Submission Checklist Before submitting, make sure: Your assignment has fulfilled all the basic requirements listed above. The visualizations and your reflections in the Jupyter notebook are properly organized and displayed. Use Quarto to render the notebook into HTML and zip the files for submission.","title":"Week 6 \u2014 Comparisons"},{"location":"weekly/module_week_6_comparisons/#week-6-comparisons","text":"Designing fair and effective comparisons across categories, groups, and time.","title":"Week 6 \u2014 Comparisons"},{"location":"weekly/module_week_6_comparisons/#background-motivation","text":"Most insight in data science comes from comparing things: groups, treatments, time periods, geographies, and models. Good comparison graphics make differences and similarities immediately legible without misleading the audience. This week focuses on selecting the right comparison design (bars, dot plots, slope charts, small multiples), aligning scales and baselines, and avoiding visual pitfalls that distort comparisons.","title":"\ud83d\udcd6 Background &amp; Motivation"},{"location":"weekly/module_week_6_comparisons/#learning-objectives","text":"Choose appropriate designs for category and time comparisons (grouped bars, dot plots, slope charts, small multiples). Align scales, baselines, and axes to ensure fair comparisons. Normalize data (per capita, percent change, index to baseline) when appropriate. Use faceting and small multiples to reduce clutter and increase clarity. Add clear annotations and ordering to emphasize key contrasts.","title":"\ud83d\udd0e Learning Objectives"},{"location":"weekly/module_week_6_comparisons/#readings-resources","text":"Fundamentals of Data Visualization \u2014 chapters on comparisons & small multiples. Seaborn: Categorical plots , FacetGrid Matplotlib: bar charts , subplots ColorBrewer: Choosing palettes Sample Data Sources: World Bank indicators (e.g., GDP per capita, life expectancy) Gapminder (country-level indicators) Sports/team statistics (season-by-season comparisons)","title":"\ud83d\udcda Readings &amp; Resources"},{"location":"weekly/module_week_6_comparisons/#setup-checklist","text":"Ensure your environment includes: pip install pandas numpy matplotlib seaborn plotly First, ensure that the virtual environment is properly created and activated. Then confirm you can import these libraries and render a simple chart before class.","title":"\ud83d\udee0\ufe0f Setup Checklist"},{"location":"weekly/module_week_6_comparisons/#lecture-outline","text":"","title":"\ud83e\udded Lecture Outline"},{"location":"weekly/module_week_6_comparisons/#session-1-75-min-theory-focus","text":"When to compare? Framing questions and choosing the right comparison graphic (10 min) Bars vs. dot plots: perceptual accuracy and overplotting concerns (15 min) Slope charts for before/after and rank changes (15 min) Scale, baseline, and normalization (indexing to 100, percent change, per\u2011capita) (20 min) Small multiples and faceting; ordering and labeling for clarity (15 min) Download the Jupyter Notebook and data used in lecture from this webpage","title":"Session 1 (75 min \u2014 Theory Focus)"},{"location":"weekly/module_week_6_comparisons/#session-2-75-min-hands-on-focus","text":"Live coding: grouped bars \u2192 dot plot refactor (15 min) Build a slope chart for a before/after dataset (20 min) Create a small multiples view with FacetGrid (20 min) Mini\u2011workshop: add annotations, reorder categories, and test alternative scales (20 min) Download the Jupyter Notebook for this session.","title":"Session 2 (75 min \u2014 Hands-on Focus)"},{"location":"weekly/module_week_6_comparisons/#starter-notebook-snippets","text":"","title":"\ud83d\udcbb Starter Notebook Snippets"},{"location":"weekly/module_week_6_comparisons/#dot-plot-vs-grouped-bars","text":"import pandas as pd import seaborn as sns import matplotlib.pyplot as plt sns.set_theme(style=\"whitegrid\") # toy data: mean score by group and condition df = pd.DataFrame({ \"group\": [\"A\",\"A\",\"B\",\"B\",\"C\",\"C\"], \"condition\": [\"Control\",\"Treatment\"]*3, \"score\": [72, 78, 65, 74, 81, 85] }) # Grouped bars sns.catplot(data=df, kind=\"bar\", x=\"group\", y=\"score\", hue=\"condition\") plt.title(\"Grouped Bars\") # Dot plot (often clearer for two conditions) sns.catplot(data=df, kind=\"point\", x=\"group\", y=\"score\", hue=\"condition\", dodge=True) plt.title(\"Dot Plot Comparison\")","title":"Dot plot vs. grouped bars"},{"location":"weekly/module_week_6_comparisons/#slope-chart-beforeafter","text":"import numpy as np before = pd.Series([72, 65, 81], index=[\"A\",\"B\",\"C\"]).rename(\"before\") after = pd.Series([78, 74, 85], index=[\"A\",\"B\",\"C\"]).rename(\"after\") long = pd.concat([before, after], axis=1).reset_index().melt(id_vars=\"index\", var_name=\"time\", value_name=\"score\") long = long.rename(columns={\"index\":\"group\"}) plt.figure(figsize=(6,4)) for g, sub in long.groupby(\"group\"): xs = [0, 1] ys = sub.sort_values(\"time\")[\"score\"].values plt.plot(xs, ys, marker=\"o\") plt.text(0-0.03, ys[0], g, ha=\"right\", va=\"center\") plt.xticks([0,1],[\"Before\",\"After\"]) plt.title(\"Slope Chart \u2014 Before vs After\") plt.ylabel(\"Score\") plt.grid(axis='y', alpha=.3) plt.tight_layout()","title":"Slope chart (before/after)"},{"location":"weekly/module_week_6_comparisons/#small-multiples-with-facetgrid","text":"# Using Gapminder-like structure peng = sns.load_dataset(\"penguins\").dropna() fg = sns.FacetGrid(peng, col=\"species\", height=3, sharey=True) fg.map_dataframe(sns.scatterplot, x=\"flipper_length_mm\", y=\"body_mass_g\", alpha=.7) fg.set_axis_labels(\"Flipper length (mm)\", \"Body mass (g)\") fg.set_titles(col_template=\"{col_name}\")","title":"Small multiples with FacetGrid"},{"location":"weekly/module_week_6_comparisons/#normalization-indexing-to-a-baseline","text":"# Index each group to its first time value wide = pd.DataFrame({\"t\":[1,2,3,4], \"A\":[100,110,108,120], \"B\":[100,98,105,112]}) base = wide.loc[0, [\"A\",\"B\"]] indexed = wide[[\"A\",\"B\"]].divide(base) * 100 indexed[\"t\"] = wide[\"t\"] indexed_m = indexed.melt(\"t\", var_name=\"series\", value_name=\"index\") sns.lineplot(data=indexed_m, x=\"t\", y=\"index\", hue=\"series\") plt.axhline(100, color=\"k\", lw=.8) plt.ylabel(\"Index (baseline=100)\") plt.title(\"Indexed Comparison\")","title":"Normalization (indexing to a baseline)"},{"location":"weekly/module_week_6_comparisons/#in-class-activity","text":"Convert a cluttered grouped\u2011bar chart into a dot plot and explain which communicates differences more clearly. Build a slope chart for a before/after dataset and annotate the largest change. Create small multiples with FacetGrid to compare subgroups on the same scale. Try at least one normalization (percent change or index to baseline) and discuss how it changes the interpretation.","title":"\ud83e\uddea In-Class Activity"},{"location":"weekly/module_week_6_comparisons/#homework-due-next-thursday-oct-9","text":"Select a dataset with at least two groups and either two conditions or multiple time points. Produce the following: One dot plot (or refactor from grouped bars) with thoughtful ordering and labels. One slope chart showing before/after or the earliest vs. the latest comparison. One small\u2011multiples chart (faceted) on a shared y\u2011scale. At least one normalized view (percent change or index to baseline). Add concise annotations and a brief (200\u2013300 words) discussion of which design best supports your comparison question and why. Submit .ipynb and .html . Rubric (10 pts) Appropriate chart choices for comparison tasks (3) Scale/baseline alignment and normalization where needed (3) Clear labeling, ordering, and annotations (2) Reproducibility and code quality (2)","title":"\ud83c\udfe0 Homework (Due next Thursday, Oct 9)"},{"location":"weekly/module_week_6_comparisons/#optional-extensions","text":"Use plotly.express to build an interactive small multiples or animation (e.g., by year). Explore ranked dot plots (ordered by value) and slopegraphs with many categories. Add confidence intervals or error bars for group comparisons.","title":"\ud83e\udde9 Optional Extensions"},{"location":"weekly/module_week_6_comparisons/#submission-checklist","text":"Before submitting, make sure: Your assignment has fulfilled all the basic requirements listed above. The visualizations and your reflections in the Jupyter notebook are properly organized and displayed. Use Quarto to render the notebook into HTML and zip the files for submission.","title":"\u2705 Submission Checklist"},{"location":"weekly/module_week_7_text_labels_tables/","text":"Week 7 \u2014 Text, Labels, & Tables Enhancing clarity and storytelling through effective text, annotation, and tabular presentation. \ud83d\udcd6 Background & Motivation Numbers and charts alone rarely tell the full story. Effective use of text, labels, annotations, and tables can direct attention, clarify meaning, and strengthen the narrative of your visualization. This week focuses on best practices for integrating words with visuals, so your charts are not only accurate but also understandable and memorable . We also cover how to design tables that are clear, accessible, and complementary to visualizations. In many professional contexts (reports, dashboards, publications), tables remain a key medium for communicating precise values alongside visuals. \ud83d\udd0e Learning Objectives Add effective titles, axis labels, captions, and annotations to charts. Use direct labeling instead of or alongside legends. Highlight important data points with callouts and text placement. Design tables for clarity and readability, including alignment and formatting. Balance text and visuals to create compelling data stories. \ud83d\udcda Readings & Resources Fundamentals of Data Visualization \u2014 chapters on annotations and labeling. Datawrapper Academy: How to annotate your charts Table Design Tips (Evergreen Data) Matplotlib: text & annotation Seaborn: FacetGrid titles and labels Sample Data Sources: Sports statistics (e.g., player or team comparisons) Election results data Financial performance tables (company revenue, expenses, profits) \ud83d\udee0\ufe0f Setup Checklist Ensure your environment includes: pip install pandas matplotlib seaborn First, make sure the virtual environment is properly created and activated. Then confirm you can import these libraries and render a simple chart before class. \ud83e\udded Lecture Outline Session 1 (Theory Focus + Hands-on) Why text matters: the role of words in data storytelling Titles, subtitles, and captions: framing interpretation Legends vs. direct labeling: when to use each Annotation techniques: highlighting key values or trends Principles of clear table design Adding labels and annotations in Matplotlib & Seaborn Redesign a cluttered chart with better labeling Create a table in pandas and format it for readability \ud83d\udcbb Starter Notebook Snippets import matplotlib.pyplot as plt import seaborn as sns import pandas as pd # Example scatterplot with annotation penguins = sns.load_dataset(\"penguins\").dropna() sns.scatterplot(data=penguins, x=\"flipper_length_mm\", y=\"body_mass_g\", hue=\"species\") plt.title(\"Penguins: Flipper length vs Body mass\") plt.xlabel(\"Flipper length (mm)\") plt.ylabel(\"Body mass (g)\") # Annotate one point max_penguin = penguins.loc[penguins['body_mass_g'].idxmax()] plt.annotate(\"Heaviest penguin\", xy=(max_penguin['flipper_length_mm'], max_penguin['body_mass_g']), xytext=(200, 6000), arrowprops=dict(facecolor='black', shrink=0.05)) plt.show() # Example formatted table in pandas data = { 'Team': ['A','B','C'], 'Wins': [10, 12, 8], 'Losses': [5, 3, 7] } df = pd.DataFrame(data) # Pretty print with alignment df.style.set_table_styles([ {\"selector\": \"th\", \"props\": [(\"text-align\", \"center\")]}, {\"selector\": \"td\", \"props\": [(\"text-align\", \"center\")]} ]).set_caption(\"Team Performance Summary\") \ud83e\uddea In-Class Activity Take an unlabeled chart and add appropriate title, labels, and annotations . Recreate a sports statistics table and improve its formatting. Compare two versions of the same chart: one with only a legend, one with direct labeling. \ud83c\udfe0 Homework (Due next Thursday, Oct 16) Select a dataset (sports, election, or financial) and create: One visualization with clear title, labels, and at least two annotations . One directly-labeled chart (instead of legend-based). One formatted table that complements your visualization. Include a short reflection (200\u2013300 words) explaining your labeling and table design choices. Submit .ipynb and .html . Rubric (10 pts) Effective use of titles, captions, and labels (3) Clear and purposeful annotations (2) Table design clarity and readability (3) Reflection quality (2) \ud83e\udde9 Optional Extensions Experiment with matplotlib.offsetbox or custom text placement. Use color and font variations to emphasize annotations. Export a styled pandas DataFrame as an image or LaTeX table. \u2705 Submission Checklist Before submitting, make sure: Your assignment has fulfilled all the basic requirements listed above. The visualizations and your reflections in the Jupyter notebook are properly organized and displayed. Use Quarto to render the notebook into HTML and zip the files for submission.","title":"Week 7 \u2014 Text, Labels, &amp; Tables"},{"location":"weekly/module_week_7_text_labels_tables/#week-7-text-labels-tables","text":"Enhancing clarity and storytelling through effective text, annotation, and tabular presentation.","title":"Week 7 \u2014 Text, Labels, &amp; Tables"},{"location":"weekly/module_week_7_text_labels_tables/#background-motivation","text":"Numbers and charts alone rarely tell the full story. Effective use of text, labels, annotations, and tables can direct attention, clarify meaning, and strengthen the narrative of your visualization. This week focuses on best practices for integrating words with visuals, so your charts are not only accurate but also understandable and memorable . We also cover how to design tables that are clear, accessible, and complementary to visualizations. In many professional contexts (reports, dashboards, publications), tables remain a key medium for communicating precise values alongside visuals.","title":"\ud83d\udcd6 Background &amp; Motivation"},{"location":"weekly/module_week_7_text_labels_tables/#learning-objectives","text":"Add effective titles, axis labels, captions, and annotations to charts. Use direct labeling instead of or alongside legends. Highlight important data points with callouts and text placement. Design tables for clarity and readability, including alignment and formatting. Balance text and visuals to create compelling data stories.","title":"\ud83d\udd0e Learning Objectives"},{"location":"weekly/module_week_7_text_labels_tables/#readings-resources","text":"Fundamentals of Data Visualization \u2014 chapters on annotations and labeling. Datawrapper Academy: How to annotate your charts Table Design Tips (Evergreen Data) Matplotlib: text & annotation Seaborn: FacetGrid titles and labels Sample Data Sources: Sports statistics (e.g., player or team comparisons) Election results data Financial performance tables (company revenue, expenses, profits)","title":"\ud83d\udcda Readings &amp; Resources"},{"location":"weekly/module_week_7_text_labels_tables/#setup-checklist","text":"Ensure your environment includes: pip install pandas matplotlib seaborn First, make sure the virtual environment is properly created and activated. Then confirm you can import these libraries and render a simple chart before class.","title":"\ud83d\udee0\ufe0f Setup Checklist"},{"location":"weekly/module_week_7_text_labels_tables/#lecture-outline","text":"","title":"\ud83e\udded Lecture Outline"},{"location":"weekly/module_week_7_text_labels_tables/#session-1-theory-focus-hands-on","text":"Why text matters: the role of words in data storytelling Titles, subtitles, and captions: framing interpretation Legends vs. direct labeling: when to use each Annotation techniques: highlighting key values or trends Principles of clear table design Adding labels and annotations in Matplotlib & Seaborn Redesign a cluttered chart with better labeling Create a table in pandas and format it for readability","title":"Session 1 (Theory Focus + Hands-on)"},{"location":"weekly/module_week_7_text_labels_tables/#starter-notebook-snippets","text":"import matplotlib.pyplot as plt import seaborn as sns import pandas as pd # Example scatterplot with annotation penguins = sns.load_dataset(\"penguins\").dropna() sns.scatterplot(data=penguins, x=\"flipper_length_mm\", y=\"body_mass_g\", hue=\"species\") plt.title(\"Penguins: Flipper length vs Body mass\") plt.xlabel(\"Flipper length (mm)\") plt.ylabel(\"Body mass (g)\") # Annotate one point max_penguin = penguins.loc[penguins['body_mass_g'].idxmax()] plt.annotate(\"Heaviest penguin\", xy=(max_penguin['flipper_length_mm'], max_penguin['body_mass_g']), xytext=(200, 6000), arrowprops=dict(facecolor='black', shrink=0.05)) plt.show() # Example formatted table in pandas data = { 'Team': ['A','B','C'], 'Wins': [10, 12, 8], 'Losses': [5, 3, 7] } df = pd.DataFrame(data) # Pretty print with alignment df.style.set_table_styles([ {\"selector\": \"th\", \"props\": [(\"text-align\", \"center\")]}, {\"selector\": \"td\", \"props\": [(\"text-align\", \"center\")]} ]).set_caption(\"Team Performance Summary\")","title":"\ud83d\udcbb Starter Notebook Snippets"},{"location":"weekly/module_week_7_text_labels_tables/#in-class-activity","text":"Take an unlabeled chart and add appropriate title, labels, and annotations . Recreate a sports statistics table and improve its formatting. Compare two versions of the same chart: one with only a legend, one with direct labeling.","title":"\ud83e\uddea In-Class Activity"},{"location":"weekly/module_week_7_text_labels_tables/#homework-due-next-thursday-oct-16","text":"Select a dataset (sports, election, or financial) and create: One visualization with clear title, labels, and at least two annotations . One directly-labeled chart (instead of legend-based). One formatted table that complements your visualization. Include a short reflection (200\u2013300 words) explaining your labeling and table design choices. Submit .ipynb and .html . Rubric (10 pts) Effective use of titles, captions, and labels (3) Clear and purposeful annotations (2) Table design clarity and readability (3) Reflection quality (2)","title":"\ud83c\udfe0 Homework (Due next Thursday, Oct 16)"},{"location":"weekly/module_week_7_text_labels_tables/#optional-extensions","text":"Experiment with matplotlib.offsetbox or custom text placement. Use color and font variations to emphasize annotations. Export a styled pandas DataFrame as an image or LaTeX table.","title":"\ud83e\udde9 Optional Extensions"},{"location":"weekly/module_week_7_text_labels_tables/#submission-checklist","text":"Before submitting, make sure: Your assignment has fulfilled all the basic requirements listed above. The visualizations and your reflections in the Jupyter notebook are properly organized and displayed. Use Quarto to render the notebook into HTML and zip the files for submission.","title":"\u2705 Submission Checklist"},{"location":"weekly/week4/file_list/","text":"Week 4 file list A collection of files included in this lecture: Data Files nyc_taxi_sample.csv \u2013 Sample dataset of NYC taxi trips. taxi_zones.csv \u2013 New York taxi zones lookup table. covid_daily.csv ` \u2013 COVID-19 case counts dataset. Notebook week04_wrangle.ipynb \u2013 Starter Jupyter Notebook.","title":"Week 4 file list"},{"location":"weekly/week4/file_list/#week-4-file-list","text":"A collection of files included in this lecture:","title":"Week 4 file list"},{"location":"weekly/week4/file_list/#data-files","text":"nyc_taxi_sample.csv \u2013 Sample dataset of NYC taxi trips. taxi_zones.csv \u2013 New York taxi zones lookup table. covid_daily.csv ` \u2013 COVID-19 case counts dataset.","title":"Data Files"},{"location":"weekly/week4/file_list/#notebook","text":"week04_wrangle.ipynb \u2013 Starter Jupyter Notebook.","title":"Notebook"},{"location":"weekly/week6/file_list/","text":"File list for Week 6 chart demo with Jupyter Notebook A collection of files included in this lecture: Data Files gapminder_subset.csv \u2013 Synthesized sample data for working with Gapminder dataset. counts_population.csv \u2013 Synthesized population data. Notebook Week06_Comparisons_session1.ipynb \u2013 Jupyter Notebook for illustrating the visuals in the lectures charts_demo.ipynb \u2013 Jupyter Notebook for demos in the \"Chart cheat sheet\" slide","title":"File list for Week 6 chart demo with Jupyter Notebook"},{"location":"weekly/week6/file_list/#file-list-for-week-6-chart-demo-with-jupyter-notebook","text":"A collection of files included in this lecture:","title":"File list for Week 6 chart demo with Jupyter Notebook"},{"location":"weekly/week6/file_list/#data-files","text":"gapminder_subset.csv \u2013 Synthesized sample data for working with Gapminder dataset. counts_population.csv \u2013 Synthesized population data.","title":"Data Files"},{"location":"weekly/week6/file_list/#notebook","text":"Week06_Comparisons_session1.ipynb \u2013 Jupyter Notebook for illustrating the visuals in the lectures charts_demo.ipynb \u2013 Jupyter Notebook for demos in the \"Chart cheat sheet\" slide","title":"Notebook"}]}