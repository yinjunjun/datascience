{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Home Welcome to Data Visualiztion for Data Science (DATS 2102) Weekly Modules Week 1 - Getting Started Week 2 - Language of Graphs Week 3 - Distributions and Variations Week 4 - Wrangling with Pandas Week 5 - Perception and Principles Week 6 - Comparisons Mid-term - Mid-term Project Week 7 - Text, Labels, and Tables Week 8 - Mapping I & II Week 9 - Color & Accessibility Week 10 - Relationships & Modeling Week 11 - Uncertainty & Error Visualization Week 12 - Visualization for ML/NLP Data Sources Please find useful and recommended data sources from the data sources page","title":"Home"},{"location":"#home","text":"Welcome to Data Visualiztion for Data Science (DATS 2102)","title":"Home"},{"location":"#weekly-modules","text":"Week 1 - Getting Started Week 2 - Language of Graphs Week 3 - Distributions and Variations Week 4 - Wrangling with Pandas Week 5 - Perception and Principles Week 6 - Comparisons Mid-term - Mid-term Project Week 7 - Text, Labels, and Tables Week 8 - Mapping I & II Week 9 - Color & Accessibility Week 10 - Relationships & Modeling Week 11 - Uncertainty & Error Visualization Week 12 - Visualization for ML/NLP","title":"Weekly Modules"},{"location":"#data-sources","text":"Please find useful and recommended data sources from the data sources page","title":"Data Sources"},{"location":"course_modules/","text":"DATS 2102 \u2014 Data Visualization for Data Science Week 1 \u2014 Getting Started Focus: Course introduction, importance of data visualization in data science, and environment setup. Learning Objectives: - Understand visualization\u2019s role in data analysis and communication. - Install Python, Jupyter, and core libraries. - Execute basic code and create markdown cells in Jupyter. - Produce first bar and scatter plots. Datasets: Seaborn penguins , small CSVs (population, GDP). Core Libraries: pandas, matplotlib, seaborn. Lecture Topics: - What is data visualization and why it matters. - Overview of course structure and expectations. - Introduction to JupyterLab workflow. In-Class Activities: Load dataset, inspect data, create bar and scatter plots. Homework: Set up environment, explore CSV, produce two labeled plots with captions. Week 2 \u2014 Language of Graphs Focus: Visual encodings, tidy data principles, grammar of graphics. Learning Objectives: - Identify and apply core visual encodings (position, color, shape, size). - Reshape data into tidy format. - Use seaborn and altair for multi-encoding charts. Datasets: Seaborn tips , Gapminder data. Core Libraries: pandas, seaborn, altair. Lecture Topics: - Mapping data to visual attributes. - Tidy data and why it matters. - Grammar of graphics overview. In-Class Activities: Reshape and plot categorical vs. numerical data. Homework: Create three visualizations using different encoding strategies, with explanations. Week 3 \u2014 Distributions & Variation Focus: Visualizing univariate distributions and variation. Learning Objectives: - Choose appropriate distribution plots. - Understand and apply binning, kernel density estimation, ECDF. Datasets: Flight delay data, iris dataset. Core Libraries: seaborn, matplotlib. Lecture Topics: - When to use histograms vs. KDEs vs. box/violin plots. - Understanding variability and spread. In-Class Activities: Compare multiple distribution plot types. Homework: Explore and visualize distributions in two datasets with narrative. Week 4 \u2014 Wrangling with pandas Focus: Data cleaning, transformation, and preparation for visualization. Learning Objectives: - Select, filter, group, summarize, and reshape data. - Work with datetime and categorical data. Datasets: NYC taxi trips sample, COVID-19 data. Core Libraries: pandas, matplotlib. Lecture Topics: - Data import and export. - Common data wrangling operations. In-Class Activities: Group data by category and visualize aggregates. Homework: Clean a messy dataset and create three informative charts. Week 5 \u2014 Perception & Principles Focus: Visual perception theory and chart design principles. Learning Objectives: - Apply Cleveland\u2013McGill perceptual rankings. - Recognize and fix misleading visualizations. Datasets: Simulated comparison datasets. Core Libraries: seaborn, matplotlib. Lecture Topics: - How humans perceive visual encodings. - Common design pitfalls. In-Class Activities: Redesign poor visualizations. Homework: Select a misleading chart, redesign it, and explain improvements. Week 6 \u2014 Comparisons Focus: Comparing categories, groups, and time series. Learning Objectives: - Create grouped bar charts, dot plots, slope charts. - Use small multiples effectively. Datasets: World Bank indicators. Core Libraries: seaborn, matplotlib, plotly. Lecture Topics: - Designing fair comparisons. - Aligning scales and baselines. In-Class Activities: Build comparison visuals using small multiples. Homework: Compare groups in chosen dataset using 2+ visualization types. Week 7 \u2014 Text, Labels, & Tables Focus: Enhancing visuals with annotations and well-formatted tables. Learning Objectives: - Apply direct labeling and meaningful captions. - Create clear and concise tables. Datasets: Sports statistics. Core Libraries: matplotlib, seaborn, pandas. Lecture Topics: - Annotating charts for storytelling. - Formatting tables for clarity. In-Class Activities: Annotate key data points in charts. Homework: Create a labeled and captioned visual from dataset of choice. Week 8 \u2014 Mapping I & II Focus: Fundamentals of geographic data visualization. Learning Objectives: - Create choropleth maps and understand coordinate reference systems. - Join spatial and tabular datasets. Datasets: US states shapefile, population data. Core Libraries: geopandas, mapclassify, folium. Lecture Topics: - Spatial joins. - Map classification schemes. In-Class Activities: Produce a choropleth map from joined datasets. Homework: Create thematic map for a real-world topic. Week 9 \u2014 Color & Accessibility Focus: Effective and inclusive color usage in visualization. Learning Objectives: - Choose appropriate color palettes. - Apply accessibility best practices. Datasets: From previous assignments. Core Libraries: seaborn, matplotlib, colorcet. Lecture Topics: - Sequential, diverging, qualitative palettes. - Colorblind-safe schemes. In-Class Activities: Recolor existing charts for better accessibility. Homework: Revise a prior visualization with improved color design. Week 10 \u2014 Relationships & Modeling Focus: Visualizing relationships and model fit. Learning Objectives: - Plot scatterplots with regression lines. - Visualize residuals and model diagnostics. Datasets: Housing prices dataset. Core Libraries: seaborn, statsmodels, matplotlib. Lecture Topics: - Visualizing correlation and causation. - Checking model assumptions visually. In-Class Activities: Fit and visualize a simple regression. Homework: Analyze and visualize a bivariate relationship with commentary. Week 11 \u2014 Uncertainty Focus: Representing uncertainty in data visualizations. Learning Objectives: - Add error bars and confidence intervals. - Visualize sampling variability. Datasets: Polling data. Core Libraries: seaborn, matplotlib. Lecture Topics: - Why uncertainty matters. - Techniques for communicating uncertainty. In-Class Activities: Compare plots with and without uncertainty intervals. Homework: Visualize uncertainty in selected dataset. Week 12 \u2014 Visualization for ML/NLP Focus: Visualizing machine learning and NLP outputs. Learning Objectives: - Plot feature importance, confusion matrices, and ROC curves. - Visualize topic clusters and word clouds. Datasets: IMDB reviews, classification dataset. Core Libraries: scikit-learn, matplotlib, seaborn, wordcloud, bertopic. Lecture Topics: - Visualization in the ML workflow. - Visualizing high-dimensional data. In-Class Activities: Train a small model, visualize predictions. Homework: Create three ML-related visualizations from a chosen dataset. Weeks 13\u201314 \u2014 Final Project Workshops Focus: Final project preparation, peer review, and refinement. Learning Objectives: - Integrate multiple visualization techniques into one narrative. - Polish charts for professional presentation. Datasets: Student-chosen. In-Class Activities: Peer feedback, troubleshooting, improving visuals. Homework: Finalize and submit project with report and reproducible code.","title":"Modules"},{"location":"course_modules/#dats-2102-data-visualization-for-data-science","text":"","title":"DATS 2102 \u2014 Data Visualization for Data Science"},{"location":"course_modules/#week-1-getting-started","text":"Focus: Course introduction, importance of data visualization in data science, and environment setup. Learning Objectives: - Understand visualization\u2019s role in data analysis and communication. - Install Python, Jupyter, and core libraries. - Execute basic code and create markdown cells in Jupyter. - Produce first bar and scatter plots. Datasets: Seaborn penguins , small CSVs (population, GDP). Core Libraries: pandas, matplotlib, seaborn. Lecture Topics: - What is data visualization and why it matters. - Overview of course structure and expectations. - Introduction to JupyterLab workflow. In-Class Activities: Load dataset, inspect data, create bar and scatter plots. Homework: Set up environment, explore CSV, produce two labeled plots with captions.","title":"Week 1 \u2014 Getting Started"},{"location":"course_modules/#week-2-language-of-graphs","text":"Focus: Visual encodings, tidy data principles, grammar of graphics. Learning Objectives: - Identify and apply core visual encodings (position, color, shape, size). - Reshape data into tidy format. - Use seaborn and altair for multi-encoding charts. Datasets: Seaborn tips , Gapminder data. Core Libraries: pandas, seaborn, altair. Lecture Topics: - Mapping data to visual attributes. - Tidy data and why it matters. - Grammar of graphics overview. In-Class Activities: Reshape and plot categorical vs. numerical data. Homework: Create three visualizations using different encoding strategies, with explanations.","title":"Week 2 \u2014 Language of Graphs"},{"location":"course_modules/#week-3-distributions-variation","text":"Focus: Visualizing univariate distributions and variation. Learning Objectives: - Choose appropriate distribution plots. - Understand and apply binning, kernel density estimation, ECDF. Datasets: Flight delay data, iris dataset. Core Libraries: seaborn, matplotlib. Lecture Topics: - When to use histograms vs. KDEs vs. box/violin plots. - Understanding variability and spread. In-Class Activities: Compare multiple distribution plot types. Homework: Explore and visualize distributions in two datasets with narrative.","title":"Week 3 \u2014 Distributions &amp; Variation"},{"location":"course_modules/#week-4-wrangling-with-pandas","text":"Focus: Data cleaning, transformation, and preparation for visualization. Learning Objectives: - Select, filter, group, summarize, and reshape data. - Work with datetime and categorical data. Datasets: NYC taxi trips sample, COVID-19 data. Core Libraries: pandas, matplotlib. Lecture Topics: - Data import and export. - Common data wrangling operations. In-Class Activities: Group data by category and visualize aggregates. Homework: Clean a messy dataset and create three informative charts.","title":"Week 4 \u2014 Wrangling with pandas"},{"location":"course_modules/#week-5-perception-principles","text":"Focus: Visual perception theory and chart design principles. Learning Objectives: - Apply Cleveland\u2013McGill perceptual rankings. - Recognize and fix misleading visualizations. Datasets: Simulated comparison datasets. Core Libraries: seaborn, matplotlib. Lecture Topics: - How humans perceive visual encodings. - Common design pitfalls. In-Class Activities: Redesign poor visualizations. Homework: Select a misleading chart, redesign it, and explain improvements.","title":"Week 5 \u2014 Perception &amp; Principles"},{"location":"course_modules/#week-6-comparisons","text":"Focus: Comparing categories, groups, and time series. Learning Objectives: - Create grouped bar charts, dot plots, slope charts. - Use small multiples effectively. Datasets: World Bank indicators. Core Libraries: seaborn, matplotlib, plotly. Lecture Topics: - Designing fair comparisons. - Aligning scales and baselines. In-Class Activities: Build comparison visuals using small multiples. Homework: Compare groups in chosen dataset using 2+ visualization types.","title":"Week 6 \u2014 Comparisons"},{"location":"course_modules/#week-7-text-labels-tables","text":"Focus: Enhancing visuals with annotations and well-formatted tables. Learning Objectives: - Apply direct labeling and meaningful captions. - Create clear and concise tables. Datasets: Sports statistics. Core Libraries: matplotlib, seaborn, pandas. Lecture Topics: - Annotating charts for storytelling. - Formatting tables for clarity. In-Class Activities: Annotate key data points in charts. Homework: Create a labeled and captioned visual from dataset of choice.","title":"Week 7 \u2014 Text, Labels, &amp; Tables"},{"location":"course_modules/#week-8-mapping-i-ii","text":"Focus: Fundamentals of geographic data visualization. Learning Objectives: - Create choropleth maps and understand coordinate reference systems. - Join spatial and tabular datasets. Datasets: US states shapefile, population data. Core Libraries: geopandas, mapclassify, folium. Lecture Topics: - Spatial joins. - Map classification schemes. In-Class Activities: Produce a choropleth map from joined datasets. Homework: Create thematic map for a real-world topic.","title":"Week 8 \u2014 Mapping I &amp; II"},{"location":"course_modules/#week-9-color-accessibility","text":"Focus: Effective and inclusive color usage in visualization. Learning Objectives: - Choose appropriate color palettes. - Apply accessibility best practices. Datasets: From previous assignments. Core Libraries: seaborn, matplotlib, colorcet. Lecture Topics: - Sequential, diverging, qualitative palettes. - Colorblind-safe schemes. In-Class Activities: Recolor existing charts for better accessibility. Homework: Revise a prior visualization with improved color design.","title":"Week 9 \u2014 Color &amp; Accessibility"},{"location":"course_modules/#week-10-relationships-modeling","text":"Focus: Visualizing relationships and model fit. Learning Objectives: - Plot scatterplots with regression lines. - Visualize residuals and model diagnostics. Datasets: Housing prices dataset. Core Libraries: seaborn, statsmodels, matplotlib. Lecture Topics: - Visualizing correlation and causation. - Checking model assumptions visually. In-Class Activities: Fit and visualize a simple regression. Homework: Analyze and visualize a bivariate relationship with commentary.","title":"Week 10 \u2014 Relationships &amp; Modeling"},{"location":"course_modules/#week-11-uncertainty","text":"Focus: Representing uncertainty in data visualizations. Learning Objectives: - Add error bars and confidence intervals. - Visualize sampling variability. Datasets: Polling data. Core Libraries: seaborn, matplotlib. Lecture Topics: - Why uncertainty matters. - Techniques for communicating uncertainty. In-Class Activities: Compare plots with and without uncertainty intervals. Homework: Visualize uncertainty in selected dataset.","title":"Week 11 \u2014 Uncertainty"},{"location":"course_modules/#week-12-visualization-for-mlnlp","text":"Focus: Visualizing machine learning and NLP outputs. Learning Objectives: - Plot feature importance, confusion matrices, and ROC curves. - Visualize topic clusters and word clouds. Datasets: IMDB reviews, classification dataset. Core Libraries: scikit-learn, matplotlib, seaborn, wordcloud, bertopic. Lecture Topics: - Visualization in the ML workflow. - Visualizing high-dimensional data. In-Class Activities: Train a small model, visualize predictions. Homework: Create three ML-related visualizations from a chosen dataset.","title":"Week 12 \u2014 Visualization for ML/NLP"},{"location":"course_modules/#weeks-1314-final-project-workshops","text":"Focus: Final project preparation, peer review, and refinement. Learning Objectives: - Integrate multiple visualization techniques into one narrative. - Polish charts for professional presentation. Datasets: Student-chosen. In-Class Activities: Peer feedback, troubleshooting, improving visuals. Homework: Finalize and submit project with report and reproducible code.","title":"Weeks 13\u201314 \u2014 Final Project Workshops"},{"location":"syllabus/","text":"DATS 2102: Data Visualization for Data Science Instructor : Junjun Yin Email : j.yin@gwu.edu Semester : Fall 2025 Dates : 08/25/25 \u2013 12/08/25 Class Time : Tuesday & Thursday Office Hours : (Details in Blackboard) Office Location : 2036 H St NW, Room 309 Course Description This course introduces students to the core principles and practices of data visualization within the context of data science. Students will learn how to collect, process, analyze, and communicate data-driven insights using effective and ethical visualization techniques. Emphasis will be placed on hands-on programming with Python\u2019s visualization ecosystem ( pandas , matplotlib , seaborn , plotly , altair , geopandas ) and applying best practices for clarity, accuracy, and storytelling. The course will cover visualization theory, design principles, and practical skills, including geographic data mapping and visualizing results from machine learning models. By the end of the semester, students will be able to produce high-quality visualizations that effectively communicate data insights to diverse audiences. Course Prerequisites DATS 1001 and STAT 1051/1053/1111/1127, or permission of the instructor. Learning Outcomes As a result of completing this course, students will be able to: 1. Process and tidy real-world data using pandas . 2. Apply visual perception and design principles to create truthful, clear graphics. 3. Visualize univariate, bivariate, and multivariate patterns; compare groups effectively. 4. Map and analyze geographic data using geopandas , contextily , and folium / plotly . 5. Visualize relationships and communicate model context and uncertainty. 6. Build interactive, annotated visuals and simple data stories/dashboards. 7. Apply visualization to ML & NLP tasks (feature importance, confusion matrices/ROC, word clouds, BERTopic topic maps, embedding plots). Course Workload This is a 3-credit course. Students are expected to engage in 2.5 hours of direct instruction and a minimum of 5 hours of independent learning each week, for a combined minimum total of 7.5 hours per week or 112.5 hours over the semester. Required Tools and Texts Tools : Anaconda (or Python 3.10+), JupyterLab, VS Code, Sublime Text, PyCharm, Google Colab, or other tools that support Python programming and visualization. Core Libraries : pandas, numpy, matplotlib, seaborn, altair, plotly, geopandas, mapclassify, contextily, folium, scikit-learn, umap-learn, sentence-transformers, bertopic, wordcloud. Documentation & Guides : - Matplotlib - Seaborn - Plotly - Altair - GeoPandas - Pandas Texts : No required textbook. Recommended: Fundamentals of Data Visualization by Claus O. Wilke (available free online) and Storytelling with Data by Cole Nussbaumer Knaflic. Weekly Topics & Schedule Week Topic Description 1 Getting Started Python setup, Jupyter, pandas basics, first plot with matplotlib. 2 Language of Graphs Encodings, tidy data, seaborn & altair grammar. 3 Distributions & Variation Hist/KDE/violin/ECDF, binning & outliers. 4 Wrangling with pandas select/filter/mutate/groupby/merge, reshape, dates. 5 Perception & Principles Cleveland\u2013McGill, preattentive features, clutter. 6 Comparisons Bars/dots/small multiples, ordering & baselines, log scales. 7 Text, Labels, & Tables Direct labeling, captions, tables. 8 Mapping I Choropleths, CRS, spatial joins, geopandas, mapclassify, folium. 9 Color & Accessibility Sequential/diverging/qualitative palettes, pitfalls. 10 Relationships & Modeling Scatter/line, smoothing, statsmodels, model checks. 11 Uncertainty Error bars, intervals, bootstrap visuals. 12 Visualization for ML/NLP Feature importance, confusion/ROC-PR, word clouds, BERTopic, UMAP embeddings. 13\u201314 Final Project Workshops Scoping, refinement, narrative. Assignments & Grading Assignment Weight Weekly Notebooks & Exercises 40% Mid-Semester Visualization Project 20% Final Project 30% Participation & Peer Feedback 10% Final Project The final project will synthesize the skills learned throughout the course. Students will: - Propose a project idea by Week 9. - Develop a prototype by Week 13. - Submit the final project by December 8. Requirements: - Multiple well-designed visualizations with an accompanying narrative. - At least one map or ML/NLP visualization. - Accessibility considerations (color choice, labeling, alt text). - A reproducible Jupyter Notebook and any necessary datasets or data sources. Projects will be graded on clarity, creativity, technical proficiency, and adherence to visualization best practices. University Policies Academic Integrity Code Academic integrity is an essential part of the educational process, and all members of the GW community take these matters very seriously. As the instructor of record for this course, my role is to provide clear expectations and uphold them in all assessments. Violations of academic integrity occur when students fail to cite research sources properly, engage in unauthorized collaboration, falsify data, and otherwise violate the Code of Academic Integrity. If you have any questions about whether particular academic practices or resources are permitted, you should ask me for clarification. If you are reported for an academic integrity violation, you should contact Conflict Education and Student Accountability (CESA) to learn more about your rights and options. Consequences can range from failure of assignment to expulsion from the University and may include a transcript notation. More info: students.gwu.edu/code-academic-integrity or cesa@gwu.edu. University policy on observance of religious holidays Students must notify faculty during the first week of the semester, or as early as possible, but no later than three weeks prior to the absence, of their intention to be absent for religious observance. See details at provost.gwu.edu/policies-procedures-and-guidelines . Use of Electronic Course Materials and Class Recordings Students are encouraged to use electronic course materials for private personal use in connection with their academic program of study. These materials should not be shared or used for non-course related purposes unless express permission is granted by the instructor. Academic Support Academic Commons Academic Commons is the central location for academic support resources for GW students. To schedule a peer tutoring session for a variety of courses visit go.gwu.edu/tutoring . Visit academiccommons.gwu.edu for study skills tips, finding help with research, and connecting with other campus resources. For questions email academiccommons@gwu.edu. GW Writing Center GW Writing Center cultivates confident writers in the University community by facilitating collaborative, critical, and inclusive conversations at all stages of the writing process. Working alongside peer mentors, writers develop strategies to write independently in academic and public settings. Appointments can be booked online at gwu.mywconline.com . Disability Support Services (DSS) Any student who may need an accommodation based on the potential impact of a disability should contact Disability Support Services at disabilitysupport.gwu.edu to establish eligibility and coordinate reasonable accommodations. Student Health Center The Student Health Center (SHC) offers medical, counseling/psychological, and psychiatric services to GW students. More information about the SHC is available at healthcenter.gwu.edu . Students experiencing a medical or mental health emergency on campus should contact GW Emergency Services at 202-994-6111, or off campus at 911. GW Campus Emergency Information GW Emergency Services : 202-994-6111 For situation-specific instructions, refer to GW\u2019s Emergency Procedures guide. GW Alert GW Alert is an emergency notification system that sends alerts to the GW community. GW requests students, faculty, and staff maintain current contact information by logging on to alert.gwu.edu . Alerts are sent via email, text, social media, and other means, including the Guardian app. Protective Actions GW prescribes four protective actions that can be issued by university officials depending on the type of emergency. All GW community members are expected to follow directions according to the specified protective action: Shelter, Evacuate, Secure, and Lockdown. Learn more at safety.gwu.edu/gw-standard-emergency-statuses .","title":"Syllabus"},{"location":"syllabus/#dats-2102-data-visualization-for-data-science","text":"Instructor : Junjun Yin Email : j.yin@gwu.edu Semester : Fall 2025 Dates : 08/25/25 \u2013 12/08/25 Class Time : Tuesday & Thursday Office Hours : (Details in Blackboard) Office Location : 2036 H St NW, Room 309","title":"DATS 2102: Data Visualization for Data Science"},{"location":"syllabus/#course-description","text":"This course introduces students to the core principles and practices of data visualization within the context of data science. Students will learn how to collect, process, analyze, and communicate data-driven insights using effective and ethical visualization techniques. Emphasis will be placed on hands-on programming with Python\u2019s visualization ecosystem ( pandas , matplotlib , seaborn , plotly , altair , geopandas ) and applying best practices for clarity, accuracy, and storytelling. The course will cover visualization theory, design principles, and practical skills, including geographic data mapping and visualizing results from machine learning models. By the end of the semester, students will be able to produce high-quality visualizations that effectively communicate data insights to diverse audiences.","title":"Course Description"},{"location":"syllabus/#course-prerequisites","text":"DATS 1001 and STAT 1051/1053/1111/1127, or permission of the instructor.","title":"Course Prerequisites"},{"location":"syllabus/#learning-outcomes","text":"As a result of completing this course, students will be able to: 1. Process and tidy real-world data using pandas . 2. Apply visual perception and design principles to create truthful, clear graphics. 3. Visualize univariate, bivariate, and multivariate patterns; compare groups effectively. 4. Map and analyze geographic data using geopandas , contextily , and folium / plotly . 5. Visualize relationships and communicate model context and uncertainty. 6. Build interactive, annotated visuals and simple data stories/dashboards. 7. Apply visualization to ML & NLP tasks (feature importance, confusion matrices/ROC, word clouds, BERTopic topic maps, embedding plots).","title":"Learning Outcomes"},{"location":"syllabus/#course-workload","text":"This is a 3-credit course. Students are expected to engage in 2.5 hours of direct instruction and a minimum of 5 hours of independent learning each week, for a combined minimum total of 7.5 hours per week or 112.5 hours over the semester.","title":"Course Workload"},{"location":"syllabus/#required-tools-and-texts","text":"Tools : Anaconda (or Python 3.10+), JupyterLab, VS Code, Sublime Text, PyCharm, Google Colab, or other tools that support Python programming and visualization. Core Libraries : pandas, numpy, matplotlib, seaborn, altair, plotly, geopandas, mapclassify, contextily, folium, scikit-learn, umap-learn, sentence-transformers, bertopic, wordcloud. Documentation & Guides : - Matplotlib - Seaborn - Plotly - Altair - GeoPandas - Pandas Texts : No required textbook. Recommended: Fundamentals of Data Visualization by Claus O. Wilke (available free online) and Storytelling with Data by Cole Nussbaumer Knaflic.","title":"Required Tools and Texts"},{"location":"syllabus/#weekly-topics-schedule","text":"Week Topic Description 1 Getting Started Python setup, Jupyter, pandas basics, first plot with matplotlib. 2 Language of Graphs Encodings, tidy data, seaborn & altair grammar. 3 Distributions & Variation Hist/KDE/violin/ECDF, binning & outliers. 4 Wrangling with pandas select/filter/mutate/groupby/merge, reshape, dates. 5 Perception & Principles Cleveland\u2013McGill, preattentive features, clutter. 6 Comparisons Bars/dots/small multiples, ordering & baselines, log scales. 7 Text, Labels, & Tables Direct labeling, captions, tables. 8 Mapping I Choropleths, CRS, spatial joins, geopandas, mapclassify, folium. 9 Color & Accessibility Sequential/diverging/qualitative palettes, pitfalls. 10 Relationships & Modeling Scatter/line, smoothing, statsmodels, model checks. 11 Uncertainty Error bars, intervals, bootstrap visuals. 12 Visualization for ML/NLP Feature importance, confusion/ROC-PR, word clouds, BERTopic, UMAP embeddings. 13\u201314 Final Project Workshops Scoping, refinement, narrative.","title":"Weekly Topics &amp; Schedule"},{"location":"syllabus/#assignments-grading","text":"Assignment Weight Weekly Notebooks & Exercises 40% Mid-Semester Visualization Project 20% Final Project 30% Participation & Peer Feedback 10%","title":"Assignments &amp; Grading"},{"location":"syllabus/#final-project","text":"The final project will synthesize the skills learned throughout the course. Students will: - Propose a project idea by Week 9. - Develop a prototype by Week 13. - Submit the final project by December 8. Requirements: - Multiple well-designed visualizations with an accompanying narrative. - At least one map or ML/NLP visualization. - Accessibility considerations (color choice, labeling, alt text). - A reproducible Jupyter Notebook and any necessary datasets or data sources. Projects will be graded on clarity, creativity, technical proficiency, and adherence to visualization best practices.","title":"Final Project"},{"location":"syllabus/#university-policies","text":"Academic Integrity Code Academic integrity is an essential part of the educational process, and all members of the GW community take these matters very seriously. As the instructor of record for this course, my role is to provide clear expectations and uphold them in all assessments. Violations of academic integrity occur when students fail to cite research sources properly, engage in unauthorized collaboration, falsify data, and otherwise violate the Code of Academic Integrity. If you have any questions about whether particular academic practices or resources are permitted, you should ask me for clarification. If you are reported for an academic integrity violation, you should contact Conflict Education and Student Accountability (CESA) to learn more about your rights and options. Consequences can range from failure of assignment to expulsion from the University and may include a transcript notation. More info: students.gwu.edu/code-academic-integrity or cesa@gwu.edu. University policy on observance of religious holidays Students must notify faculty during the first week of the semester, or as early as possible, but no later than three weeks prior to the absence, of their intention to be absent for religious observance. See details at provost.gwu.edu/policies-procedures-and-guidelines . Use of Electronic Course Materials and Class Recordings Students are encouraged to use electronic course materials for private personal use in connection with their academic program of study. These materials should not be shared or used for non-course related purposes unless express permission is granted by the instructor.","title":"University Policies"},{"location":"syllabus/#academic-support","text":"Academic Commons Academic Commons is the central location for academic support resources for GW students. To schedule a peer tutoring session for a variety of courses visit go.gwu.edu/tutoring . Visit academiccommons.gwu.edu for study skills tips, finding help with research, and connecting with other campus resources. For questions email academiccommons@gwu.edu. GW Writing Center GW Writing Center cultivates confident writers in the University community by facilitating collaborative, critical, and inclusive conversations at all stages of the writing process. Working alongside peer mentors, writers develop strategies to write independently in academic and public settings. Appointments can be booked online at gwu.mywconline.com . Disability Support Services (DSS) Any student who may need an accommodation based on the potential impact of a disability should contact Disability Support Services at disabilitysupport.gwu.edu to establish eligibility and coordinate reasonable accommodations. Student Health Center The Student Health Center (SHC) offers medical, counseling/psychological, and psychiatric services to GW students. More information about the SHC is available at healthcenter.gwu.edu . Students experiencing a medical or mental health emergency on campus should contact GW Emergency Services at 202-994-6111, or off campus at 911.","title":"Academic Support"},{"location":"syllabus/#gw-campus-emergency-information","text":"GW Emergency Services : 202-994-6111 For situation-specific instructions, refer to GW\u2019s Emergency Procedures guide. GW Alert GW Alert is an emergency notification system that sends alerts to the GW community. GW requests students, faculty, and staff maintain current contact information by logging on to alert.gwu.edu . Alerts are sent via email, text, social media, and other means, including the Guardian app. Protective Actions GW prescribes four protective actions that can be issued by university officials depending on the type of emergency. All GW community members are expected to follow directions according to the specified protective action: Shelter, Evacuate, Secure, and Lockdown. Learn more at safety.gwu.edu/gw-standard-emergency-statuses .","title":"GW Campus Emergency Information"},{"location":"ds/data_sources_module/","text":"Data Sources (Weeks 1\u20134) This module provides a consolidated list of recommended data sources from Weeks 1\u20134. Students are encouraged to explore these datasets for hands-on exercises, projects, and further exploration in data visualization. Week 1 \u2013 Introduction to Data Visualization Gapminder Data : Global socio-economic and health indicators over time. Our World in Data : Extensive datasets on global development, environment, health, and society. Week 2 \u2013 Visual Encodings and Principles FiveThirtyEight Datasets : Curated datasets behind FiveThirtyEight\u2019s data journalism articles. UN Data : Official UN datasets on demographics, economics, and development. Week 3 \u2013 Distributions and Comparisons Iris Dataset (UCI ML Repository) : Classic dataset of flower measurements, widely used for visualization demos. Airline Flight Delay Data (Synthetic Example) : U.S. Bureau of Transportation Statistics flight data, often used for delay analysis. Week 4 \u2013 Data Wrangling and Joins TidyTuesday Datasets : Weekly datasets for data wrangling and visualization practice. U.S. Census Data : Demographic, housing, and economic data from the U.S. Census Bureau. Additional References ColorBrewer 2.0 : Color palette selection tool, including colorblind-friendly options. Real Python: ggplot in Python : Tutorial on the grammar of graphics approach in Python.","title":"Data Sources (Weeks 1\u20134)"},{"location":"ds/data_sources_module/#data-sources-weeks-14","text":"This module provides a consolidated list of recommended data sources from Weeks 1\u20134. Students are encouraged to explore these datasets for hands-on exercises, projects, and further exploration in data visualization.","title":"Data Sources (Weeks 1\u20134)"},{"location":"ds/data_sources_module/#week-1-introduction-to-data-visualization","text":"Gapminder Data : Global socio-economic and health indicators over time. Our World in Data : Extensive datasets on global development, environment, health, and society.","title":"Week 1 \u2013 Introduction to Data Visualization"},{"location":"ds/data_sources_module/#week-2-visual-encodings-and-principles","text":"FiveThirtyEight Datasets : Curated datasets behind FiveThirtyEight\u2019s data journalism articles. UN Data : Official UN datasets on demographics, economics, and development.","title":"Week 2 \u2013 Visual Encodings and Principles"},{"location":"ds/data_sources_module/#week-3-distributions-and-comparisons","text":"Iris Dataset (UCI ML Repository) : Classic dataset of flower measurements, widely used for visualization demos. Airline Flight Delay Data (Synthetic Example) : U.S. Bureau of Transportation Statistics flight data, often used for delay analysis.","title":"Week 3 \u2013 Distributions and Comparisons"},{"location":"ds/data_sources_module/#week-4-data-wrangling-and-joins","text":"TidyTuesday Datasets : Weekly datasets for data wrangling and visualization practice. U.S. Census Data : Demographic, housing, and economic data from the U.S. Census Bureau.","title":"Week 4 \u2013 Data Wrangling and Joins"},{"location":"ds/data_sources_module/#additional-references","text":"ColorBrewer 2.0 : Color palette selection tool, including colorblind-friendly options. Real Python: ggplot in Python : Tutorial on the grammar of graphics approach in Python.","title":"Additional References"},{"location":"weekly/mid_term_project/","text":"Mid-Term Project \u2014 DATS 2102: Data Visualization for Data Science A project assignment for the first half of the course (Weeks 1\u20136). \ud83c\udfaf Objectives By mid-semester, you will: Apply foundational data visualization techniques (Weeks 1\u20136). Demonstrate mastery of: environment setup & reproducible notebooks, tidy data principles & visual encodings, distributions & variation, wrangling with pandas, perception-based design principles, fair and effective comparisons. Produce a mini data story using 2\u20133 datasets. \ud83d\udcd6 Project Description Select a real-world dataset (from provided sources or external datasets of interest). Using the tools and concepts learned in the first six weeks, create a narrative notebook that: Introduces the dataset and research question(s). Cleans, reshapes, and prepares the data for visualization, demonstrating core pandas wrangling: selection/filtering, sorting, grouping + aggregation, joins/merges, and tidy reshaping. Produces at least 6\u20138 visualizations , including: At least one distribution plot (histogram/KDE/boxplot/ECDF). At least one comparison plot (dot plot, slope chart, or small multiples). At least one of your own visualizations revised and improved by reflecting on perception principles , showing how thoughtful design choices enhance clarity and fairness. At least one visualization with clear text/labels/annotations . Applies best practices for choice of color, scales, and labeling . Provides a written narrative explaining insights, choices, and design considerations. \ud83d\udce6 Deliverables Jupyter Notebook with all code, markdown explanations, and charts. Rendered HTML file (via Quarto). A short reflective essay (300\u2013500 words) addressing: What challenges did you face in cleaning/visualizing the data? How did perception/design principles guide your choices? Which visualization best communicates your main insight, and why? \ud83d\udcca Suggested Datasets Seaborn sample datasets Gapminder Our World in Data Open Data DC FiveThirtyEight Data \ud83d\uddd3\ufe0f Timeline Final Submission (Deadline: October 26): Completed notebook, HTML export, and reflection. \ud83e\uddfe Grading Rubric (20 pts total) Data Wrangling & Preparation (4 pts): Appropriate cleaning, filtering, and reshaping. Variety of Visualizations (5 pts): Includes required chart types; demonstrates range. Application of Principles (4 pts): Perception, scales, baselines, labeling. Narrative & Reflection (4 pts): Clear storyline; thoughtful discussion of design choices. Technical Quality (3 pts): The notebook runs cleanly, is reproducible, and is well-organized. \u2705 Submission Checklist Before submitting, make sure: -","title":"Mid-Term Project \u2014 DATS 2102: Data Visualization for Data Science"},{"location":"weekly/mid_term_project/#mid-term-project-dats-2102-data-visualization-for-data-science","text":"A project assignment for the first half of the course (Weeks 1\u20136).","title":"Mid-Term Project \u2014 DATS 2102: Data Visualization for Data Science"},{"location":"weekly/mid_term_project/#objectives","text":"By mid-semester, you will: Apply foundational data visualization techniques (Weeks 1\u20136). Demonstrate mastery of: environment setup & reproducible notebooks, tidy data principles & visual encodings, distributions & variation, wrangling with pandas, perception-based design principles, fair and effective comparisons. Produce a mini data story using 2\u20133 datasets.","title":"\ud83c\udfaf Objectives"},{"location":"weekly/mid_term_project/#project-description","text":"Select a real-world dataset (from provided sources or external datasets of interest). Using the tools and concepts learned in the first six weeks, create a narrative notebook that: Introduces the dataset and research question(s). Cleans, reshapes, and prepares the data for visualization, demonstrating core pandas wrangling: selection/filtering, sorting, grouping + aggregation, joins/merges, and tidy reshaping. Produces at least 6\u20138 visualizations , including: At least one distribution plot (histogram/KDE/boxplot/ECDF). At least one comparison plot (dot plot, slope chart, or small multiples). At least one of your own visualizations revised and improved by reflecting on perception principles , showing how thoughtful design choices enhance clarity and fairness. At least one visualization with clear text/labels/annotations . Applies best practices for choice of color, scales, and labeling . Provides a written narrative explaining insights, choices, and design considerations.","title":"\ud83d\udcd6 Project Description"},{"location":"weekly/mid_term_project/#deliverables","text":"Jupyter Notebook with all code, markdown explanations, and charts. Rendered HTML file (via Quarto). A short reflective essay (300\u2013500 words) addressing: What challenges did you face in cleaning/visualizing the data? How did perception/design principles guide your choices? Which visualization best communicates your main insight, and why?","title":"\ud83d\udce6 Deliverables"},{"location":"weekly/mid_term_project/#suggested-datasets","text":"Seaborn sample datasets Gapminder Our World in Data Open Data DC FiveThirtyEight Data","title":"\ud83d\udcca Suggested Datasets"},{"location":"weekly/mid_term_project/#timeline","text":"Final Submission (Deadline: October 26): Completed notebook, HTML export, and reflection.","title":"\ud83d\uddd3\ufe0f Timeline"},{"location":"weekly/mid_term_project/#grading-rubric-20-pts-total","text":"Data Wrangling & Preparation (4 pts): Appropriate cleaning, filtering, and reshaping. Variety of Visualizations (5 pts): Includes required chart types; demonstrates range. Application of Principles (4 pts): Perception, scales, baselines, labeling. Narrative & Reflection (4 pts): Clear storyline; thoughtful discussion of design choices. Technical Quality (3 pts): The notebook runs cleanly, is reproducible, and is well-organized.","title":"\ud83e\uddfe Grading Rubric (20 pts total)"},{"location":"weekly/mid_term_project/#submission-checklist","text":"Before submitting, make sure: -","title":"\u2705 Submission Checklist"},{"location":"weekly/module_week_10_relationships_modeling/","text":"Week 10 \u2014 Relationships & Modeling Visualizing relationships, correlations, and model fits to understand data patterns and predictive insights. \ud83d\udcd6 Background & Motivation Beyond distributions and comparisons, data visualization can help us understand relationships between variables and evaluate model performance . This week introduces how to visualize bivariate relationships, regression fits, residuals, and uncertainty, providing the foundation for interpreting linear and non\u2011linear trends. Students will learn how to use scatterplots, trend lines, confidence intervals, and diagnostic plots to explore patterns and assess model fit, combining statistical modeling with visual storytelling. \ud83d\udd0e Learning Objectives Create scatterplots to explore relationships between two or more variables. Visualize regression lines and confidence intervals. Understand correlation vs. causation and potential pitfalls. Evaluate model residuals visually to check fit and assumptions. Communicate model performance and uncertainty through effective visualization. \ud83d\udcda Readings & Resources Fundamentals of Data Visualization \u2014 chapters on relationships & uncertainty. Seaborn: regplot and lmplot Statsmodels: OLS Regression Visualizing Statistical Models Sample Data Sources: Penguins dataset (bill length vs. flipper length) Housing price dataset (price vs. area) Gapminder (GDP vs. life expectancy) \ud83d\udee0\ufe0f Setup Checklist Ensure your environment includes: pip install seaborn matplotlib statsmodels pandas numpy Confirm you can run regression visualizations and calculate correlations using Seaborn and Statsmodels. \ud83e\udded Lecture Outline Session 1 (75 min \u2014 Theory Focus) Understanding relationships: correlation vs. causation (10 min) Scatterplots and trend lines \u2014 visualizing associations (15 min) Simple regression and confidence intervals (20 min) Interpreting model fit and residuals visually (20 min) Visual pitfalls: spurious correlation, overfitting, and omitted variables (10 min) Download the Jupyter Notebook Session 2 (75 min \u2014 Hands-on Focus) Creating scatterplots with regression fits in Seaborn (20 min) Adding confidence intervals and customizing aesthetics (15 min) Building an OLS regression model with Statsmodels (20 min) Visualizing residuals and diagnostic plots (15 min) Mini\u2011workshop: interpret one key relationship in your dataset (5 min) Download the Jupyter Notebook A Working version of linked plotly plot can be downloaded here \ud83d\udcbb Starter Notebook Snippets Scatterplot with regression fit import seaborn as sns import matplotlib.pyplot as plt penguins = sns.load_dataset(\"penguins\").dropna() sns.lmplot(data=penguins, x=\"flipper_length_mm\", y=\"body_mass_g\", hue=\"species\", height=5, aspect=1.2) plt.title(\"Flipper length vs Body mass with regression line\") plt.show() Correlation matrix heatmap import pandas as pd corr = penguins.select_dtypes('number').corr() sns.heatmap(corr, annot=True, cmap='coolwarm', center=0) plt.title(\"Correlation matrix of numeric features\") plt.show() Residual plot sns.residplot(data=penguins, x=\"flipper_length_mm\", y=\"body_mass_g\", lowess=True, color=\"#4e79a7\") plt.title(\"Residual plot: checking nonlinearity\") plt.show() Regression with Statsmodels import statsmodels.api as sm X = penguins[[\"flipper_length_mm\"]] y = penguins[\"body_mass_g\"] X = sm.add_constant(X) model = sm.OLS(y, X).fit() print(model.summary()) # Add predictions and visualize penguins['pred'] = model.predict(X) plt.scatter(penguins['flipper_length_mm'], y, label='Observed') plt.plot(penguins['flipper_length_mm'], penguins['pred'], color='red', label='Fitted line') plt.legend() plt.title(\"OLS Regression Fit\") plt.show() \ud83e\uddea In-Class Activity Create scatterplots for multiple variable pairs and interpret patterns. Build a simple regression model and visualize fit and residuals. Discuss what model visualization reveals beyond summary statistics. Explore an example of spurious correlation and discuss implications. \ud83c\udfe0 Homework (Due next Thursday, Nov 6) Select a dataset of your choice (or continue from a previous week). Produce the following: One scatterplot with regression fit and confidence interval. One correlation matrix heatmap . One residual plot illustrating model fit or deviation. Include a brief interpretation (200\u2013300 words) explaining: What relationships you observed. How visualization helped confirm or question your assumptions. Submit .ipynb and .html . Rubric (10 pts) Correct implementation of regression and correlation plots (4) Quality of interpretation and insights (3) Clarity of visualizations and labeling (2) Code reproducibility and documentation (1) \ud83e\udde9 Optional Extensions Add multiple regression and visualize partial effects. Compare linear vs. non-linear fits. Visualize prediction intervals and uncertainty bands. Explore pairplots for multivariate relationships. \u2705 Submission Checklist Before submitting, make sure: Your assignment has fulfilled all the basic requirements listed above. Use Quarto to render the notebook into HTML and zip the files for submission. Double-check the visualizations and your reflections in the HTML are properly organized and displayed.","title":"Week 10 \u2014 Relationships &amp; Modeling"},{"location":"weekly/module_week_10_relationships_modeling/#week-10-relationships-modeling","text":"Visualizing relationships, correlations, and model fits to understand data patterns and predictive insights.","title":"Week 10 \u2014 Relationships &amp; Modeling"},{"location":"weekly/module_week_10_relationships_modeling/#background-motivation","text":"Beyond distributions and comparisons, data visualization can help us understand relationships between variables and evaluate model performance . This week introduces how to visualize bivariate relationships, regression fits, residuals, and uncertainty, providing the foundation for interpreting linear and non\u2011linear trends. Students will learn how to use scatterplots, trend lines, confidence intervals, and diagnostic plots to explore patterns and assess model fit, combining statistical modeling with visual storytelling.","title":"\ud83d\udcd6 Background &amp; Motivation"},{"location":"weekly/module_week_10_relationships_modeling/#learning-objectives","text":"Create scatterplots to explore relationships between two or more variables. Visualize regression lines and confidence intervals. Understand correlation vs. causation and potential pitfalls. Evaluate model residuals visually to check fit and assumptions. Communicate model performance and uncertainty through effective visualization.","title":"\ud83d\udd0e Learning Objectives"},{"location":"weekly/module_week_10_relationships_modeling/#readings-resources","text":"Fundamentals of Data Visualization \u2014 chapters on relationships & uncertainty. Seaborn: regplot and lmplot Statsmodels: OLS Regression Visualizing Statistical Models Sample Data Sources: Penguins dataset (bill length vs. flipper length) Housing price dataset (price vs. area) Gapminder (GDP vs. life expectancy)","title":"\ud83d\udcda Readings &amp; Resources"},{"location":"weekly/module_week_10_relationships_modeling/#setup-checklist","text":"Ensure your environment includes: pip install seaborn matplotlib statsmodels pandas numpy Confirm you can run regression visualizations and calculate correlations using Seaborn and Statsmodels.","title":"\ud83d\udee0\ufe0f Setup Checklist"},{"location":"weekly/module_week_10_relationships_modeling/#lecture-outline","text":"","title":"\ud83e\udded Lecture Outline"},{"location":"weekly/module_week_10_relationships_modeling/#session-1-75-min-theory-focus","text":"Understanding relationships: correlation vs. causation (10 min) Scatterplots and trend lines \u2014 visualizing associations (15 min) Simple regression and confidence intervals (20 min) Interpreting model fit and residuals visually (20 min) Visual pitfalls: spurious correlation, overfitting, and omitted variables (10 min) Download the Jupyter Notebook","title":"Session 1 (75 min \u2014 Theory Focus)"},{"location":"weekly/module_week_10_relationships_modeling/#session-2-75-min-hands-on-focus","text":"Creating scatterplots with regression fits in Seaborn (20 min) Adding confidence intervals and customizing aesthetics (15 min) Building an OLS regression model with Statsmodels (20 min) Visualizing residuals and diagnostic plots (15 min) Mini\u2011workshop: interpret one key relationship in your dataset (5 min) Download the Jupyter Notebook A Working version of linked plotly plot can be downloaded here","title":"Session 2 (75 min \u2014 Hands-on Focus)"},{"location":"weekly/module_week_10_relationships_modeling/#starter-notebook-snippets","text":"","title":"\ud83d\udcbb Starter Notebook Snippets"},{"location":"weekly/module_week_10_relationships_modeling/#scatterplot-with-regression-fit","text":"import seaborn as sns import matplotlib.pyplot as plt penguins = sns.load_dataset(\"penguins\").dropna() sns.lmplot(data=penguins, x=\"flipper_length_mm\", y=\"body_mass_g\", hue=\"species\", height=5, aspect=1.2) plt.title(\"Flipper length vs Body mass with regression line\") plt.show()","title":"Scatterplot with regression fit"},{"location":"weekly/module_week_10_relationships_modeling/#correlation-matrix-heatmap","text":"import pandas as pd corr = penguins.select_dtypes('number').corr() sns.heatmap(corr, annot=True, cmap='coolwarm', center=0) plt.title(\"Correlation matrix of numeric features\") plt.show()","title":"Correlation matrix heatmap"},{"location":"weekly/module_week_10_relationships_modeling/#residual-plot","text":"sns.residplot(data=penguins, x=\"flipper_length_mm\", y=\"body_mass_g\", lowess=True, color=\"#4e79a7\") plt.title(\"Residual plot: checking nonlinearity\") plt.show()","title":"Residual plot"},{"location":"weekly/module_week_10_relationships_modeling/#regression-with-statsmodels","text":"import statsmodels.api as sm X = penguins[[\"flipper_length_mm\"]] y = penguins[\"body_mass_g\"] X = sm.add_constant(X) model = sm.OLS(y, X).fit() print(model.summary()) # Add predictions and visualize penguins['pred'] = model.predict(X) plt.scatter(penguins['flipper_length_mm'], y, label='Observed') plt.plot(penguins['flipper_length_mm'], penguins['pred'], color='red', label='Fitted line') plt.legend() plt.title(\"OLS Regression Fit\") plt.show()","title":"Regression with Statsmodels"},{"location":"weekly/module_week_10_relationships_modeling/#in-class-activity","text":"Create scatterplots for multiple variable pairs and interpret patterns. Build a simple regression model and visualize fit and residuals. Discuss what model visualization reveals beyond summary statistics. Explore an example of spurious correlation and discuss implications.","title":"\ud83e\uddea In-Class Activity"},{"location":"weekly/module_week_10_relationships_modeling/#homework-due-next-thursday-nov-6","text":"Select a dataset of your choice (or continue from a previous week). Produce the following: One scatterplot with regression fit and confidence interval. One correlation matrix heatmap . One residual plot illustrating model fit or deviation. Include a brief interpretation (200\u2013300 words) explaining: What relationships you observed. How visualization helped confirm or question your assumptions. Submit .ipynb and .html . Rubric (10 pts) Correct implementation of regression and correlation plots (4) Quality of interpretation and insights (3) Clarity of visualizations and labeling (2) Code reproducibility and documentation (1)","title":"\ud83c\udfe0 Homework (Due next Thursday, Nov 6)"},{"location":"weekly/module_week_10_relationships_modeling/#optional-extensions","text":"Add multiple regression and visualize partial effects. Compare linear vs. non-linear fits. Visualize prediction intervals and uncertainty bands. Explore pairplots for multivariate relationships.","title":"\ud83e\udde9 Optional Extensions"},{"location":"weekly/module_week_10_relationships_modeling/#submission-checklist","text":"Before submitting, make sure: Your assignment has fulfilled all the basic requirements listed above. Use Quarto to render the notebook into HTML and zip the files for submission. Double-check the visualizations and your reflections in the HTML are properly organized and displayed.","title":"\u2705 Submission Checklist"},{"location":"weekly/module_week_11_uncertainty_error_visualization/","text":"Week 11 \u2014 Uncertainty & Error Visualization Communicating uncertainty, variability, and confidence through effective visual representations. \ud83d\udcd6 Background & Motivation Data visualizations often emphasize what is known\u2014but communicating what is uncertain is equally critical for honest and transparent storytelling. This week explores how to represent statistical uncertainty, variability, and measurement error using visual design. Students will learn how to use error bars, confidence bands, sampling distributions, and bootstrap visualizations to convey uncertainty clearly and responsibly. \ud83d\udd0e Learning Objectives Understand the sources of uncertainty in data and models. Differentiate between standard deviation, standard error, and confidence interval. Visualize uncertainty with error bars, ribbons, and confidence bands. Communicate uncertainty effectively without misleading interpretation. Apply resampling or bootstrapping methods for visual inference. \ud83d\udcda Readings & Resources Fundamentals of Data Visualization \u2014 Chapter on uncertainty. Why We Should Visualize Uncertainty (Nature) Seaborn confidence intervals documentation Visualizing Uncertainty (Information is Beautiful) Sample Data Sources: Simulated sample means and bootstraps Gapminder GDP data (yearly changes) Experimental datasets (e.g., survey or sensor data) \ud83d\udee0\ufe0f Setup Checklist Ensure your environment includes: pip install seaborn matplotlib numpy pandas scipy Verify that Seaborn is configured to display confidence intervals and that Matplotlib renders error bars correctly. \ud83e\udded Lecture Outline Session 1 (Theory Focus) What is uncertainty? Sources in data collection and modeling Standard deviation, standard error, and confidence intervals Visual metaphors for uncertainty (error bars, ribbons, shaded regions) Common pitfalls: false precision, overlapping intervals, and transparency Case studies: how media and research visualize uncertainty Session 2 (Hands-on Focus) Plotting error bars with Seaborn and Matplotlib Adding confidence bands around regression lines Simulating sampling distributions and bootstrap intervals Improve one of your previous plots by including uncertainty Download the hands-on Jupyter Notebook \ud83d\udcbb Starter Notebook Snippets Adding error bars import numpy as np import pandas as pd import matplotlib.pyplot as plt # Simulated means and standard errors groups = ['A','B','C','D'] means = [20, 23, 25, 22] se = [1.5, 2.0, 1.2, 1.8] plt.bar(groups, means, yerr=se, capsize=5, color='#4e79a7') plt.title('Bar chart with error bars') plt.ylabel('Mean value') plt.show() Confidence intervals with Seaborn import seaborn as sns penguins = sns.load_dataset('penguins').dropna() sns.lmplot(data=penguins, x='flipper_length_mm', y='body_mass_g', ci=95) plt.title('Regression with 95% confidence interval') plt.show() Bootstrap sampling visualization np.random.seed(42) data = np.random.normal(50, 10, 100) bootstrap_means = [np.mean(np.random.choice(data, size=100, replace=True)) for _ in range(1000)] sns.histplot(bootstrap_means, kde=True) plt.axvline(np.mean(data), color='red', linestyle='--', label='Observed mean') plt.title('Bootstrap sampling distribution of the mean') plt.legend() plt.show() \ud83e\uddea In-Class Activity Compare bar charts with and without error bars \u2014 what changes in interpretation? Explore how sample size affects confidence interval width. Visualize a bootstrap sampling distribution and discuss its meaning. Redesign a visualization from your earlier project to include uncertainty representation. \ud83c\udfe0 Homework (Due next Thursday, Nov 13) Select a dataset of your choice (or use one from a prior week). Produce: One bar or line chart with error bars or confidence bands. One bootstrap visualization or sampling distribution. A short (200\u2013300 words) reflection on how uncertainty affects the interpretation of your results. Submit .ipynb and .html . Rubric (10 pts) Correct calculation and visualization of uncertainty (4) Clarity and labeling of intervals/bands (2) Quality of interpretation and reflection (3) Reproducibility and documentation (1) \ud83e\udde9 Optional Extensions Compare 68%, 90%, and 95% confidence intervals visually. Add uncertainty bands to model predictions from Statsmodels. Visualize uncertainty in map-based data (e.g., population margins of error). \u2705 Submission Checklist Before submitting, make sure: Your assignment has fulfilled all the basic requirements listed above. Use Quarto to render the notebook into HTML and zip the files for submission. Double-check the visualizations and your reflections in the HTML are properly organized and displayed.","title":"Week 11 \u2014 Uncertainty &amp; Error Visualization"},{"location":"weekly/module_week_11_uncertainty_error_visualization/#week-11-uncertainty-error-visualization","text":"Communicating uncertainty, variability, and confidence through effective visual representations.","title":"Week 11 \u2014 Uncertainty &amp; Error Visualization"},{"location":"weekly/module_week_11_uncertainty_error_visualization/#background-motivation","text":"Data visualizations often emphasize what is known\u2014but communicating what is uncertain is equally critical for honest and transparent storytelling. This week explores how to represent statistical uncertainty, variability, and measurement error using visual design. Students will learn how to use error bars, confidence bands, sampling distributions, and bootstrap visualizations to convey uncertainty clearly and responsibly.","title":"\ud83d\udcd6 Background &amp; Motivation"},{"location":"weekly/module_week_11_uncertainty_error_visualization/#learning-objectives","text":"Understand the sources of uncertainty in data and models. Differentiate between standard deviation, standard error, and confidence interval. Visualize uncertainty with error bars, ribbons, and confidence bands. Communicate uncertainty effectively without misleading interpretation. Apply resampling or bootstrapping methods for visual inference.","title":"\ud83d\udd0e Learning Objectives"},{"location":"weekly/module_week_11_uncertainty_error_visualization/#readings-resources","text":"Fundamentals of Data Visualization \u2014 Chapter on uncertainty. Why We Should Visualize Uncertainty (Nature) Seaborn confidence intervals documentation Visualizing Uncertainty (Information is Beautiful) Sample Data Sources: Simulated sample means and bootstraps Gapminder GDP data (yearly changes) Experimental datasets (e.g., survey or sensor data)","title":"\ud83d\udcda Readings &amp; Resources"},{"location":"weekly/module_week_11_uncertainty_error_visualization/#setup-checklist","text":"Ensure your environment includes: pip install seaborn matplotlib numpy pandas scipy Verify that Seaborn is configured to display confidence intervals and that Matplotlib renders error bars correctly.","title":"\ud83d\udee0\ufe0f Setup Checklist"},{"location":"weekly/module_week_11_uncertainty_error_visualization/#lecture-outline","text":"","title":"\ud83e\udded Lecture Outline"},{"location":"weekly/module_week_11_uncertainty_error_visualization/#session-1-theory-focus","text":"What is uncertainty? Sources in data collection and modeling Standard deviation, standard error, and confidence intervals Visual metaphors for uncertainty (error bars, ribbons, shaded regions) Common pitfalls: false precision, overlapping intervals, and transparency Case studies: how media and research visualize uncertainty","title":"Session 1 (Theory Focus)"},{"location":"weekly/module_week_11_uncertainty_error_visualization/#session-2-hands-on-focus","text":"Plotting error bars with Seaborn and Matplotlib Adding confidence bands around regression lines Simulating sampling distributions and bootstrap intervals Improve one of your previous plots by including uncertainty Download the hands-on Jupyter Notebook","title":"Session 2 (Hands-on Focus)"},{"location":"weekly/module_week_11_uncertainty_error_visualization/#starter-notebook-snippets","text":"","title":"\ud83d\udcbb Starter Notebook Snippets"},{"location":"weekly/module_week_11_uncertainty_error_visualization/#adding-error-bars","text":"import numpy as np import pandas as pd import matplotlib.pyplot as plt # Simulated means and standard errors groups = ['A','B','C','D'] means = [20, 23, 25, 22] se = [1.5, 2.0, 1.2, 1.8] plt.bar(groups, means, yerr=se, capsize=5, color='#4e79a7') plt.title('Bar chart with error bars') plt.ylabel('Mean value') plt.show()","title":"Adding error bars"},{"location":"weekly/module_week_11_uncertainty_error_visualization/#confidence-intervals-with-seaborn","text":"import seaborn as sns penguins = sns.load_dataset('penguins').dropna() sns.lmplot(data=penguins, x='flipper_length_mm', y='body_mass_g', ci=95) plt.title('Regression with 95% confidence interval') plt.show()","title":"Confidence intervals with Seaborn"},{"location":"weekly/module_week_11_uncertainty_error_visualization/#bootstrap-sampling-visualization","text":"np.random.seed(42) data = np.random.normal(50, 10, 100) bootstrap_means = [np.mean(np.random.choice(data, size=100, replace=True)) for _ in range(1000)] sns.histplot(bootstrap_means, kde=True) plt.axvline(np.mean(data), color='red', linestyle='--', label='Observed mean') plt.title('Bootstrap sampling distribution of the mean') plt.legend() plt.show()","title":"Bootstrap sampling visualization"},{"location":"weekly/module_week_11_uncertainty_error_visualization/#in-class-activity","text":"Compare bar charts with and without error bars \u2014 what changes in interpretation? Explore how sample size affects confidence interval width. Visualize a bootstrap sampling distribution and discuss its meaning. Redesign a visualization from your earlier project to include uncertainty representation.","title":"\ud83e\uddea In-Class Activity"},{"location":"weekly/module_week_11_uncertainty_error_visualization/#homework-due-next-thursday-nov-13","text":"Select a dataset of your choice (or use one from a prior week). Produce: One bar or line chart with error bars or confidence bands. One bootstrap visualization or sampling distribution. A short (200\u2013300 words) reflection on how uncertainty affects the interpretation of your results. Submit .ipynb and .html . Rubric (10 pts) Correct calculation and visualization of uncertainty (4) Clarity and labeling of intervals/bands (2) Quality of interpretation and reflection (3) Reproducibility and documentation (1)","title":"\ud83c\udfe0 Homework (Due next Thursday, Nov 13)"},{"location":"weekly/module_week_11_uncertainty_error_visualization/#optional-extensions","text":"Compare 68%, 90%, and 95% confidence intervals visually. Add uncertainty bands to model predictions from Statsmodels. Visualize uncertainty in map-based data (e.g., population margins of error).","title":"\ud83e\udde9 Optional Extensions"},{"location":"weekly/module_week_11_uncertainty_error_visualization/#submission-checklist","text":"Before submitting, make sure: Your assignment has fulfilled all the basic requirements listed above. Use Quarto to render the notebook into HTML and zip the files for submission. Double-check the visualizations and your reflections in the HTML are properly organized and displayed.","title":"\u2705 Submission Checklist"},{"location":"weekly/module_week_12_viz_ml_nlp/","text":"Week 12 \u2014 Visualization for ML/NLP Visualizing machine learning and natural language processing outputs for interpretability and insight. \ud83d\udcd6 Background & Motivation Modern machine learning and NLP models generate complex outputs \u2014 from feature importances and prediction probabilities to topic clusters and embeddings. Visualization provides the bridge between model mechanics and human understanding. This week focuses on how to visualize model performance, interpret model decisions, and explore textual data patterns. \ud83d\udd0e Learning Objectives Plot feature importance for classification and regression models. Visualize model performance with confusion matrices and ROC curves. Use embeddings and clustering visualizations to interpret NLP models. Generate word clouds and topic cluster plots using BERTopic. Understand visualization's role in the ML workflow for interpretability and trust. \ud83d\udcda Readings & Resources Hands-On Machine Learning with Scikit-Learn & TensorFlow \u2014 chapters on model evaluation. scikit-learn: Model Evaluation & Visualization BERTopic: Topic Modeling & Visualization WordCloud: Python WordCloud Library Interpretable ML Book by Christoph Molnar Sample Datasets: IMDB Reviews (text sentiment classification) News Categories or 20 Newsgroups dataset Any scikit-learn classification dataset (e.g., iris, digits) \ud83d\udee0\ufe0f Setup Checklist Ensure your environment includes: pip install scikit-learn matplotlib seaborn wordcloud bertopic numpy pandas Confirm you can train a simple classifier, generate predictions, and render evaluation plots. \ud83e\udded Lecture Outline Session 1 (75 min \u2014 Theory Focus) Role of visualization in the ML workflow (10 min) Model interpretability and explainability (10 min) Feature importance and coefficient visualization (20 min) Model evaluation plots: confusion matrix, ROC curve, precision-recall (20 min) Discussion: visualization ethics and bias (15 min) Session 2 (75 min \u2014 Hands-on Focus) Train and evaluate a classifier (IMDB reviews or scikit-learn dataset) (20 min) Plot confusion matrix and ROC curve (20 min) Visualize feature importances or SHAP-like explanations (15 min) Generate word clouds and BERTopic clusters for NLP data (15 min) Mini-workshop: interpret model predictions visually (5 min) \ud83d\udcbb Starter Notebook Snippets Feature Importance Plot from sklearn.ensemble import RandomForestClassifier from sklearn.datasets import load_iris import pandas as pd import matplotlib.pyplot as plt X, y = load_iris(return_X_y=True, as_frame=True) model = RandomForestClassifier(random_state=42).fit(X, y) importances = pd.Series(model.feature_importances_, index=X.columns).sort_values() importances.plot(kind='barh', color='#4e79a7') plt.title('Feature Importance \u2014 Random Forest') plt.xlabel('Importance Score') plt.show() Confusion Matrix and ROC Curve from sklearn.metrics import ConfusionMatrixDisplay, RocCurveDisplay, classification_report from sklearn.model_selection import train_test_split X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42) model.fit(X_train, y_train) y_pred = model.predict(X_test) ConfusionMatrixDisplay.from_estimator(model, X_test, y_test) plt.title('Confusion Matrix') plt.show() RocCurveDisplay.from_estimator(model, X_test, y_test) plt.title('ROC Curve') plt.show() Word Cloud and Topic Clusters from wordcloud import WordCloud import matplotlib.pyplot as plt text = ' '.join(['great movie', 'terrible film', 'excellent acting', 'boring story']) wc = WordCloud(width=600, height=300, background_color='white').generate(text) plt.imshow(wc, interpolation='bilinear') plt.axis('off') plt.title('Example Word Cloud') plt.show() from bertopic import BERTopic from sklearn.datasets import fetch_20newsgroups newsgroups = fetch_20newsgroups(subset='all') docs = newsgroups.data[:200] model = BERTopic(verbose=True) topics, probs = model.fit_transform(docs) model.visualize_topics() \ud83e\uddea In-Class Activity Plot feature importance and discuss which features drive predictions. Evaluate model performance visually using confusion matrix and ROC curve. Generate a word cloud summarizing frequent terms from text data. Use BERTopic to visualize clusters of topics from IMDB reviews or news data. Discuss visual explainability: how do these visualizations build model trust? \ud83c\udfe0 Homework (Due Thursday, November 28) Choose either a structured dataset (classification/regression) or an NLP text dataset. Produce: One feature importance or coefficient plot. One model evaluation visualization (confusion matrix or ROC curve). One text visualization (word cloud or BERTopic topic cluster). Include a 200\u2013300 word reflection on how visualization supports model interpretability. Submit .ipynb and .html . Rubric (10 pts) Correct and complete implementation of model visualizations (4) Insightful reflection on interpretability and trust (3) Clarity and labeling of visuals (2) Code quality and reproducibility (1) \ud83e\udde9 Optional Extensions Explore SHAP or LIME visualizations for feature explanations. Create animated confusion matrices or topic evolution plots. Compare multiple models visually using ROC or precision-recall curves. \u2705 Submission Checklist Before submitting, make sure: -","title":"Week 12 \u2014 Visualization for ML/NLP"},{"location":"weekly/module_week_12_viz_ml_nlp/#week-12-visualization-for-mlnlp","text":"Visualizing machine learning and natural language processing outputs for interpretability and insight.","title":"Week 12 \u2014 Visualization for ML/NLP"},{"location":"weekly/module_week_12_viz_ml_nlp/#background-motivation","text":"Modern machine learning and NLP models generate complex outputs \u2014 from feature importances and prediction probabilities to topic clusters and embeddings. Visualization provides the bridge between model mechanics and human understanding. This week focuses on how to visualize model performance, interpret model decisions, and explore textual data patterns.","title":"\ud83d\udcd6 Background &amp; Motivation"},{"location":"weekly/module_week_12_viz_ml_nlp/#learning-objectives","text":"Plot feature importance for classification and regression models. Visualize model performance with confusion matrices and ROC curves. Use embeddings and clustering visualizations to interpret NLP models. Generate word clouds and topic cluster plots using BERTopic. Understand visualization's role in the ML workflow for interpretability and trust.","title":"\ud83d\udd0e Learning Objectives"},{"location":"weekly/module_week_12_viz_ml_nlp/#readings-resources","text":"Hands-On Machine Learning with Scikit-Learn & TensorFlow \u2014 chapters on model evaluation. scikit-learn: Model Evaluation & Visualization BERTopic: Topic Modeling & Visualization WordCloud: Python WordCloud Library Interpretable ML Book by Christoph Molnar Sample Datasets: IMDB Reviews (text sentiment classification) News Categories or 20 Newsgroups dataset Any scikit-learn classification dataset (e.g., iris, digits)","title":"\ud83d\udcda Readings &amp; Resources"},{"location":"weekly/module_week_12_viz_ml_nlp/#setup-checklist","text":"Ensure your environment includes: pip install scikit-learn matplotlib seaborn wordcloud bertopic numpy pandas Confirm you can train a simple classifier, generate predictions, and render evaluation plots.","title":"\ud83d\udee0\ufe0f Setup Checklist"},{"location":"weekly/module_week_12_viz_ml_nlp/#lecture-outline","text":"","title":"\ud83e\udded Lecture Outline"},{"location":"weekly/module_week_12_viz_ml_nlp/#session-1-75-min-theory-focus","text":"Role of visualization in the ML workflow (10 min) Model interpretability and explainability (10 min) Feature importance and coefficient visualization (20 min) Model evaluation plots: confusion matrix, ROC curve, precision-recall (20 min) Discussion: visualization ethics and bias (15 min)","title":"Session 1 (75 min \u2014 Theory Focus)"},{"location":"weekly/module_week_12_viz_ml_nlp/#session-2-75-min-hands-on-focus","text":"Train and evaluate a classifier (IMDB reviews or scikit-learn dataset) (20 min) Plot confusion matrix and ROC curve (20 min) Visualize feature importances or SHAP-like explanations (15 min) Generate word clouds and BERTopic clusters for NLP data (15 min) Mini-workshop: interpret model predictions visually (5 min)","title":"Session 2 (75 min \u2014 Hands-on Focus)"},{"location":"weekly/module_week_12_viz_ml_nlp/#starter-notebook-snippets","text":"","title":"\ud83d\udcbb Starter Notebook Snippets"},{"location":"weekly/module_week_12_viz_ml_nlp/#feature-importance-plot","text":"from sklearn.ensemble import RandomForestClassifier from sklearn.datasets import load_iris import pandas as pd import matplotlib.pyplot as plt X, y = load_iris(return_X_y=True, as_frame=True) model = RandomForestClassifier(random_state=42).fit(X, y) importances = pd.Series(model.feature_importances_, index=X.columns).sort_values() importances.plot(kind='barh', color='#4e79a7') plt.title('Feature Importance \u2014 Random Forest') plt.xlabel('Importance Score') plt.show()","title":"Feature Importance Plot"},{"location":"weekly/module_week_12_viz_ml_nlp/#confusion-matrix-and-roc-curve","text":"from sklearn.metrics import ConfusionMatrixDisplay, RocCurveDisplay, classification_report from sklearn.model_selection import train_test_split X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42) model.fit(X_train, y_train) y_pred = model.predict(X_test) ConfusionMatrixDisplay.from_estimator(model, X_test, y_test) plt.title('Confusion Matrix') plt.show() RocCurveDisplay.from_estimator(model, X_test, y_test) plt.title('ROC Curve') plt.show()","title":"Confusion Matrix and ROC Curve"},{"location":"weekly/module_week_12_viz_ml_nlp/#word-cloud-and-topic-clusters","text":"from wordcloud import WordCloud import matplotlib.pyplot as plt text = ' '.join(['great movie', 'terrible film', 'excellent acting', 'boring story']) wc = WordCloud(width=600, height=300, background_color='white').generate(text) plt.imshow(wc, interpolation='bilinear') plt.axis('off') plt.title('Example Word Cloud') plt.show() from bertopic import BERTopic from sklearn.datasets import fetch_20newsgroups newsgroups = fetch_20newsgroups(subset='all') docs = newsgroups.data[:200] model = BERTopic(verbose=True) topics, probs = model.fit_transform(docs) model.visualize_topics()","title":"Word Cloud and Topic Clusters"},{"location":"weekly/module_week_12_viz_ml_nlp/#in-class-activity","text":"Plot feature importance and discuss which features drive predictions. Evaluate model performance visually using confusion matrix and ROC curve. Generate a word cloud summarizing frequent terms from text data. Use BERTopic to visualize clusters of topics from IMDB reviews or news data. Discuss visual explainability: how do these visualizations build model trust?","title":"\ud83e\uddea In-Class Activity"},{"location":"weekly/module_week_12_viz_ml_nlp/#homework-due-thursday-november-28","text":"Choose either a structured dataset (classification/regression) or an NLP text dataset. Produce: One feature importance or coefficient plot. One model evaluation visualization (confusion matrix or ROC curve). One text visualization (word cloud or BERTopic topic cluster). Include a 200\u2013300 word reflection on how visualization supports model interpretability. Submit .ipynb and .html . Rubric (10 pts) Correct and complete implementation of model visualizations (4) Insightful reflection on interpretability and trust (3) Clarity and labeling of visuals (2) Code quality and reproducibility (1)","title":"\ud83c\udfe0 Homework (Due Thursday, November 28)"},{"location":"weekly/module_week_12_viz_ml_nlp/#optional-extensions","text":"Explore SHAP or LIME visualizations for feature explanations. Create animated confusion matrices or topic evolution plots. Compare multiple models visually using ROC or precision-recall curves.","title":"\ud83e\udde9 Optional Extensions"},{"location":"weekly/module_week_12_viz_ml_nlp/#submission-checklist","text":"Before submitting, make sure: -","title":"\u2705 Submission Checklist"},{"location":"weekly/module_week_1_getting_started/","text":"Week 1 \u2014 Getting Started A Quarto/Panel-style module page for DATS 2102, implemented in Python/Jupyter. \ud83d\udcd6 Background & Motivation Data visualization is the bridge between raw data and human understanding. In data science, visualizations are not just decorative \u2014 they are powerful analytical tools that help reveal patterns, outliers, and trends that might remain hidden in tables or statistical summaries. Well-designed visualizations can: Tell compelling, evidence-based stories that influence decision-making. Make complex concepts easier to grasp for diverse audiences. Identify and expose errors or inconsistencies in data during the exploratory stage. Enable collaboration between technical and non-technical stakeholders. Applications span across domains: Public health: Tracking disease spread with interactive dashboards. Climate science: Mapping temperature anomalies over decades. Business analytics: Visualizing customer behavior or sales performance. Machine learning: Understanding model performance through ROC curves, feature importance charts, or clustering visualizations. As data science projects grow in size and complexity, the ability to craft clear, truthful, and impactful visuals becomes as important as building the models themselves. \ud83d\udd0e Learning Objectives Set up a reliable Python environment for data visualization. Navigate Jupyter Notebook/Lab and basic notebook hygiene (headings, code vs. markdown, restart & run all). Load and inspect tabular data with pandas . Produce the first charts with matplotlib and seaborn . \ud83d\udcda Readings & Resources JupyterLab User Guide Python Tutorial Pandas Matplotlib Pyplot Seaborn Tutorials Sample Data Sources for Practice: Seaborn Built-in Datasets Kaggle Datasets FiveThirtyEight Data Our World in Data Open Data DC UCI Machine Learning Repository data.gov GeoPandas Sample Datasets Social Explorer \ud83d\udee0\ufe0f Setup Checklist Install Anaconda or Miniconda. Create/activate environment: bash conda create -n dataviz python=3.12 -y conda activate dataviz Install libraries (CPU-friendly baseline): bash pip install pandas numpy matplotlib seaborn plotly altair geopandas Launch JupyterLab : bash jupyter lab (Optional) IDEs you can use: VS Code, PyCharm, Sublime Text; or run in Google Colab. Troubleshooting If geopandas fails on Windows, try conda install -c conda-forge geopandas . If Jupyter can\u2019t see the env, run: python -m ipykernel install --user --name dataviz --display-name \"Python (dataviz)\" . \ud83e\udded Lecture Outline Session 1 (75 minutes) Course overview & syllabus tour (15 min) Why visualization in data science? (truthfulness, clarity, audience) (15 min) Environment setup: conda + Jupyter walkthrough, troubleshooting (30 min) First dataset in pandas : load CSV \u2192 DataFrame \u2192 quick EDA (15 min) Session 2 (75 minutes) Recap + Q&A on environment setup (10 min) Notebook workflow: cells, markdown, restart & run all, saving (20 min) Basic plotting: matplotlib bar/line; seaborn scatter/histogram (30 min) Guided practice with penguins dataset: scatterplot, pairplot activity (15 min) Sample data 1 ( customers_1000.csv ); Sample data 2 ( life_journey_data.csv ), Sample data 3 ( unemployment-x ) Check out the detailed instructions in a Notebook and download the week1_session2.ipynb \ud83d\udcbb Starter Notebook Snippets Load a tiny dataset ( download the tab-separated file (tsv) version ) import pandas as pd cities = pd.DataFrame({ \"city\": [\"DC\", \"NY\", \"LA\", \"Chicago\", \"Houston\"], \"population\": [712_816, 8_336_817, 3_898_747, 2_746_388, 2_304_580] }) cities.head() First charts (matplotlib \u2192 seaborn) import matplotlib.pyplot as plt import seaborn as sns # Matplotlib bar chart plt.bar(cities[\"city\"], cities[\"population\"]) plt.title(\"Population by City\") plt.xlabel(\"City\"); plt.ylabel(\"Population\") plt.show() # Seaborn bar chart sns.barplot(data=cities, x=\"city\", y=\"population\") plt.title(\"Population by City (Seaborn)\") plt.show() Quick EDA helpers cities.describe(include=\"all\") print(\"Missing values by column:\\n\", cities.isna().sum()) \ud83e\uddea In-Class Activity Using seaborn.load_dataset(\"penguins\") : Make a scatterplot of flipper_length_mm vs body_mass_g colored by species . Add axis labels, a title, and a legend with a better title. Try a seaborn.pairplot to see relationships across multiple variables. Hints penguins = sns.load_dataset(\"penguins\").dropna() ax = sns.scatterplot(data=penguins, x=\"flipper_length_mm\", y=\"body_mass_g\", hue=\"species\") ax.set(title=\"Penguins: Flipper vs Body Mass\", xlabel=\"Flipper length (mm)\", ylabel=\"Body mass (g)\") \ud83c\udfe0 Homework (Due before Week 2) Set up your environment and confirm you can open/run notebooks. Import a CSV of your choice and submit one notebook that includes: A short markdown description of the dataset (source, what, who, when). Top 5 rows, .info() , and .describe() . One bar or histogram plot, and one scatter plot. A brief paragraph reflecting on one insight + one limitation of the data. Export notebook to HTML ( File \u2192 Save and Export Notebook As ) and upload both .ipynb and .html . Rubric (10 pts) Reproducible environment & clean notebook structure (2) Correct loading/inspection & basic EDA (3) Two charts with sensible labels/titles (3) Insight + limitation reflection (2) \ud83e\udde9 Optional Extensions Try the same chart in both matplotlib and seaborn ; note the pros/cons you observe. Install altair (a declarative statistical visualization library for Python, built on top of Vega-Lite, useful for creating interactive charts with minimal code) and create the same scatterplot with tooltips. If you\u2019re comfortable with maps, test your geopandas install ( geopandas.datasets.get_path('naturalearth_lowres') ). \u2705 Submission Checklist This section, for example, lists everything you should verify before submitting your work for Week 1.","title":"Week 1 \u2014 Getting Started"},{"location":"weekly/module_week_1_getting_started/#week-1-getting-started","text":"A Quarto/Panel-style module page for DATS 2102, implemented in Python/Jupyter.","title":"Week 1 \u2014 Getting Started"},{"location":"weekly/module_week_1_getting_started/#background-motivation","text":"Data visualization is the bridge between raw data and human understanding. In data science, visualizations are not just decorative \u2014 they are powerful analytical tools that help reveal patterns, outliers, and trends that might remain hidden in tables or statistical summaries. Well-designed visualizations can: Tell compelling, evidence-based stories that influence decision-making. Make complex concepts easier to grasp for diverse audiences. Identify and expose errors or inconsistencies in data during the exploratory stage. Enable collaboration between technical and non-technical stakeholders. Applications span across domains: Public health: Tracking disease spread with interactive dashboards. Climate science: Mapping temperature anomalies over decades. Business analytics: Visualizing customer behavior or sales performance. Machine learning: Understanding model performance through ROC curves, feature importance charts, or clustering visualizations. As data science projects grow in size and complexity, the ability to craft clear, truthful, and impactful visuals becomes as important as building the models themselves.","title":"\ud83d\udcd6 Background &amp; Motivation"},{"location":"weekly/module_week_1_getting_started/#learning-objectives","text":"Set up a reliable Python environment for data visualization. Navigate Jupyter Notebook/Lab and basic notebook hygiene (headings, code vs. markdown, restart & run all). Load and inspect tabular data with pandas . Produce the first charts with matplotlib and seaborn .","title":"\ud83d\udd0e Learning Objectives"},{"location":"weekly/module_week_1_getting_started/#readings-resources","text":"JupyterLab User Guide Python Tutorial Pandas Matplotlib Pyplot Seaborn Tutorials Sample Data Sources for Practice: Seaborn Built-in Datasets Kaggle Datasets FiveThirtyEight Data Our World in Data Open Data DC UCI Machine Learning Repository data.gov GeoPandas Sample Datasets Social Explorer","title":"\ud83d\udcda Readings &amp; Resources"},{"location":"weekly/module_week_1_getting_started/#setup-checklist","text":"Install Anaconda or Miniconda. Create/activate environment: bash conda create -n dataviz python=3.12 -y conda activate dataviz Install libraries (CPU-friendly baseline): bash pip install pandas numpy matplotlib seaborn plotly altair geopandas Launch JupyterLab : bash jupyter lab (Optional) IDEs you can use: VS Code, PyCharm, Sublime Text; or run in Google Colab. Troubleshooting If geopandas fails on Windows, try conda install -c conda-forge geopandas . If Jupyter can\u2019t see the env, run: python -m ipykernel install --user --name dataviz --display-name \"Python (dataviz)\" .","title":"\ud83d\udee0\ufe0f Setup Checklist"},{"location":"weekly/module_week_1_getting_started/#lecture-outline","text":"","title":"\ud83e\udded Lecture Outline"},{"location":"weekly/module_week_1_getting_started/#session-1-75-minutes","text":"Course overview & syllabus tour (15 min) Why visualization in data science? (truthfulness, clarity, audience) (15 min) Environment setup: conda + Jupyter walkthrough, troubleshooting (30 min) First dataset in pandas : load CSV \u2192 DataFrame \u2192 quick EDA (15 min)","title":"Session 1 (75 minutes)"},{"location":"weekly/module_week_1_getting_started/#session-2-75-minutes","text":"Recap + Q&A on environment setup (10 min) Notebook workflow: cells, markdown, restart & run all, saving (20 min) Basic plotting: matplotlib bar/line; seaborn scatter/histogram (30 min) Guided practice with penguins dataset: scatterplot, pairplot activity (15 min) Sample data 1 ( customers_1000.csv ); Sample data 2 ( life_journey_data.csv ), Sample data 3 ( unemployment-x ) Check out the detailed instructions in a Notebook and download the week1_session2.ipynb","title":"Session 2 (75 minutes)"},{"location":"weekly/module_week_1_getting_started/#starter-notebook-snippets","text":"","title":"\ud83d\udcbb Starter Notebook Snippets"},{"location":"weekly/module_week_1_getting_started/#load-a-tiny-dataset-download-the-tab-separated-file-tsv-version","text":"import pandas as pd cities = pd.DataFrame({ \"city\": [\"DC\", \"NY\", \"LA\", \"Chicago\", \"Houston\"], \"population\": [712_816, 8_336_817, 3_898_747, 2_746_388, 2_304_580] }) cities.head()","title":"Load a tiny dataset (download the tab-separated file (tsv) version)"},{"location":"weekly/module_week_1_getting_started/#first-charts-matplotlib-seaborn","text":"import matplotlib.pyplot as plt import seaborn as sns # Matplotlib bar chart plt.bar(cities[\"city\"], cities[\"population\"]) plt.title(\"Population by City\") plt.xlabel(\"City\"); plt.ylabel(\"Population\") plt.show() # Seaborn bar chart sns.barplot(data=cities, x=\"city\", y=\"population\") plt.title(\"Population by City (Seaborn)\") plt.show()","title":"First charts (matplotlib \u2192 seaborn)"},{"location":"weekly/module_week_1_getting_started/#quick-eda-helpers","text":"cities.describe(include=\"all\") print(\"Missing values by column:\\n\", cities.isna().sum())","title":"Quick EDA helpers"},{"location":"weekly/module_week_1_getting_started/#in-class-activity","text":"Using seaborn.load_dataset(\"penguins\") : Make a scatterplot of flipper_length_mm vs body_mass_g colored by species . Add axis labels, a title, and a legend with a better title. Try a seaborn.pairplot to see relationships across multiple variables. Hints penguins = sns.load_dataset(\"penguins\").dropna() ax = sns.scatterplot(data=penguins, x=\"flipper_length_mm\", y=\"body_mass_g\", hue=\"species\") ax.set(title=\"Penguins: Flipper vs Body Mass\", xlabel=\"Flipper length (mm)\", ylabel=\"Body mass (g)\")","title":"\ud83e\uddea In-Class Activity"},{"location":"weekly/module_week_1_getting_started/#homework-due-before-week-2","text":"Set up your environment and confirm you can open/run notebooks. Import a CSV of your choice and submit one notebook that includes: A short markdown description of the dataset (source, what, who, when). Top 5 rows, .info() , and .describe() . One bar or histogram plot, and one scatter plot. A brief paragraph reflecting on one insight + one limitation of the data. Export notebook to HTML ( File \u2192 Save and Export Notebook As ) and upload both .ipynb and .html . Rubric (10 pts) Reproducible environment & clean notebook structure (2) Correct loading/inspection & basic EDA (3) Two charts with sensible labels/titles (3) Insight + limitation reflection (2)","title":"\ud83c\udfe0 Homework (Due before Week 2)"},{"location":"weekly/module_week_1_getting_started/#optional-extensions","text":"Try the same chart in both matplotlib and seaborn ; note the pros/cons you observe. Install altair (a declarative statistical visualization library for Python, built on top of Vega-Lite, useful for creating interactive charts with minimal code) and create the same scatterplot with tooltips. If you\u2019re comfortable with maps, test your geopandas install ( geopandas.datasets.get_path('naturalearth_lowres') ).","title":"\ud83e\udde9 Optional Extensions"},{"location":"weekly/module_week_1_getting_started/#submission-checklist","text":"This section, for example, lists everything you should verify before submitting your work for Week 1.","title":"\u2705 Submission Checklist"},{"location":"weekly/module_week_2_language_of_graphs/","text":"Week 2 \u2014 Language of Graphs Understanding encodings, tidy data, and the grammar of graphics with Python. This module will deepen your ability to think critically about how information is mapped visually and how choices in data structure affect the clarity of your analysis. \ud83d\udcd6 Background & Motivation The \"language\" of data visualization comes from how we map variables to visual elements: position, shape, color, size, and scale. Mastering these encodings allows you to choose the right chart type and present information clearly. This week also introduces the concept of tidy data, a standard way of structuring datasets to facilitate easier analysis and visualization. Beyond technical correctness, understanding these principles ensures that your work communicates insights effectively. Choosing the right encoding is about audience, purpose, and the kind of story you want your data to tell. For example, using color to differentiate categories can make a chart intuitive, but overusing it can lead to confusion. Similarly, reshaping data into tidy form streamlines your workflow and makes your notebooks reproducible and easier to understand for others. The combined skill set of visual encodings and tidy data practices represents the foundation for nearly every visualization you will create later in the course. \ud83d\udd0e Learning Objectives Identify and apply core visual encodings (position, color, shape, size). Reshape datasets into tidy form for plotting. Create multi-encoding plots using seaborn and Altair\u2019s grammar of graphics. Critically evaluate when and why to use specific encodings. \ud83d\udcda Readings & Resources The Grammar of Graphics (Wilkinson) \u2014 conceptual foundation for how data maps to visuals. Seaborn Categorical Plots \u2014 useful introduction to encoding categorical variables. Altair Tutorials \u2014 practice with grammar of graphics in Python. Tidy Data by Hadley Wickham \u2014 essential reading for organizing datasets. ggplot-style Visualization in Python (Real Python) \u2014 practical tutorial for using ggplot concepts in Python. ColorBrewer2 \u2014 an interactive tool for choosing effective and accessible color schemes. Sample Data Sources for Practice: Seaborn Tips Dataset \u2014 classic dataset for learning encodings. Gapminder Data via Plotly Express \u2014 long-term country-level indicators. Our World in Data \u2014 a wide range of curated datasets. Gapminder \u2014 global development indicators with interactive visualization resources. \ud83d\udee0\ufe0f Setup Checklist Make sure your environment includes: pip install pandas numpy matplotlib seaborn altair plotly First make sure the virtual environment is properly created and activated. Then confirm you can import these libraries in a notebook and render a simple chart before class. \ud83e\udded Lecture Outline Session 1 (75 min \u2014 Theory Focus) Why tidy data matters in visualization workflows (10 min) Core visual encodings: position, shape, color, size, and scale, with conceptual discussion and examples from research/literature (25 min) Grammar of graphics overview: key ideas from Wilkinson and tidy data principles (20 min) Class discussion: When encodings clarify vs. when they clutter (20 min) Session 2 (75 min \u2014 Hands-on Focus) Seaborn\u2019s approach to categorical vs. continuous data with live coding (20 min) Altair grammar of graphics in Python with interactive demos (25 min) Guided exercise: create multiple encodings in one chart, reflect on readability (20 min) Workshop and Q&A: applying tidy reshaping and encodings to provided datasets (10 min) You can refer to the Web page and download the Jupyter Notebook \ud83d\udcbb Notebook Snippets Load example dataset import seaborn as sns import pandas as pd # Load tips dataset tips = sns.load_dataset(\"tips\") tips.head() Seaborn scatterplot with multiple encodings sns.scatterplot( data=tips, x=\"total_bill\", y=\"tip\", hue=\"day\", style=\"time\", size=\"size\", palette=\"deep\", sizes=(20, 200) ) Tidy data example # Pivot from wide to long (tidy) df_wide = pd.DataFrame({ 'name': ['Alice', 'Bob'], 'math': [90, 80], 'english': [85, 78] }) df_tidy = df_wide.melt(id_vars='name', var_name='subject', value_name='score') Altair example import altair as alt alt.Chart(tips).mark_point().encode( x='total_bill', y='tip', color='day', shape='time', size='size' ) \ud83e\uddea In-Class Activity Using the gapminder dataset (via plotly.express.data.gapminder() ), create: A scatterplot of GDP per capita vs. life expectancy. Encode continent as color and year as an animation frame. Discuss: What does each encoding reveal? Which encoding is most effective at showing inequality? How does animation enhance or hinder interpretation? Hints import plotly.express as px gap = px.data.gapminder() px.scatter( gap, x=\"gdpPercap\", y=\"lifeExp\", color=\"continent\", size=\"pop\", hover_name=\"country\", animation_frame=\"year\", log_x=True ) \ud83c\udfe0 Homework (Due next Thursday, Sept 11) Pick one dataset from the sample sources or bring your own. Create three different charts using at least three distinct encodings. For each chart, include: A brief description of what the chart shows. Why did you choose those encodings, and how did they help interpretation? One limitation or challenge in readability. Submit .ipynb and .html to Blackboard (You can zip the files together). Rubric (10 pts) Correct application of tidy data principles (2) Effective and varied use of encodings (4) Chart clarity, proper labeling, and interpretability (2) Justification of choices and discussion of limitations (2) \ud83e\udde9 Optional Extensions Use Altair to add interactive tooltips for deeper exploration. Compare the same visualization in Seaborn and Altair and note trade-offs. Explore plotly.express for creating interactive dashboards. Experiment with using two vs. three encodings in the same chart; evaluate which is clearer. \u2705 Submission Checklist Before submitting, make sure: Your assignment has fulfilled all the basic requirements listed above. The visualizations in the Notebook and HTML are well displayed.","title":"Week 2 \u2014 Language of Graphs"},{"location":"weekly/module_week_2_language_of_graphs/#week-2-language-of-graphs","text":"Understanding encodings, tidy data, and the grammar of graphics with Python. This module will deepen your ability to think critically about how information is mapped visually and how choices in data structure affect the clarity of your analysis.","title":"Week 2 \u2014 Language of Graphs"},{"location":"weekly/module_week_2_language_of_graphs/#background-motivation","text":"The \"language\" of data visualization comes from how we map variables to visual elements: position, shape, color, size, and scale. Mastering these encodings allows you to choose the right chart type and present information clearly. This week also introduces the concept of tidy data, a standard way of structuring datasets to facilitate easier analysis and visualization. Beyond technical correctness, understanding these principles ensures that your work communicates insights effectively. Choosing the right encoding is about audience, purpose, and the kind of story you want your data to tell. For example, using color to differentiate categories can make a chart intuitive, but overusing it can lead to confusion. Similarly, reshaping data into tidy form streamlines your workflow and makes your notebooks reproducible and easier to understand for others. The combined skill set of visual encodings and tidy data practices represents the foundation for nearly every visualization you will create later in the course.","title":"\ud83d\udcd6 Background &amp; Motivation"},{"location":"weekly/module_week_2_language_of_graphs/#learning-objectives","text":"Identify and apply core visual encodings (position, color, shape, size). Reshape datasets into tidy form for plotting. Create multi-encoding plots using seaborn and Altair\u2019s grammar of graphics. Critically evaluate when and why to use specific encodings.","title":"\ud83d\udd0e Learning Objectives"},{"location":"weekly/module_week_2_language_of_graphs/#readings-resources","text":"The Grammar of Graphics (Wilkinson) \u2014 conceptual foundation for how data maps to visuals. Seaborn Categorical Plots \u2014 useful introduction to encoding categorical variables. Altair Tutorials \u2014 practice with grammar of graphics in Python. Tidy Data by Hadley Wickham \u2014 essential reading for organizing datasets. ggplot-style Visualization in Python (Real Python) \u2014 practical tutorial for using ggplot concepts in Python. ColorBrewer2 \u2014 an interactive tool for choosing effective and accessible color schemes. Sample Data Sources for Practice: Seaborn Tips Dataset \u2014 classic dataset for learning encodings. Gapminder Data via Plotly Express \u2014 long-term country-level indicators. Our World in Data \u2014 a wide range of curated datasets. Gapminder \u2014 global development indicators with interactive visualization resources.","title":"\ud83d\udcda Readings &amp; Resources"},{"location":"weekly/module_week_2_language_of_graphs/#setup-checklist","text":"Make sure your environment includes: pip install pandas numpy matplotlib seaborn altair plotly First make sure the virtual environment is properly created and activated. Then confirm you can import these libraries in a notebook and render a simple chart before class.","title":"\ud83d\udee0\ufe0f Setup Checklist"},{"location":"weekly/module_week_2_language_of_graphs/#lecture-outline","text":"","title":"\ud83e\udded Lecture Outline"},{"location":"weekly/module_week_2_language_of_graphs/#session-1-75-min-theory-focus","text":"Why tidy data matters in visualization workflows (10 min) Core visual encodings: position, shape, color, size, and scale, with conceptual discussion and examples from research/literature (25 min) Grammar of graphics overview: key ideas from Wilkinson and tidy data principles (20 min) Class discussion: When encodings clarify vs. when they clutter (20 min)","title":"Session 1 (75 min \u2014 Theory Focus)"},{"location":"weekly/module_week_2_language_of_graphs/#session-2-75-min-hands-on-focus","text":"Seaborn\u2019s approach to categorical vs. continuous data with live coding (20 min) Altair grammar of graphics in Python with interactive demos (25 min) Guided exercise: create multiple encodings in one chart, reflect on readability (20 min) Workshop and Q&A: applying tidy reshaping and encodings to provided datasets (10 min)","title":"Session 2 (75 min \u2014 Hands-on Focus)"},{"location":"weekly/module_week_2_language_of_graphs/#you-can-refer-to-the-web-page-and-download-the-jupyter-notebook","text":"","title":"You can refer to the Web page and download the Jupyter Notebook"},{"location":"weekly/module_week_2_language_of_graphs/#notebook-snippets","text":"","title":"\ud83d\udcbb Notebook Snippets"},{"location":"weekly/module_week_2_language_of_graphs/#load-example-dataset","text":"import seaborn as sns import pandas as pd # Load tips dataset tips = sns.load_dataset(\"tips\") tips.head()","title":"Load example dataset"},{"location":"weekly/module_week_2_language_of_graphs/#seaborn-scatterplot-with-multiple-encodings","text":"sns.scatterplot( data=tips, x=\"total_bill\", y=\"tip\", hue=\"day\", style=\"time\", size=\"size\", palette=\"deep\", sizes=(20, 200) )","title":"Seaborn scatterplot with multiple encodings"},{"location":"weekly/module_week_2_language_of_graphs/#tidy-data-example","text":"# Pivot from wide to long (tidy) df_wide = pd.DataFrame({ 'name': ['Alice', 'Bob'], 'math': [90, 80], 'english': [85, 78] }) df_tidy = df_wide.melt(id_vars='name', var_name='subject', value_name='score')","title":"Tidy data example"},{"location":"weekly/module_week_2_language_of_graphs/#altair-example","text":"import altair as alt alt.Chart(tips).mark_point().encode( x='total_bill', y='tip', color='day', shape='time', size='size' )","title":"Altair example"},{"location":"weekly/module_week_2_language_of_graphs/#in-class-activity","text":"Using the gapminder dataset (via plotly.express.data.gapminder() ), create: A scatterplot of GDP per capita vs. life expectancy. Encode continent as color and year as an animation frame. Discuss: What does each encoding reveal? Which encoding is most effective at showing inequality? How does animation enhance or hinder interpretation? Hints import plotly.express as px gap = px.data.gapminder() px.scatter( gap, x=\"gdpPercap\", y=\"lifeExp\", color=\"continent\", size=\"pop\", hover_name=\"country\", animation_frame=\"year\", log_x=True )","title":"\ud83e\uddea In-Class Activity"},{"location":"weekly/module_week_2_language_of_graphs/#homework-due-next-thursday-sept-11","text":"Pick one dataset from the sample sources or bring your own. Create three different charts using at least three distinct encodings. For each chart, include: A brief description of what the chart shows. Why did you choose those encodings, and how did they help interpretation? One limitation or challenge in readability. Submit .ipynb and .html to Blackboard (You can zip the files together). Rubric (10 pts) Correct application of tidy data principles (2) Effective and varied use of encodings (4) Chart clarity, proper labeling, and interpretability (2) Justification of choices and discussion of limitations (2)","title":"\ud83c\udfe0 Homework (Due next Thursday, Sept 11)"},{"location":"weekly/module_week_2_language_of_graphs/#optional-extensions","text":"Use Altair to add interactive tooltips for deeper exploration. Compare the same visualization in Seaborn and Altair and note trade-offs. Explore plotly.express for creating interactive dashboards. Experiment with using two vs. three encodings in the same chart; evaluate which is clearer.","title":"\ud83e\udde9 Optional Extensions"},{"location":"weekly/module_week_2_language_of_graphs/#submission-checklist","text":"Before submitting, make sure: Your assignment has fulfilled all the basic requirements listed above. The visualizations in the Notebook and HTML are well displayed.","title":"\u2705 Submission Checklist"},{"location":"weekly/module_week_3_distributions_variation/","text":"Week 3 \u2014 Distributions & Variation Exploring distributions, variation, and choices in single-variable visualization. \ud83d\udcd6 Background & Motivation Understanding how data is distributed is the foundation of exploratory data analysis. Whether we want to know if flight delays cluster around certain times or if iris flower species differ in petal length, distribution plots reveal the shape, spread, and potential outliers. Poorly chosen or misinterpreted plots can obscure variation and mislead conclusions. Distributions are more than just \u201cshapes of data\u201d. They tell us about central tendency (where the bulk of data lies), spread (how much variation exists), skewness (whether data is lopsided), and outliers (values that are unusual or extreme). These insights form the basis for both descriptive statistics and inferential modeling. For data scientists, knowing how to visualize distributions effectively is an essential skill for diagnosing problems, preparing data, and communicating results. \ud83d\udd0e Learning Objectives Choose and interpret appropriate distribution plots. Apply binning strategies and kernel density estimation. Construct and read empirical cumulative distribution functions (ECDFs). Compare plots to understand spread, skewness, and outliers. Critically evaluate the strengths and weaknesses of each distribution visualization technique. \ud83d\udcda Readings & Resources Seaborn Distribution Plots \u2014 practical guide to histograms, KDEs, and more. Matplotlib Histograms \u2014 documentation for histogram basics. EDA Concepts \u2014 blog overview of exploratory data analysis. Fundamentals of Data Visualization \u2014 chapter on histograms and density plots. Sample Data Sources: Flight delay data (US DOT Bureau of Transportation Statistics) Iris dataset ( seaborn.load_dataset('iris') ) Titanic dataset (Kaggle / Seaborn) COVID-19 case data (Our World in Data) \ud83d\udee0\ufe0f Setup Checklist Ensure you can run: pip install seaborn matplotlib pandas Check that you can load the iris dataset and render a histogram before class. \ud83e\udded Lecture Outline Session 1 (75 min) Motivation: Why study distributions? Examples from real-world datasets (10 min) Histograms & binning choices: impact of bin width on interpretation (20 min) Kernel density estimation: intuition, bandwidth selection, pros/cons (25 min) Hands-on with iris dataset: plot histograms and KDEs for sepal/petal features (20 min) Session 2 (75 min) Recap & troubleshooting from Session 1 (10 min) Boxplots & violin plots: comparing categories and visualizing spread (25 min) ECDF: cumulative view of distributions, why it\u2019s useful (20 min) Workshop: students choose dataset, produce 2\u20133 distribution plots, peer feedback (20 min) You can refer to the Jupyter Notebook template \ud83d\udcbb Starter Notebook Snippets import seaborn as sns import matplotlib.pyplot as plt iris = sns.load_dataset('iris') # Histogram sns.histplot(iris['sepal_length'], bins=20, kde=False) # KDE sns.kdeplot(iris['sepal_length'], fill=True) # Boxplot by species sns.boxplot(data=iris, x='species', y='sepal_length') # ECDF def ecdf(data): x = np.sort(data) y = np.arange(1, len(x)+1) / len(x) return x, y import numpy as np x, y = ecdf(iris['sepal_length']) plt.plot(x, y, marker='.', linestyle='none') plt.xlabel('Sepal length') plt.ylabel('ECDF') \ud83e\uddea In-Class Activity Compare histogram vs. KDE of flight delay data. Which communicates central tendency more clearly? Which better shows multimodality? Plot boxplot of iris petal length by species. Discuss: how does this compare to histograms? Construct ECDFs for sepal width. What does it reveal about spread and skewness? Group work: each team selects a dataset and produces multiple distribution plots, then explains which is most effective. \ud83c\udfe0 Homework (Due next Thursday, Sept 18) Select two datasets (one provided + one of your choice). For each dataset: Produce at least 3 distribution plots (histogram, KDE, ECDF, box/violin). Interpret shape, spread, skew, and outliers in markdown. Reflect on the pros/cons of each visualization type. Add at least one annotated chart highlighting a key pattern. Submit .ipynb and .html as a zip file. Rubric (10 pts) Correct use of multiple plot types (4) Clear interpretation and discussion (3) Labeling, annotations, and readability (2) Reproducibility (1) \ud83e\udde9 Optional Extensions Experiment with different bin sizes in histograms and compare results. Overlay histogram and KDE to show complementarity. Use sns.pairplot to examine multiple distributions and correlations. Compare distributions across groups using facet plots. Try violin plots with split by category. \u2705 Submission Checklist Before submitting, make sure: Your assignment has fulfilled all the basic requirements listed above. The visualizations in the Notebook and HTML are well displayed.","title":"Week 3 \u2014 Distributions &amp; Variation"},{"location":"weekly/module_week_3_distributions_variation/#week-3-distributions-variation","text":"Exploring distributions, variation, and choices in single-variable visualization.","title":"Week 3 \u2014 Distributions &amp; Variation"},{"location":"weekly/module_week_3_distributions_variation/#background-motivation","text":"Understanding how data is distributed is the foundation of exploratory data analysis. Whether we want to know if flight delays cluster around certain times or if iris flower species differ in petal length, distribution plots reveal the shape, spread, and potential outliers. Poorly chosen or misinterpreted plots can obscure variation and mislead conclusions. Distributions are more than just \u201cshapes of data\u201d. They tell us about central tendency (where the bulk of data lies), spread (how much variation exists), skewness (whether data is lopsided), and outliers (values that are unusual or extreme). These insights form the basis for both descriptive statistics and inferential modeling. For data scientists, knowing how to visualize distributions effectively is an essential skill for diagnosing problems, preparing data, and communicating results.","title":"\ud83d\udcd6 Background &amp; Motivation"},{"location":"weekly/module_week_3_distributions_variation/#learning-objectives","text":"Choose and interpret appropriate distribution plots. Apply binning strategies and kernel density estimation. Construct and read empirical cumulative distribution functions (ECDFs). Compare plots to understand spread, skewness, and outliers. Critically evaluate the strengths and weaknesses of each distribution visualization technique.","title":"\ud83d\udd0e Learning Objectives"},{"location":"weekly/module_week_3_distributions_variation/#readings-resources","text":"Seaborn Distribution Plots \u2014 practical guide to histograms, KDEs, and more. Matplotlib Histograms \u2014 documentation for histogram basics. EDA Concepts \u2014 blog overview of exploratory data analysis. Fundamentals of Data Visualization \u2014 chapter on histograms and density plots. Sample Data Sources: Flight delay data (US DOT Bureau of Transportation Statistics) Iris dataset ( seaborn.load_dataset('iris') ) Titanic dataset (Kaggle / Seaborn) COVID-19 case data (Our World in Data)","title":"\ud83d\udcda Readings &amp; Resources"},{"location":"weekly/module_week_3_distributions_variation/#setup-checklist","text":"Ensure you can run: pip install seaborn matplotlib pandas Check that you can load the iris dataset and render a histogram before class.","title":"\ud83d\udee0\ufe0f Setup Checklist"},{"location":"weekly/module_week_3_distributions_variation/#lecture-outline","text":"","title":"\ud83e\udded Lecture Outline"},{"location":"weekly/module_week_3_distributions_variation/#session-1-75-min","text":"Motivation: Why study distributions? Examples from real-world datasets (10 min) Histograms & binning choices: impact of bin width on interpretation (20 min) Kernel density estimation: intuition, bandwidth selection, pros/cons (25 min) Hands-on with iris dataset: plot histograms and KDEs for sepal/petal features (20 min)","title":"Session 1 (75 min)"},{"location":"weekly/module_week_3_distributions_variation/#session-2-75-min","text":"Recap & troubleshooting from Session 1 (10 min) Boxplots & violin plots: comparing categories and visualizing spread (25 min) ECDF: cumulative view of distributions, why it\u2019s useful (20 min) Workshop: students choose dataset, produce 2\u20133 distribution plots, peer feedback (20 min)","title":"Session 2 (75 min)"},{"location":"weekly/module_week_3_distributions_variation/#you-can-refer-to-the-jupyter-notebook-template","text":"","title":"You can refer to the Jupyter Notebook template"},{"location":"weekly/module_week_3_distributions_variation/#starter-notebook-snippets","text":"import seaborn as sns import matplotlib.pyplot as plt iris = sns.load_dataset('iris') # Histogram sns.histplot(iris['sepal_length'], bins=20, kde=False) # KDE sns.kdeplot(iris['sepal_length'], fill=True) # Boxplot by species sns.boxplot(data=iris, x='species', y='sepal_length') # ECDF def ecdf(data): x = np.sort(data) y = np.arange(1, len(x)+1) / len(x) return x, y import numpy as np x, y = ecdf(iris['sepal_length']) plt.plot(x, y, marker='.', linestyle='none') plt.xlabel('Sepal length') plt.ylabel('ECDF')","title":"\ud83d\udcbb Starter Notebook Snippets"},{"location":"weekly/module_week_3_distributions_variation/#in-class-activity","text":"Compare histogram vs. KDE of flight delay data. Which communicates central tendency more clearly? Which better shows multimodality? Plot boxplot of iris petal length by species. Discuss: how does this compare to histograms? Construct ECDFs for sepal width. What does it reveal about spread and skewness? Group work: each team selects a dataset and produces multiple distribution plots, then explains which is most effective.","title":"\ud83e\uddea In-Class Activity"},{"location":"weekly/module_week_3_distributions_variation/#homework-due-next-thursday-sept-18","text":"Select two datasets (one provided + one of your choice). For each dataset: Produce at least 3 distribution plots (histogram, KDE, ECDF, box/violin). Interpret shape, spread, skew, and outliers in markdown. Reflect on the pros/cons of each visualization type. Add at least one annotated chart highlighting a key pattern. Submit .ipynb and .html as a zip file. Rubric (10 pts) Correct use of multiple plot types (4) Clear interpretation and discussion (3) Labeling, annotations, and readability (2) Reproducibility (1)","title":"\ud83c\udfe0 Homework (Due next Thursday, Sept 18)"},{"location":"weekly/module_week_3_distributions_variation/#optional-extensions","text":"Experiment with different bin sizes in histograms and compare results. Overlay histogram and KDE to show complementarity. Use sns.pairplot to examine multiple distributions and correlations. Compare distributions across groups using facet plots. Try violin plots with split by category.","title":"\ud83e\udde9 Optional Extensions"},{"location":"weekly/module_week_3_distributions_variation/#submission-checklist","text":"Before submitting, make sure: Your assignment has fulfilled all the basic requirements listed above. The visualizations in the Notebook and HTML are well displayed.","title":"\u2705 Submission Checklist"},{"location":"weekly/module_week_4_wrangling_with_pandas/","text":"Week 4 \u2014 Wrangling with pandas Learning how to clean, transform, and prepare data for effective visualization. \ud83d\udcd6 Background & Motivation Data visualization is only as good as the data behind it. Most real-world datasets are messy, requiring cleaning and transformation before they can be meaningfully visualized. Pandas is the cornerstone Python library for data wrangling, providing flexible tools to reshape, aggregate, and join datasets. This week introduces practical techniques for preparing data that will allow you to build more accurate and insightful visualizations. \ud83d\udd0e Learning Objectives Select, filter, group, summarize, and reshape data in pandas. Work with datetime and categorical data types. Join and merge datasets for richer analysis. Prepare clean datasets ready for visualization. \ud83d\udcda Readings & Resources Pandas User Guide 10 Minutes to pandas Working with Text Data Time Series / Date Functionality Sample Data Sources: NYC Taxi trips sample (NYC Open Data) COVID-19 data (Johns Hopkins University) \ud83d\udee0\ufe0f Setup Checklist Ensure you can run: pip install pandas matplotlib seaborn \ud83e\udded Lecture Outline Session 1 (75 min \u2014 Theory Focus) Introduction to pandas DataFrames & Series (15 min) Selection and filtering operations (20 min) GroupBy and aggregation (20 min) Intro to joining and merging: concepts and syntax (15 min) Hands-on with NYC Taxi dataset (20 min). Download the files from here Session 2 (75 min - Hands-On) Recap & troubleshooting (10 min) Reshaping data: pivot, melt, stack/unstack (25 min) Working with datetime and categorical variables (20 min) Merging and joining multiple datasets (20 min) Download the Jupyter Notebook and the additional population table for the session. Download the complete Jupyter Notebook . Remember to have other files ready for the notebook. \ud83d\udcbb Starter Notebook Snippets import pandas as pd # Load dataset trips = pd.read_csv(\"nyc_taxi_sample.csv\") # Filter rows filtered = trips[trips[\"passenger_count\"] > 2] # Group and aggregate agg = trips.groupby(\"passenger_count\")[\"fare_amount\"].mean() # Reshape with melt df_wide = pd.DataFrame({ 'id': [1, 2], 'math': [90, 80], 'english': [85, 78] }) df_tidy = df_wide.melt(id_vars='id', var_name='subject', value_name='score') # Parse dates trips['pickup_datetime'] = pd.to_datetime(trips['pickup_datetime']) \ud83e\uddea In-Class Activity Use the COVID-19 dataset to: Filter by one country and visualize new cases over time. Group data by month and compare monthly averages. Reshape the dataset to tidy form and create a plot. \ud83c\udfe0 Homework (Due next Thursday, Sept 25) Select a dataset with at least 5 columns. Perform the following in a notebook: Clean and filter the dataset. Apply at least 2 groupby operations with aggregations. Reshape the dataset at least once (pivot, melt, etc.). Create 3 visualizations from the cleaned dataset. Submit .ipynb and .html . Rubric (10 pts) Correct wrangling operations applied (4) Creativity in reshaping & grouping (2) Clear and readable plots (2) Reproducibility (2) \ud83e\udde9 Optional Extensions Merge two datasets to add richer context. Explore pandas string operations to clean messy text. Create a time series plot with rolling averages. \u2705 Submission Checklist Before submitting, make sure: Your assignment has fulfilled all the basic requirements listed above. The operations and visualizations in the Jupyter notebook are correct. Use Quarto to render the notebook and ensure the content is displayed well.","title":"Week 4 \u2014 Wrangling with pandas"},{"location":"weekly/module_week_4_wrangling_with_pandas/#week-4-wrangling-with-pandas","text":"Learning how to clean, transform, and prepare data for effective visualization.","title":"Week 4 \u2014 Wrangling with pandas"},{"location":"weekly/module_week_4_wrangling_with_pandas/#background-motivation","text":"Data visualization is only as good as the data behind it. Most real-world datasets are messy, requiring cleaning and transformation before they can be meaningfully visualized. Pandas is the cornerstone Python library for data wrangling, providing flexible tools to reshape, aggregate, and join datasets. This week introduces practical techniques for preparing data that will allow you to build more accurate and insightful visualizations.","title":"\ud83d\udcd6 Background &amp; Motivation"},{"location":"weekly/module_week_4_wrangling_with_pandas/#learning-objectives","text":"Select, filter, group, summarize, and reshape data in pandas. Work with datetime and categorical data types. Join and merge datasets for richer analysis. Prepare clean datasets ready for visualization.","title":"\ud83d\udd0e Learning Objectives"},{"location":"weekly/module_week_4_wrangling_with_pandas/#readings-resources","text":"Pandas User Guide 10 Minutes to pandas Working with Text Data Time Series / Date Functionality Sample Data Sources: NYC Taxi trips sample (NYC Open Data) COVID-19 data (Johns Hopkins University)","title":"\ud83d\udcda Readings &amp; Resources"},{"location":"weekly/module_week_4_wrangling_with_pandas/#setup-checklist","text":"Ensure you can run: pip install pandas matplotlib seaborn","title":"\ud83d\udee0\ufe0f Setup Checklist"},{"location":"weekly/module_week_4_wrangling_with_pandas/#lecture-outline","text":"","title":"\ud83e\udded Lecture Outline"},{"location":"weekly/module_week_4_wrangling_with_pandas/#session-1-75-min-theory-focus","text":"Introduction to pandas DataFrames & Series (15 min) Selection and filtering operations (20 min) GroupBy and aggregation (20 min) Intro to joining and merging: concepts and syntax (15 min) Hands-on with NYC Taxi dataset (20 min). Download the files from here","title":"Session 1 (75 min \u2014 Theory Focus)"},{"location":"weekly/module_week_4_wrangling_with_pandas/#session-2-75-min-hands-on","text":"Recap & troubleshooting (10 min) Reshaping data: pivot, melt, stack/unstack (25 min) Working with datetime and categorical variables (20 min) Merging and joining multiple datasets (20 min) Download the Jupyter Notebook and the additional population table for the session. Download the complete Jupyter Notebook . Remember to have other files ready for the notebook.","title":"Session 2 (75 min - Hands-On)"},{"location":"weekly/module_week_4_wrangling_with_pandas/#starter-notebook-snippets","text":"import pandas as pd # Load dataset trips = pd.read_csv(\"nyc_taxi_sample.csv\") # Filter rows filtered = trips[trips[\"passenger_count\"] > 2] # Group and aggregate agg = trips.groupby(\"passenger_count\")[\"fare_amount\"].mean() # Reshape with melt df_wide = pd.DataFrame({ 'id': [1, 2], 'math': [90, 80], 'english': [85, 78] }) df_tidy = df_wide.melt(id_vars='id', var_name='subject', value_name='score') # Parse dates trips['pickup_datetime'] = pd.to_datetime(trips['pickup_datetime'])","title":"\ud83d\udcbb Starter Notebook Snippets"},{"location":"weekly/module_week_4_wrangling_with_pandas/#in-class-activity","text":"Use the COVID-19 dataset to: Filter by one country and visualize new cases over time. Group data by month and compare monthly averages. Reshape the dataset to tidy form and create a plot.","title":"\ud83e\uddea In-Class Activity"},{"location":"weekly/module_week_4_wrangling_with_pandas/#homework-due-next-thursday-sept-25","text":"Select a dataset with at least 5 columns. Perform the following in a notebook: Clean and filter the dataset. Apply at least 2 groupby operations with aggregations. Reshape the dataset at least once (pivot, melt, etc.). Create 3 visualizations from the cleaned dataset. Submit .ipynb and .html . Rubric (10 pts) Correct wrangling operations applied (4) Creativity in reshaping & grouping (2) Clear and readable plots (2) Reproducibility (2)","title":"\ud83c\udfe0 Homework (Due next Thursday, Sept 25)"},{"location":"weekly/module_week_4_wrangling_with_pandas/#optional-extensions","text":"Merge two datasets to add richer context. Explore pandas string operations to clean messy text. Create a time series plot with rolling averages.","title":"\ud83e\udde9 Optional Extensions"},{"location":"weekly/module_week_4_wrangling_with_pandas/#submission-checklist","text":"Before submitting, make sure: Your assignment has fulfilled all the basic requirements listed above. The operations and visualizations in the Jupyter notebook are correct. Use Quarto to render the notebook and ensure the content is displayed well.","title":"\u2705 Submission Checklist"},{"location":"weekly/module_week_5_perception_principles/","text":"Week 5 \u2014 Perception & Principles Applying visual perception theory and design principles to create effective, truthful, and clear visualizations. \ud83d\udcd6 Background & Motivation Even when the data is clean and the chart type is appropriate, design decisions can make the difference between clarity and confusion. Human perception imposes limits on how well we can decode visual information. By understanding principles from perceptual psychology, we can design graphics that communicate more effectively and avoid misleading audiences. This week introduces concepts like Cleveland & McGill\u2019s hierarchy of graphical perception, preattentive attributes, Gestalt principles, and common pitfalls in chart design. These theoretical foundations provide guidance for making practical design decisions in your visualizations. \ud83d\udd0e Learning Objectives Understand how human perception shapes data interpretation. Apply the Cleveland\u2013McGill perceptual rankings to select more effective encodings. Identify and use preattentive features to guide viewer attention. Recognize and correct misleading design practices. \ud83d\udcda Readings & Resources Cleveland & McGill (1984): Graphical Perception Fundamentals of Data Visualization \u2014 Chapters on perception and design. Data Visualization Society: Design Principles The Gestalt Principles Sample Data Sources: Simulated datasets designed to illustrate perception issues. Any dataset from previous weeks (for redesign exercises). \ud83d\udee0\ufe0f Setup Checklist Ensure your environment includes: pip install seaborn matplotlib pandas \ud83e\udded Lecture Outline Session 1 (75 min \u2014 Theory Focus) Motivation: Why perception matters in visualization (10 min) Cleveland\u2013McGill hierarchy of graphical perception (20 min) Preattentive attributes (color, shape, position, orientation) (20 min) Gestalt principles and visual grouping (15 min) Misleading charts and design pitfalls (10 min) Session 2 (75 min \u2014 Hands-on Focus) Recap & discussion of theory (10 min) Redesign bad charts into effective versions (30 min) Guided exercise: compare encodings using simulated data (20 min) Workshop: students bring prior homework plots and improve them (15 min) Download the Jupyter Notebook \ud83d\udcbb Starter Notebook Snippets import pandas as pd import matplotlib.pyplot as plt import seaborn as sns # Example of a misleading bar chart values = [5, 10, 15] labels = ['A', 'B', 'C'] plt.bar(labels, values) plt.ylim(4, 16) # Misleading y-axis range plt.title(\"Misleading Bar Chart\") plt.show() # Redesigned chart with zero baseline plt.bar(labels, values) plt.ylim(0, 16) plt.title(\"Improved Bar Chart\") plt.show() \ud83e\uddea In-Class Activity Critique provided \"poorly-designed\" charts and redesign them. Use preattentive attributes to highlight important data points. Compare multiple encoding strategies for the same dataset. \ud83c\udfe0 Homework (Due next Friday, Oct 3) Find a poorly designed chart (for example, a truncated y-axis bar chart from a news article, a rainbow-colored heatmap in a research paper, or an infographic with distorted area encodings). Recreate the chart faithfully in Python. Redesign the chart applying perception & design principles. Write a short reflection (200+ words) describing: Why the original was misleading or ineffective. What principles guided your redesign? How your redesign improves comprehension. Submit .ipynb and .html . Rubric (10 pts) Accurate reproduction of the original chart (2) Effective redesign applying principles (4) Clear reflection linking to theory (2) Visual clarity and labeling (2) \ud83e\udde9 Optional Extensions Experiment with alternative encodings and compare effectiveness. Conduct a quick peer survey: which design is easier to interpret? Try adding annotations or highlights using preattentive cues. \u2705 Submission Checklist Before submitting, make sure: Your assignment has fulfilled all the basic requirements listed above. The visualizations and your reflections in the Jupyter notebook are properly organized and displayed. Use Quarto to render the notebook into HTML and zip the files for submission.","title":"Week 5 \u2014 Perception &amp; Principles"},{"location":"weekly/module_week_5_perception_principles/#week-5-perception-principles","text":"Applying visual perception theory and design principles to create effective, truthful, and clear visualizations.","title":"Week 5 \u2014 Perception &amp; Principles"},{"location":"weekly/module_week_5_perception_principles/#background-motivation","text":"Even when the data is clean and the chart type is appropriate, design decisions can make the difference between clarity and confusion. Human perception imposes limits on how well we can decode visual information. By understanding principles from perceptual psychology, we can design graphics that communicate more effectively and avoid misleading audiences. This week introduces concepts like Cleveland & McGill\u2019s hierarchy of graphical perception, preattentive attributes, Gestalt principles, and common pitfalls in chart design. These theoretical foundations provide guidance for making practical design decisions in your visualizations.","title":"\ud83d\udcd6 Background &amp; Motivation"},{"location":"weekly/module_week_5_perception_principles/#learning-objectives","text":"Understand how human perception shapes data interpretation. Apply the Cleveland\u2013McGill perceptual rankings to select more effective encodings. Identify and use preattentive features to guide viewer attention. Recognize and correct misleading design practices.","title":"\ud83d\udd0e Learning Objectives"},{"location":"weekly/module_week_5_perception_principles/#readings-resources","text":"Cleveland & McGill (1984): Graphical Perception Fundamentals of Data Visualization \u2014 Chapters on perception and design. Data Visualization Society: Design Principles The Gestalt Principles Sample Data Sources: Simulated datasets designed to illustrate perception issues. Any dataset from previous weeks (for redesign exercises).","title":"\ud83d\udcda Readings &amp; Resources"},{"location":"weekly/module_week_5_perception_principles/#setup-checklist","text":"Ensure your environment includes: pip install seaborn matplotlib pandas","title":"\ud83d\udee0\ufe0f Setup Checklist"},{"location":"weekly/module_week_5_perception_principles/#lecture-outline","text":"","title":"\ud83e\udded Lecture Outline"},{"location":"weekly/module_week_5_perception_principles/#session-1-75-min-theory-focus","text":"Motivation: Why perception matters in visualization (10 min) Cleveland\u2013McGill hierarchy of graphical perception (20 min) Preattentive attributes (color, shape, position, orientation) (20 min) Gestalt principles and visual grouping (15 min) Misleading charts and design pitfalls (10 min)","title":"Session 1 (75 min \u2014 Theory Focus)"},{"location":"weekly/module_week_5_perception_principles/#session-2-75-min-hands-on-focus","text":"Recap & discussion of theory (10 min) Redesign bad charts into effective versions (30 min) Guided exercise: compare encodings using simulated data (20 min) Workshop: students bring prior homework plots and improve them (15 min) Download the Jupyter Notebook","title":"Session 2 (75 min \u2014 Hands-on Focus)"},{"location":"weekly/module_week_5_perception_principles/#starter-notebook-snippets","text":"import pandas as pd import matplotlib.pyplot as plt import seaborn as sns # Example of a misleading bar chart values = [5, 10, 15] labels = ['A', 'B', 'C'] plt.bar(labels, values) plt.ylim(4, 16) # Misleading y-axis range plt.title(\"Misleading Bar Chart\") plt.show() # Redesigned chart with zero baseline plt.bar(labels, values) plt.ylim(0, 16) plt.title(\"Improved Bar Chart\") plt.show()","title":"\ud83d\udcbb Starter Notebook Snippets"},{"location":"weekly/module_week_5_perception_principles/#in-class-activity","text":"Critique provided \"poorly-designed\" charts and redesign them. Use preattentive attributes to highlight important data points. Compare multiple encoding strategies for the same dataset.","title":"\ud83e\uddea In-Class Activity"},{"location":"weekly/module_week_5_perception_principles/#homework-due-next-friday-oct-3","text":"Find a poorly designed chart (for example, a truncated y-axis bar chart from a news article, a rainbow-colored heatmap in a research paper, or an infographic with distorted area encodings). Recreate the chart faithfully in Python. Redesign the chart applying perception & design principles. Write a short reflection (200+ words) describing: Why the original was misleading or ineffective. What principles guided your redesign? How your redesign improves comprehension. Submit .ipynb and .html . Rubric (10 pts) Accurate reproduction of the original chart (2) Effective redesign applying principles (4) Clear reflection linking to theory (2) Visual clarity and labeling (2)","title":"\ud83c\udfe0 Homework (Due next Friday, Oct 3)"},{"location":"weekly/module_week_5_perception_principles/#optional-extensions","text":"Experiment with alternative encodings and compare effectiveness. Conduct a quick peer survey: which design is easier to interpret? Try adding annotations or highlights using preattentive cues.","title":"\ud83e\udde9 Optional Extensions"},{"location":"weekly/module_week_5_perception_principles/#submission-checklist","text":"Before submitting, make sure: Your assignment has fulfilled all the basic requirements listed above. The visualizations and your reflections in the Jupyter notebook are properly organized and displayed. Use Quarto to render the notebook into HTML and zip the files for submission.","title":"\u2705 Submission Checklist"},{"location":"weekly/module_week_6_comparisons/","text":"Week 6 \u2014 Comparisons Designing fair and effective comparisons across categories, groups, and time. \ud83d\udcd6 Background & Motivation Most insight in data science comes from comparing things: groups, treatments, time periods, geographies, and models. Good comparison graphics make differences and similarities immediately legible without misleading the audience. This week focuses on selecting the right comparison design (bars, dot plots, slope charts, small multiples), aligning scales and baselines, and avoiding visual pitfalls that distort comparisons. \ud83d\udd0e Learning Objectives Choose appropriate designs for category and time comparisons (grouped bars, dot plots, slope charts, small multiples). Align scales, baselines, and axes to ensure fair comparisons. Normalize data (per capita, percent change, index to baseline) when appropriate. Use faceting and small multiples to reduce clutter and increase clarity. Add clear annotations and ordering to emphasize key contrasts. \ud83d\udcda Readings & Resources Fundamentals of Data Visualization \u2014 chapters on comparisons & small multiples. Seaborn: Categorical plots , FacetGrid Matplotlib: bar charts , subplots ColorBrewer: Choosing palettes Sample Data Sources: World Bank indicators (e.g., GDP per capita, life expectancy) Gapminder (country-level indicators) Sports/team statistics (season-by-season comparisons) \ud83d\udee0\ufe0f Setup Checklist Ensure your environment includes: pip install pandas numpy matplotlib seaborn plotly First, ensure that the virtual environment is properly created and activated. Then confirm you can import these libraries and render a simple chart before class. \ud83e\udded Lecture Outline Session 1 (75 min \u2014 Theory Focus) When to compare? Framing questions and choosing the right comparison graphic (10 min) Bars vs. dot plots: perceptual accuracy and overplotting concerns (15 min) Slope charts for before/after and rank changes (15 min) Scale, baseline, and normalization (indexing to 100, percent change, per\u2011capita) (20 min) Small multiples and faceting; ordering and labeling for clarity (15 min) Download the Jupyter Notebook and data used in lecture from this webpage Session 2 (75 min \u2014 Hands-on Focus) Live coding: grouped bars \u2192 dot plot refactor (15 min) Build a slope chart for a before/after dataset (20 min) Create a small multiples view with FacetGrid (20 min) Mini\u2011workshop: add annotations, reorder categories, and test alternative scales (20 min) Download the Jupyter Notebook for this session. \ud83d\udcbb Starter Notebook Snippets Dot plot vs. grouped bars import pandas as pd import seaborn as sns import matplotlib.pyplot as plt sns.set_theme(style=\"whitegrid\") # toy data: mean score by group and condition df = pd.DataFrame({ \"group\": [\"A\",\"A\",\"B\",\"B\",\"C\",\"C\"], \"condition\": [\"Control\",\"Treatment\"]*3, \"score\": [72, 78, 65, 74, 81, 85] }) # Grouped bars sns.catplot(data=df, kind=\"bar\", x=\"group\", y=\"score\", hue=\"condition\") plt.title(\"Grouped Bars\") # Dot plot (often clearer for two conditions) sns.catplot(data=df, kind=\"point\", x=\"group\", y=\"score\", hue=\"condition\", dodge=True) plt.title(\"Dot Plot Comparison\") Slope chart (before/after) import numpy as np before = pd.Series([72, 65, 81], index=[\"A\",\"B\",\"C\"]).rename(\"before\") after = pd.Series([78, 74, 85], index=[\"A\",\"B\",\"C\"]).rename(\"after\") long = pd.concat([before, after], axis=1).reset_index().melt(id_vars=\"index\", var_name=\"time\", value_name=\"score\") long = long.rename(columns={\"index\":\"group\"}) plt.figure(figsize=(6,4)) for g, sub in long.groupby(\"group\"): xs = [0, 1] ys = sub.sort_values(\"time\")[\"score\"].values plt.plot(xs, ys, marker=\"o\") plt.text(0-0.03, ys[0], g, ha=\"right\", va=\"center\") plt.xticks([0,1],[\"Before\",\"After\"]) plt.title(\"Slope Chart \u2014 Before vs After\") plt.ylabel(\"Score\") plt.grid(axis='y', alpha=.3) plt.tight_layout() Small multiples with FacetGrid # Using Gapminder-like structure peng = sns.load_dataset(\"penguins\").dropna() fg = sns.FacetGrid(peng, col=\"species\", height=3, sharey=True) fg.map_dataframe(sns.scatterplot, x=\"flipper_length_mm\", y=\"body_mass_g\", alpha=.7) fg.set_axis_labels(\"Flipper length (mm)\", \"Body mass (g)\") fg.set_titles(col_template=\"{col_name}\") Normalization (indexing to a baseline) # Index each group to its first time value wide = pd.DataFrame({\"t\":[1,2,3,4], \"A\":[100,110,108,120], \"B\":[100,98,105,112]}) base = wide.loc[0, [\"A\",\"B\"]] indexed = wide[[\"A\",\"B\"]].divide(base) * 100 indexed[\"t\"] = wide[\"t\"] indexed_m = indexed.melt(\"t\", var_name=\"series\", value_name=\"index\") sns.lineplot(data=indexed_m, x=\"t\", y=\"index\", hue=\"series\") plt.axhline(100, color=\"k\", lw=.8) plt.ylabel(\"Index (baseline=100)\") plt.title(\"Indexed Comparison\") \ud83e\uddea In-Class Activity Convert a cluttered grouped\u2011bar chart into a dot plot and explain which communicates differences more clearly. Build a slope chart for a before/after dataset and annotate the largest change. Create small multiples with FacetGrid to compare subgroups on the same scale. Try at least one normalization (percent change or index to baseline) and discuss how it changes the interpretation. \ud83c\udfe0 Homework (Due next Thursday, Oct 9) Select a dataset with at least two groups and either two conditions or multiple time points. Produce the following: One dot plot (or refactor from grouped bars) with thoughtful ordering and labels. One slope chart showing before/after or the earliest vs. the latest comparison. One small\u2011multiples chart (faceted) on a shared y\u2011scale. At least one normalized view (percent change or index to baseline). Add concise annotations and a brief (200\u2013300 words) discussion of which design best supports your comparison question and why. Submit .ipynb and .html . Rubric (10 pts) Appropriate chart choices for comparison tasks (3) Scale/baseline alignment and normalization where needed (3) Clear labeling, ordering, and annotations (2) Reproducibility and code quality (2) \ud83e\udde9 Optional Extensions Use plotly.express to build an interactive small multiples or animation (e.g., by year). Explore ranked dot plots (ordered by value) and slopegraphs with many categories. Add confidence intervals or error bars for group comparisons. \u2705 Submission Checklist Before submitting, make sure: Your assignment has fulfilled all the basic requirements listed above. The visualizations and your reflections in the Jupyter notebook are properly organized and displayed. Use Quarto to render the notebook into HTML and zip the files for submission.","title":"Week 6 \u2014 Comparisons"},{"location":"weekly/module_week_6_comparisons/#week-6-comparisons","text":"Designing fair and effective comparisons across categories, groups, and time.","title":"Week 6 \u2014 Comparisons"},{"location":"weekly/module_week_6_comparisons/#background-motivation","text":"Most insight in data science comes from comparing things: groups, treatments, time periods, geographies, and models. Good comparison graphics make differences and similarities immediately legible without misleading the audience. This week focuses on selecting the right comparison design (bars, dot plots, slope charts, small multiples), aligning scales and baselines, and avoiding visual pitfalls that distort comparisons.","title":"\ud83d\udcd6 Background &amp; Motivation"},{"location":"weekly/module_week_6_comparisons/#learning-objectives","text":"Choose appropriate designs for category and time comparisons (grouped bars, dot plots, slope charts, small multiples). Align scales, baselines, and axes to ensure fair comparisons. Normalize data (per capita, percent change, index to baseline) when appropriate. Use faceting and small multiples to reduce clutter and increase clarity. Add clear annotations and ordering to emphasize key contrasts.","title":"\ud83d\udd0e Learning Objectives"},{"location":"weekly/module_week_6_comparisons/#readings-resources","text":"Fundamentals of Data Visualization \u2014 chapters on comparisons & small multiples. Seaborn: Categorical plots , FacetGrid Matplotlib: bar charts , subplots ColorBrewer: Choosing palettes Sample Data Sources: World Bank indicators (e.g., GDP per capita, life expectancy) Gapminder (country-level indicators) Sports/team statistics (season-by-season comparisons)","title":"\ud83d\udcda Readings &amp; Resources"},{"location":"weekly/module_week_6_comparisons/#setup-checklist","text":"Ensure your environment includes: pip install pandas numpy matplotlib seaborn plotly First, ensure that the virtual environment is properly created and activated. Then confirm you can import these libraries and render a simple chart before class.","title":"\ud83d\udee0\ufe0f Setup Checklist"},{"location":"weekly/module_week_6_comparisons/#lecture-outline","text":"","title":"\ud83e\udded Lecture Outline"},{"location":"weekly/module_week_6_comparisons/#session-1-75-min-theory-focus","text":"When to compare? Framing questions and choosing the right comparison graphic (10 min) Bars vs. dot plots: perceptual accuracy and overplotting concerns (15 min) Slope charts for before/after and rank changes (15 min) Scale, baseline, and normalization (indexing to 100, percent change, per\u2011capita) (20 min) Small multiples and faceting; ordering and labeling for clarity (15 min) Download the Jupyter Notebook and data used in lecture from this webpage","title":"Session 1 (75 min \u2014 Theory Focus)"},{"location":"weekly/module_week_6_comparisons/#session-2-75-min-hands-on-focus","text":"Live coding: grouped bars \u2192 dot plot refactor (15 min) Build a slope chart for a before/after dataset (20 min) Create a small multiples view with FacetGrid (20 min) Mini\u2011workshop: add annotations, reorder categories, and test alternative scales (20 min) Download the Jupyter Notebook for this session.","title":"Session 2 (75 min \u2014 Hands-on Focus)"},{"location":"weekly/module_week_6_comparisons/#starter-notebook-snippets","text":"","title":"\ud83d\udcbb Starter Notebook Snippets"},{"location":"weekly/module_week_6_comparisons/#dot-plot-vs-grouped-bars","text":"import pandas as pd import seaborn as sns import matplotlib.pyplot as plt sns.set_theme(style=\"whitegrid\") # toy data: mean score by group and condition df = pd.DataFrame({ \"group\": [\"A\",\"A\",\"B\",\"B\",\"C\",\"C\"], \"condition\": [\"Control\",\"Treatment\"]*3, \"score\": [72, 78, 65, 74, 81, 85] }) # Grouped bars sns.catplot(data=df, kind=\"bar\", x=\"group\", y=\"score\", hue=\"condition\") plt.title(\"Grouped Bars\") # Dot plot (often clearer for two conditions) sns.catplot(data=df, kind=\"point\", x=\"group\", y=\"score\", hue=\"condition\", dodge=True) plt.title(\"Dot Plot Comparison\")","title":"Dot plot vs. grouped bars"},{"location":"weekly/module_week_6_comparisons/#slope-chart-beforeafter","text":"import numpy as np before = pd.Series([72, 65, 81], index=[\"A\",\"B\",\"C\"]).rename(\"before\") after = pd.Series([78, 74, 85], index=[\"A\",\"B\",\"C\"]).rename(\"after\") long = pd.concat([before, after], axis=1).reset_index().melt(id_vars=\"index\", var_name=\"time\", value_name=\"score\") long = long.rename(columns={\"index\":\"group\"}) plt.figure(figsize=(6,4)) for g, sub in long.groupby(\"group\"): xs = [0, 1] ys = sub.sort_values(\"time\")[\"score\"].values plt.plot(xs, ys, marker=\"o\") plt.text(0-0.03, ys[0], g, ha=\"right\", va=\"center\") plt.xticks([0,1],[\"Before\",\"After\"]) plt.title(\"Slope Chart \u2014 Before vs After\") plt.ylabel(\"Score\") plt.grid(axis='y', alpha=.3) plt.tight_layout()","title":"Slope chart (before/after)"},{"location":"weekly/module_week_6_comparisons/#small-multiples-with-facetgrid","text":"# Using Gapminder-like structure peng = sns.load_dataset(\"penguins\").dropna() fg = sns.FacetGrid(peng, col=\"species\", height=3, sharey=True) fg.map_dataframe(sns.scatterplot, x=\"flipper_length_mm\", y=\"body_mass_g\", alpha=.7) fg.set_axis_labels(\"Flipper length (mm)\", \"Body mass (g)\") fg.set_titles(col_template=\"{col_name}\")","title":"Small multiples with FacetGrid"},{"location":"weekly/module_week_6_comparisons/#normalization-indexing-to-a-baseline","text":"# Index each group to its first time value wide = pd.DataFrame({\"t\":[1,2,3,4], \"A\":[100,110,108,120], \"B\":[100,98,105,112]}) base = wide.loc[0, [\"A\",\"B\"]] indexed = wide[[\"A\",\"B\"]].divide(base) * 100 indexed[\"t\"] = wide[\"t\"] indexed_m = indexed.melt(\"t\", var_name=\"series\", value_name=\"index\") sns.lineplot(data=indexed_m, x=\"t\", y=\"index\", hue=\"series\") plt.axhline(100, color=\"k\", lw=.8) plt.ylabel(\"Index (baseline=100)\") plt.title(\"Indexed Comparison\")","title":"Normalization (indexing to a baseline)"},{"location":"weekly/module_week_6_comparisons/#in-class-activity","text":"Convert a cluttered grouped\u2011bar chart into a dot plot and explain which communicates differences more clearly. Build a slope chart for a before/after dataset and annotate the largest change. Create small multiples with FacetGrid to compare subgroups on the same scale. Try at least one normalization (percent change or index to baseline) and discuss how it changes the interpretation.","title":"\ud83e\uddea In-Class Activity"},{"location":"weekly/module_week_6_comparisons/#homework-due-next-thursday-oct-9","text":"Select a dataset with at least two groups and either two conditions or multiple time points. Produce the following: One dot plot (or refactor from grouped bars) with thoughtful ordering and labels. One slope chart showing before/after or the earliest vs. the latest comparison. One small\u2011multiples chart (faceted) on a shared y\u2011scale. At least one normalized view (percent change or index to baseline). Add concise annotations and a brief (200\u2013300 words) discussion of which design best supports your comparison question and why. Submit .ipynb and .html . Rubric (10 pts) Appropriate chart choices for comparison tasks (3) Scale/baseline alignment and normalization where needed (3) Clear labeling, ordering, and annotations (2) Reproducibility and code quality (2)","title":"\ud83c\udfe0 Homework (Due next Thursday, Oct 9)"},{"location":"weekly/module_week_6_comparisons/#optional-extensions","text":"Use plotly.express to build an interactive small multiples or animation (e.g., by year). Explore ranked dot plots (ordered by value) and slopegraphs with many categories. Add confidence intervals or error bars for group comparisons.","title":"\ud83e\udde9 Optional Extensions"},{"location":"weekly/module_week_6_comparisons/#submission-checklist","text":"Before submitting, make sure: Your assignment has fulfilled all the basic requirements listed above. The visualizations and your reflections in the Jupyter notebook are properly organized and displayed. Use Quarto to render the notebook into HTML and zip the files for submission.","title":"\u2705 Submission Checklist"},{"location":"weekly/module_week_7_text_labels_tables/","text":"Week 7 \u2014 Text, Labels, & Tables Enhancing clarity and storytelling through effective text, annotation, and tabular presentation. \ud83d\udcd6 Background & Motivation Numbers and charts alone rarely tell the full story. Effective use of text, labels, annotations, and tables can direct attention, clarify meaning, and strengthen the narrative of your visualization. This week focuses on best practices for integrating words with visuals, so your charts are not only accurate but also understandable and memorable . We also cover how to design tables that are clear, accessible, and complementary to visualizations. In many professional contexts (reports, dashboards, publications), tables remain a key medium for communicating precise values alongside visuals. \ud83d\udd0e Learning Objectives Add effective titles, axis labels, captions, and annotations to charts. Use direct labeling instead of or alongside legends. Highlight important data points with callouts and text placement. Design tables for clarity and readability, including alignment and formatting. Balance text and visuals to create compelling data stories. \ud83d\udcda Readings & Resources Fundamentals of Data Visualization \u2014 chapters on annotations and labeling. Datawrapper Academy: How to annotate your charts Table Design Tips (Evergreen Data) Matplotlib: text & annotation Seaborn: FacetGrid titles and labels Sample Data Sources: Sports statistics (e.g., player or team comparisons) Election results data Financial performance tables (company revenue, expenses, profits) \ud83d\udee0\ufe0f Setup Checklist Ensure your environment includes: pip install pandas matplotlib seaborn First, make sure the virtual environment is properly created and activated. Then confirm you can import these libraries and render a simple chart before class. \ud83e\udded Lecture Outline Session 1 (Theory Focus + Hands-on) Why text matters: the role of words in data storytelling Titles, subtitles, and captions: framing interpretation Legends vs. direct labeling: when to use each Annotation techniques: highlighting key values or trends Principles of clear table design Adding labels and annotations in Matplotlib & Seaborn Redesign a cluttered chart with better labeling Create a table in pandas and format it for readability Download the hands-on Jupyter Notebook Download the extra Jupyter Notebook for table formatting \ud83d\udcbb Starter Notebook Snippets import matplotlib.pyplot as plt import seaborn as sns import pandas as pd # Example scatterplot with annotation penguins = sns.load_dataset(\"penguins\").dropna() sns.scatterplot(data=penguins, x=\"flipper_length_mm\", y=\"body_mass_g\", hue=\"species\") plt.title(\"Penguins: Flipper length vs Body mass\") plt.xlabel(\"Flipper length (mm)\") plt.ylabel(\"Body mass (g)\") # Annotate one point max_penguin = penguins.loc[penguins['body_mass_g'].idxmax()] plt.annotate(\"Heaviest penguin\", xy=(max_penguin['flipper_length_mm'], max_penguin['body_mass_g']), xytext=(200, 6000), arrowprops=dict(facecolor='black', shrink=0.05)) plt.show() # Example formatted table in pandas data = { 'Team': ['A','B','C'], 'Wins': [10, 12, 8], 'Losses': [5, 3, 7] } df = pd.DataFrame(data) # Pretty print with alignment df.style.set_table_styles([ {\"selector\": \"th\", \"props\": [(\"text-align\", \"center\")]}, {\"selector\": \"td\", \"props\": [(\"text-align\", \"center\")]} ]).set_caption(\"Team Performance Summary\") \ud83e\uddea In-Class Activity Take an unlabeled chart and add appropriate title, labels, and annotations . Recreate a sports statistics table and improve its formatting. Compare two versions of the same chart: one with only a legend, one with direct labeling. \ud83c\udfe0 Homework (Due Oct 19) Select a dataset (sports, election, or financial) and create: One visualization with clear title, labels, and at least two annotations . One directly-labeled chart (instead of legend-based). One formatted table that complements your visualization. Include a short reflection (200\u2013300 words) explaining your labeling and table design choices. Submit .ipynb and .html . Rubric (10 pts) Effective use of titles, captions, and labels (3) Clear and purposeful annotations (2) Table design clarity and readability (3) Reflection quality (2) \ud83e\udde9 Optional Extensions Experiment with matplotlib.offsetbox or custom text placement. Use color and font variations to emphasize annotations. Export a styled pandas DataFrame as an image or LaTeX table. \u2705 Submission Checklist Before submitting, make sure: Your assignment has fulfilled all the basic requirements listed above. The visualizations and your reflections in the Jupyter notebook are properly organized and displayed. Use Quarto to render the notebook into HTML and zip the files for submission.","title":"Week 7 \u2014 Text, Labels, &amp; Tables"},{"location":"weekly/module_week_7_text_labels_tables/#week-7-text-labels-tables","text":"Enhancing clarity and storytelling through effective text, annotation, and tabular presentation.","title":"Week 7 \u2014 Text, Labels, &amp; Tables"},{"location":"weekly/module_week_7_text_labels_tables/#background-motivation","text":"Numbers and charts alone rarely tell the full story. Effective use of text, labels, annotations, and tables can direct attention, clarify meaning, and strengthen the narrative of your visualization. This week focuses on best practices for integrating words with visuals, so your charts are not only accurate but also understandable and memorable . We also cover how to design tables that are clear, accessible, and complementary to visualizations. In many professional contexts (reports, dashboards, publications), tables remain a key medium for communicating precise values alongside visuals.","title":"\ud83d\udcd6 Background &amp; Motivation"},{"location":"weekly/module_week_7_text_labels_tables/#learning-objectives","text":"Add effective titles, axis labels, captions, and annotations to charts. Use direct labeling instead of or alongside legends. Highlight important data points with callouts and text placement. Design tables for clarity and readability, including alignment and formatting. Balance text and visuals to create compelling data stories.","title":"\ud83d\udd0e Learning Objectives"},{"location":"weekly/module_week_7_text_labels_tables/#readings-resources","text":"Fundamentals of Data Visualization \u2014 chapters on annotations and labeling. Datawrapper Academy: How to annotate your charts Table Design Tips (Evergreen Data) Matplotlib: text & annotation Seaborn: FacetGrid titles and labels Sample Data Sources: Sports statistics (e.g., player or team comparisons) Election results data Financial performance tables (company revenue, expenses, profits)","title":"\ud83d\udcda Readings &amp; Resources"},{"location":"weekly/module_week_7_text_labels_tables/#setup-checklist","text":"Ensure your environment includes: pip install pandas matplotlib seaborn First, make sure the virtual environment is properly created and activated. Then confirm you can import these libraries and render a simple chart before class.","title":"\ud83d\udee0\ufe0f Setup Checklist"},{"location":"weekly/module_week_7_text_labels_tables/#lecture-outline","text":"","title":"\ud83e\udded Lecture Outline"},{"location":"weekly/module_week_7_text_labels_tables/#session-1-theory-focus-hands-on","text":"Why text matters: the role of words in data storytelling Titles, subtitles, and captions: framing interpretation Legends vs. direct labeling: when to use each Annotation techniques: highlighting key values or trends Principles of clear table design Adding labels and annotations in Matplotlib & Seaborn Redesign a cluttered chart with better labeling Create a table in pandas and format it for readability Download the hands-on Jupyter Notebook Download the extra Jupyter Notebook for table formatting","title":"Session 1 (Theory Focus + Hands-on)"},{"location":"weekly/module_week_7_text_labels_tables/#starter-notebook-snippets","text":"import matplotlib.pyplot as plt import seaborn as sns import pandas as pd # Example scatterplot with annotation penguins = sns.load_dataset(\"penguins\").dropna() sns.scatterplot(data=penguins, x=\"flipper_length_mm\", y=\"body_mass_g\", hue=\"species\") plt.title(\"Penguins: Flipper length vs Body mass\") plt.xlabel(\"Flipper length (mm)\") plt.ylabel(\"Body mass (g)\") # Annotate one point max_penguin = penguins.loc[penguins['body_mass_g'].idxmax()] plt.annotate(\"Heaviest penguin\", xy=(max_penguin['flipper_length_mm'], max_penguin['body_mass_g']), xytext=(200, 6000), arrowprops=dict(facecolor='black', shrink=0.05)) plt.show() # Example formatted table in pandas data = { 'Team': ['A','B','C'], 'Wins': [10, 12, 8], 'Losses': [5, 3, 7] } df = pd.DataFrame(data) # Pretty print with alignment df.style.set_table_styles([ {\"selector\": \"th\", \"props\": [(\"text-align\", \"center\")]}, {\"selector\": \"td\", \"props\": [(\"text-align\", \"center\")]} ]).set_caption(\"Team Performance Summary\")","title":"\ud83d\udcbb Starter Notebook Snippets"},{"location":"weekly/module_week_7_text_labels_tables/#in-class-activity","text":"Take an unlabeled chart and add appropriate title, labels, and annotations . Recreate a sports statistics table and improve its formatting. Compare two versions of the same chart: one with only a legend, one with direct labeling.","title":"\ud83e\uddea In-Class Activity"},{"location":"weekly/module_week_7_text_labels_tables/#homework-due-oct-19","text":"Select a dataset (sports, election, or financial) and create: One visualization with clear title, labels, and at least two annotations . One directly-labeled chart (instead of legend-based). One formatted table that complements your visualization. Include a short reflection (200\u2013300 words) explaining your labeling and table design choices. Submit .ipynb and .html . Rubric (10 pts) Effective use of titles, captions, and labels (3) Clear and purposeful annotations (2) Table design clarity and readability (3) Reflection quality (2)","title":"\ud83c\udfe0 Homework (Due Oct 19)"},{"location":"weekly/module_week_7_text_labels_tables/#optional-extensions","text":"Experiment with matplotlib.offsetbox or custom text placement. Use color and font variations to emphasize annotations. Export a styled pandas DataFrame as an image or LaTeX table.","title":"\ud83e\udde9 Optional Extensions"},{"location":"weekly/module_week_7_text_labels_tables/#submission-checklist","text":"Before submitting, make sure: Your assignment has fulfilled all the basic requirements listed above. The visualizations and your reflections in the Jupyter notebook are properly organized and displayed. Use Quarto to render the notebook into HTML and zip the files for submission.","title":"\u2705 Submission Checklist"},{"location":"weekly/module_week_8_mapping_i_ii/","text":"Week 8 \u2014 Mapping I & II Foundations & Choropleths; Spatial Joins, Enrichment & Interactivity \ud83d\udcd6 Background & Motivation This two\u2011session module builds a solid foundation for geographic data visualization and then applies it to real analytical workflows. In Mapping I , students learn core geospatial concepts (data types, formats, and coordinate systems) and produce clear choropleth maps with appropriate normalization, classification, and legends. In Mapping II , students connect maps to real analysis tasks by performing spatial and attribute joins, enriching with socio\u2011economic context, and delivering interactive maps for exploration and communication. \ud83d\udd0e Learning Objectives Distinguish vector vs. raster data; recognize common geospatial file formats (Shapefile, GeoJSON, TopoJSON, GeoPackage). Explain Coordinate Reference Systems (CRS) and projections; choose and document an appropriate CRS. Create choropleths with sensible normalization, classification, color, and legends. Perform spatial joins (point\u2011in\u2011polygon, polygon overlaps) and attribute joins on stable keys (e.g., FIPS/GEOID). Enrich maps with socio\u2011economic variables (e.g., ACS) and build interactive web maps. \ud83d\udcda Readings & Resources GeoPandas User Guide \u2014 geopandas.org PyGIS \u2014 Intro to GIS in Python \u2014 pygis.io/docs/a_intro.html Folium Quickstart \u2014 python-visualization.github.io/folium Plotly Express Choropleth \u2014 plotly.com/python/choropleth-maps Claus Wilke , Fundamentals of Data Visualization (Geospatial) \u2014 clauswilke.com/dataviz/geospatial.html ColorBrewer 2.0 \u2014 colorbrewer2.org EPSG.io (CRS search) \u2014 epsg.io Census/ACS data portal \u2014 data.census.gov ; Social Explorer \u2014 socialexplorer.com/home TopoJSON docs \u2014 github.com/topojson/topojson \ud83d\udee0\ufe0f Setup Install/verify: pip install geopandas folium plotly mapclassify pyproj shapely pandas matplotlib Notes: If computing areas/lengths, reproject to an appropriate projected CRS (e.g., equal\u2011area). Interactive HTML maps (Folium/Plotly) load tiles/scripts at view time. \ud83e\udded Session 1 \u2014 Mapping I: Foundations & Choropleths (\u224875 min) 1) Why map? When not to map Use maps when spatial structure matters (clusters, corridors, gradients). Prefer rates/ratios over raw counts; preview MAUP & ecological fallacy. 2) Geographic data fundamentals Vector (points/lines/polygons/multiparts) vs Raster (continuous/categorical); resolution, extent. 3) File formats Shapefile (.shp/.shx/.dbf/.prj) \u2013 common pitfalls: field name limits, encoding, missing .prj. GeoJSON (WGS84 lon/lat); TopoJSON (shared arcs, smaller web payloads); GeoPackage, Parquet+WKB. 4) CRS & projections Geographic vs Projected CRS; angular vs linear units. WGS84 (EPSG:4326) vs Web Mercator (EPSG:3857) vs Equal\u2011Area (e.g., ESRI:102003 for CONUS). Distortions (area/distance/direction); document CRS in captions. 5) Choropleths: principles Appropriate use: polygon\u2011level rates with clear denominators and time windows. Classification: Quantiles , Equal Interval , Natural Breaks (Jenks) , Std\u2011Dev; 4\u20137 bins. Color: sequential for ordered magnitudes; diverging for centered (\u00b1mean); avoid rainbow; accessible palettes. Legends & captions: variable name + units, bin method, CRS, data period, source. 6) Demos (brief) GeoPandas + Matplotlib : static choropleth; export PNG/SVG. Plotly Express : interactive choropleth with hover; export HTML. Folium : tile basemap, tooltips/popups, layer control; export HTML. Download the Jupyter Notebook and Data 7) Mini\u2011exercise (10\u201315 min) Given polygons + counts + population: make two choropleths (quantiles vs equal\u2011interval). Add a 3\u2011sentence note comparing how binning changes the story. \ud83e\udded Session 2 \u2014 Mapping II: Spatial Joins, Enrichment & Interactivity (\u224875 min) 1) Spatial joins Point\u2011in\u2011polygon (assign incidents/POIs to tracts), polygon\u2011to\u2011polygon (overlaps), nearest joins. GeoPandas sjoin predicates: within , contains , intersects ; geometry validity & CRS alignment. 2) Attribute joins & data hygiene Join on stable keys (FIPS/GEOID). Handle types, leading zeros, whitespace, duplicates, missing keys. 3) Aggregation, normalization, and stability Dissolve/aggregate to analysis geography; per\u2011capita / per\u2011household / per\u2011area rates. Consider rate stabilization (mention: Empirical Bayes) for small populations. 4) Socio\u2011economic enrichment Typical sources: ACS (income, education, housing, commute), CDC PLACES , BLS . Temporal alignment and definitional consistency. 5) Interactive mapping patterns Layer toggles (choropleth + points), marker clustering, heatmaps (when appropriate). Filters (sliders/dropdowns), hover templates, annotations; geometry simplification & TopoJSON for performance. 6) Demos (brief) Demo A : spatial join (points\u2192polygons) \u2192 counts per polygon \u2192 normalized rate. Demo B : attribute join with ACS; compute indicator; classify & map. Demo C : interactive Folium (choropleth + proportional symbols, tooltips, layer control). Demo D : interactive Plotly/Mapbox; export standalone HTML. 7) In\u2011class activity Start\u2011to\u2011finish pipeline: spatial join incidents \u2192 polygons, enrich with ACS denominator, build an interactive map with two layers, 3\u20135 sentence reflection on design choices + limitations. Download the Jupyter Notebook and Data \ud83d\udcbb Starter Code (snippets) # GeoPandas read + quick plot import geopandas as gpd polys = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres')) polys.to_crs(3857).plot(edgecolor='white') # Attribute join on a key import pandas as pd attrs = pd.read_csv('attrs.csv') # contains GEOID and a value joined = polys.merge(attrs, how='left', left_on='iso_a3', right_on='GEOID') # Choropleth (static) joined.plot(column='rate_per_10k', cmap='Blues', legend=True, edgecolor='0.7') # Plotly Express (interactive) import plotly.express as px import json geojson = json.loads(polys.to_json()) fig = px.choropleth(joined, geojson=geojson, locations=joined.index, color='rate_per_10k', featureidkey='properties.index') fig.update_geos(fitbounds='locations', visible=False) fig.show() # Spatial join (points \u2192 polygons) pts = gpd.read_file('points.geojson').to_crs(polys.crs) joined_pts = gpd.sjoin(pts, polys, predicate='within') counts = joined_pts.groupby('polygon_id').size().rename('count') result = polys.join(counts).fillna({'count':0}) \ud83e\uddea In\u2011Class Activities (both sessions) Work in pairs. Use provided notebook or your own dataset. Maintain a caption block for each map (CRS, data period, binning, source, denominator). \ud83c\udfe0 Homework (Due next Tuesday, Oct 28) Pick a geographic unit (country/state/county/tract) + a topic. Build a reproducible pipeline (notebook) that includes: One static choropleth with clear legend + caption. One interactive map (Folium or Plotly) with at least two layers (e.g., choropleth + points) and tooltips. At least one join (spatial or attribute) and appropriate normalization. A 150\u2013250 word reflection on design choices, denominators, classification, CRS, and limitations. Submit .ipynb and .html . Rubric (10 pts) Correct joins & CRS handling (3) Sound normalization + clear classification/legend (3) Interactive map quality (layers, tooltips, usability) (2) Reflection clarity & critique of limitations (2) \u2705 Submission Checklist Before submitting, make sure: Your assignment has fulfilled all the basic requirements listed above. Use Quarto to render the notebook into HTML and zip the files for submission. Double-check the visualizations and your reflections in the HTML are properly organized and displayed.","title":"Week 8 \u2014 Mapping I &amp; II"},{"location":"weekly/module_week_8_mapping_i_ii/#week-8-mapping-i-ii","text":"Foundations & Choropleths; Spatial Joins, Enrichment & Interactivity","title":"Week 8 \u2014 Mapping I &amp; II"},{"location":"weekly/module_week_8_mapping_i_ii/#background-motivation","text":"This two\u2011session module builds a solid foundation for geographic data visualization and then applies it to real analytical workflows. In Mapping I , students learn core geospatial concepts (data types, formats, and coordinate systems) and produce clear choropleth maps with appropriate normalization, classification, and legends. In Mapping II , students connect maps to real analysis tasks by performing spatial and attribute joins, enriching with socio\u2011economic context, and delivering interactive maps for exploration and communication.","title":"\ud83d\udcd6 Background &amp; Motivation"},{"location":"weekly/module_week_8_mapping_i_ii/#learning-objectives","text":"Distinguish vector vs. raster data; recognize common geospatial file formats (Shapefile, GeoJSON, TopoJSON, GeoPackage). Explain Coordinate Reference Systems (CRS) and projections; choose and document an appropriate CRS. Create choropleths with sensible normalization, classification, color, and legends. Perform spatial joins (point\u2011in\u2011polygon, polygon overlaps) and attribute joins on stable keys (e.g., FIPS/GEOID). Enrich maps with socio\u2011economic variables (e.g., ACS) and build interactive web maps.","title":"\ud83d\udd0e Learning Objectives"},{"location":"weekly/module_week_8_mapping_i_ii/#readings-resources","text":"GeoPandas User Guide \u2014 geopandas.org PyGIS \u2014 Intro to GIS in Python \u2014 pygis.io/docs/a_intro.html Folium Quickstart \u2014 python-visualization.github.io/folium Plotly Express Choropleth \u2014 plotly.com/python/choropleth-maps Claus Wilke , Fundamentals of Data Visualization (Geospatial) \u2014 clauswilke.com/dataviz/geospatial.html ColorBrewer 2.0 \u2014 colorbrewer2.org EPSG.io (CRS search) \u2014 epsg.io Census/ACS data portal \u2014 data.census.gov ; Social Explorer \u2014 socialexplorer.com/home TopoJSON docs \u2014 github.com/topojson/topojson","title":"\ud83d\udcda Readings &amp; Resources"},{"location":"weekly/module_week_8_mapping_i_ii/#setup","text":"Install/verify: pip install geopandas folium plotly mapclassify pyproj shapely pandas matplotlib Notes: If computing areas/lengths, reproject to an appropriate projected CRS (e.g., equal\u2011area). Interactive HTML maps (Folium/Plotly) load tiles/scripts at view time.","title":"\ud83d\udee0\ufe0f Setup"},{"location":"weekly/module_week_8_mapping_i_ii/#session-1-mapping-i-foundations-choropleths-75-min","text":"","title":"\ud83e\udded Session 1 \u2014 Mapping I: Foundations &amp; Choropleths (\u224875 min)"},{"location":"weekly/module_week_8_mapping_i_ii/#1-why-map-when-not-to-map","text":"Use maps when spatial structure matters (clusters, corridors, gradients). Prefer rates/ratios over raw counts; preview MAUP & ecological fallacy.","title":"1) Why map? When not to map"},{"location":"weekly/module_week_8_mapping_i_ii/#2-geographic-data-fundamentals","text":"Vector (points/lines/polygons/multiparts) vs Raster (continuous/categorical); resolution, extent.","title":"2) Geographic data fundamentals"},{"location":"weekly/module_week_8_mapping_i_ii/#3-file-formats","text":"Shapefile (.shp/.shx/.dbf/.prj) \u2013 common pitfalls: field name limits, encoding, missing .prj. GeoJSON (WGS84 lon/lat); TopoJSON (shared arcs, smaller web payloads); GeoPackage, Parquet+WKB.","title":"3) File formats"},{"location":"weekly/module_week_8_mapping_i_ii/#4-crs-projections","text":"Geographic vs Projected CRS; angular vs linear units. WGS84 (EPSG:4326) vs Web Mercator (EPSG:3857) vs Equal\u2011Area (e.g., ESRI:102003 for CONUS). Distortions (area/distance/direction); document CRS in captions.","title":"4) CRS &amp; projections"},{"location":"weekly/module_week_8_mapping_i_ii/#5-choropleths-principles","text":"Appropriate use: polygon\u2011level rates with clear denominators and time windows. Classification: Quantiles , Equal Interval , Natural Breaks (Jenks) , Std\u2011Dev; 4\u20137 bins. Color: sequential for ordered magnitudes; diverging for centered (\u00b1mean); avoid rainbow; accessible palettes. Legends & captions: variable name + units, bin method, CRS, data period, source.","title":"5) Choropleths: principles"},{"location":"weekly/module_week_8_mapping_i_ii/#6-demos-brief","text":"GeoPandas + Matplotlib : static choropleth; export PNG/SVG. Plotly Express : interactive choropleth with hover; export HTML. Folium : tile basemap, tooltips/popups, layer control; export HTML. Download the Jupyter Notebook and Data","title":"6) Demos (brief)"},{"location":"weekly/module_week_8_mapping_i_ii/#7-miniexercise-1015-min","text":"Given polygons + counts + population: make two choropleths (quantiles vs equal\u2011interval). Add a 3\u2011sentence note comparing how binning changes the story.","title":"7) Mini\u2011exercise (10\u201315 min)"},{"location":"weekly/module_week_8_mapping_i_ii/#session-2-mapping-ii-spatial-joins-enrichment-interactivity-75-min","text":"","title":"\ud83e\udded Session 2 \u2014 Mapping II: Spatial Joins, Enrichment &amp; Interactivity (\u224875 min)"},{"location":"weekly/module_week_8_mapping_i_ii/#1-spatial-joins","text":"Point\u2011in\u2011polygon (assign incidents/POIs to tracts), polygon\u2011to\u2011polygon (overlaps), nearest joins. GeoPandas sjoin predicates: within , contains , intersects ; geometry validity & CRS alignment.","title":"1) Spatial joins"},{"location":"weekly/module_week_8_mapping_i_ii/#2-attribute-joins-data-hygiene","text":"Join on stable keys (FIPS/GEOID). Handle types, leading zeros, whitespace, duplicates, missing keys.","title":"2) Attribute joins &amp; data hygiene"},{"location":"weekly/module_week_8_mapping_i_ii/#3-aggregation-normalization-and-stability","text":"Dissolve/aggregate to analysis geography; per\u2011capita / per\u2011household / per\u2011area rates. Consider rate stabilization (mention: Empirical Bayes) for small populations.","title":"3) Aggregation, normalization, and stability"},{"location":"weekly/module_week_8_mapping_i_ii/#4-socioeconomic-enrichment","text":"Typical sources: ACS (income, education, housing, commute), CDC PLACES , BLS . Temporal alignment and definitional consistency.","title":"4) Socio\u2011economic enrichment"},{"location":"weekly/module_week_8_mapping_i_ii/#5-interactive-mapping-patterns","text":"Layer toggles (choropleth + points), marker clustering, heatmaps (when appropriate). Filters (sliders/dropdowns), hover templates, annotations; geometry simplification & TopoJSON for performance.","title":"5) Interactive mapping patterns"},{"location":"weekly/module_week_8_mapping_i_ii/#6-demos-brief_1","text":"Demo A : spatial join (points\u2192polygons) \u2192 counts per polygon \u2192 normalized rate. Demo B : attribute join with ACS; compute indicator; classify & map. Demo C : interactive Folium (choropleth + proportional symbols, tooltips, layer control). Demo D : interactive Plotly/Mapbox; export standalone HTML.","title":"6) Demos (brief)"},{"location":"weekly/module_week_8_mapping_i_ii/#7-inclass-activity","text":"Start\u2011to\u2011finish pipeline: spatial join incidents \u2192 polygons, enrich with ACS denominator, build an interactive map with two layers, 3\u20135 sentence reflection on design choices + limitations. Download the Jupyter Notebook and Data","title":"7) In\u2011class activity"},{"location":"weekly/module_week_8_mapping_i_ii/#starter-code-snippets","text":"# GeoPandas read + quick plot import geopandas as gpd polys = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres')) polys.to_crs(3857).plot(edgecolor='white') # Attribute join on a key import pandas as pd attrs = pd.read_csv('attrs.csv') # contains GEOID and a value joined = polys.merge(attrs, how='left', left_on='iso_a3', right_on='GEOID') # Choropleth (static) joined.plot(column='rate_per_10k', cmap='Blues', legend=True, edgecolor='0.7') # Plotly Express (interactive) import plotly.express as px import json geojson = json.loads(polys.to_json()) fig = px.choropleth(joined, geojson=geojson, locations=joined.index, color='rate_per_10k', featureidkey='properties.index') fig.update_geos(fitbounds='locations', visible=False) fig.show() # Spatial join (points \u2192 polygons) pts = gpd.read_file('points.geojson').to_crs(polys.crs) joined_pts = gpd.sjoin(pts, polys, predicate='within') counts = joined_pts.groupby('polygon_id').size().rename('count') result = polys.join(counts).fillna({'count':0})","title":"\ud83d\udcbb Starter Code (snippets)"},{"location":"weekly/module_week_8_mapping_i_ii/#inclass-activities-both-sessions","text":"Work in pairs. Use provided notebook or your own dataset. Maintain a caption block for each map (CRS, data period, binning, source, denominator).","title":"\ud83e\uddea In\u2011Class Activities (both sessions)"},{"location":"weekly/module_week_8_mapping_i_ii/#homework-due-next-tuesday-oct-28","text":"Pick a geographic unit (country/state/county/tract) + a topic. Build a reproducible pipeline (notebook) that includes: One static choropleth with clear legend + caption. One interactive map (Folium or Plotly) with at least two layers (e.g., choropleth + points) and tooltips. At least one join (spatial or attribute) and appropriate normalization. A 150\u2013250 word reflection on design choices, denominators, classification, CRS, and limitations. Submit .ipynb and .html . Rubric (10 pts) Correct joins & CRS handling (3) Sound normalization + clear classification/legend (3) Interactive map quality (layers, tooltips, usability) (2) Reflection clarity & critique of limitations (2)","title":"\ud83c\udfe0 Homework (Due next Tuesday, Oct 28)"},{"location":"weekly/module_week_8_mapping_i_ii/#submission-checklist","text":"Before submitting, make sure: Your assignment has fulfilled all the basic requirements listed above. Use Quarto to render the notebook into HTML and zip the files for submission. Double-check the visualizations and your reflections in the HTML are properly organized and displayed.","title":"\u2705 Submission Checklist"},{"location":"weekly/module_week_9_color_accessibility/","text":"Week 9 \u2014 Color & Accessibility Understanding color theory, palette selection, and accessibility best practices in data visualization. \ud83d\udcd6 Background & Motivation Color is one of the most powerful and expressive tools in visualization. It can highlight differences, show magnitude, encode categories, or evoke emotion\u2014but it can also distort, confuse, or exclude if not used carefully. This module explores color theory, perceptual uniformity, and accessibility guidelines to ensure your visuals communicate effectively to all audiences. We will discuss the use of color in sequential, diverging, and categorical scales, and how to design visualizations that remain interpretable for viewers with color vision deficiencies. \ud83d\udd0e Learning Objectives Distinguish between sequential , diverging , and categorical color schemes. Select appropriate palettes based on data type and context. Apply color theory concepts (hue, saturation, luminance) to improve legibility. Use color tools to ensure accessibility for all users. Test visualizations for color blindness and accessibility compliance. \ud83d\udcda Readings & Resources Fundamentals of Data Visualization \u2014 chapters on color and perception. ColorBrewer2 \u2014 tool for choosing effective color schemes. Colorcet - Perceptually accurate 256-color colormaps Adobe Color \u2014 create custom palettes. Coblis \u2014 Color Blindness Simulator Accessible Data Visualization Guide (W3C) Seaborn color palettes documentation Sample Data Sources: Gapminder dataset (for categorical and quantitative mapping) U.S. demographic data (for diverging and sequential maps) Simulated survey data (for categorical comparison) \ud83d\udee0\ufe0f Setup Checklist Ensure your environment includes: pip install seaborn matplotlib colorcet pandas Confirm you can load sample datasets and apply color palettes using Seaborn and Matplotlib. \ud83e\udded Lecture Outline Session 1 (Theory + Hands-on) Introduction: Why color matters in visualization Color theory basics \u2014 hue, saturation, brightness Types of color schemes \u2014 sequential, diverging, categorical Color perception & accessibility \u2014 common pitfalls Experiment with Seaborn and Matplotlib color palettes Apply ColorBrewer and Colorcet palettes to the previous week\u2019s map visualizations Download the Jupyter Notebook and Data \ud83d\udcbb Starter Notebook Snippets Using Seaborn palettes import seaborn as sns import matplotlib.pyplot as plt # Sequential palette sns.palplot(sns.color_palette(\"Blues\", 8)) plt.title(\"Sequential palette example\") # Diverging palette sns.palplot(sns.diverging_palette(220, 20, n=8)) plt.title(\"Diverging palette example\") # Categorical palette sns.palplot(sns.color_palette(\"Set2\", 8)) plt.title(\"Categorical palette example\") plt.show() Applying color palettes to a chart penguins = sns.load_dataset(\"penguins\").dropna() sns.scatterplot(data=penguins, x=\"flipper_length_mm\", y=\"body_mass_g\", hue=\"species\", palette=\"Set2\") plt.title(\"Categorical color palette example\") plt.show() Testing color palettes for accessibility # Example: simulate grayscale or color blindness import matplotlib.colors as mcolors import numpy as np # Convert to grayscale to check luminance contrast img = np.linspace(0, 1, 256).reshape(1, -1) plt.imshow(img, cmap=\"viridis\", aspect=\"auto\") plt.title(\"Luminance contrast check (Viridis)\") plt.axis('off') plt.show() \ud83e\uddea In-Class Activity Create 3 mini visualizations (one sequential, one diverging, one categorical) using Seaborn. Use ColorBrewer to test and adjust color schemes. Simulate color blindness and discuss readability. Redesign a prior week\u2019s map or chart with improved accessibility. \ud83c\udfe0 Homework (Due next Monday, Nov 3) Choose one of your visualizations from a previous week and redesign it to improve color and accessibility. Include: One before-and-after comparison of color schemes. Discussion (150\u2013250 words) of how your new design improves clarity and inclusivity. Verification of color accessibility (using simulator or contrast tool). Submit .ipynb and .html . Rubric (10 pts) Appropriate use of color schemes (3) Accessibility testing and discussion (3) Clarity and improvement of redesigned visual (2) Reproducibility and documentation (2) \ud83e\udde9 Optional Extensions Explore colorcet for perceptually uniform colormaps. Create a color legend that works both in grayscale and color. Compare the performance of different palettes in color\u2011blind simulation. \u2705 Submission Checklist Before submitting, make sure: Your assignment has fulfilled all the basic requirements listed above. Use Quarto to render the notebook into HTML and zip the files for submission. Double-check the visualizations and your reflections in the HTML are properly organized and displayed.","title":"Week 9 \u2014 Color &amp; Accessibility"},{"location":"weekly/module_week_9_color_accessibility/#week-9-color-accessibility","text":"Understanding color theory, palette selection, and accessibility best practices in data visualization.","title":"Week 9 \u2014 Color &amp; Accessibility"},{"location":"weekly/module_week_9_color_accessibility/#background-motivation","text":"Color is one of the most powerful and expressive tools in visualization. It can highlight differences, show magnitude, encode categories, or evoke emotion\u2014but it can also distort, confuse, or exclude if not used carefully. This module explores color theory, perceptual uniformity, and accessibility guidelines to ensure your visuals communicate effectively to all audiences. We will discuss the use of color in sequential, diverging, and categorical scales, and how to design visualizations that remain interpretable for viewers with color vision deficiencies.","title":"\ud83d\udcd6 Background &amp; Motivation"},{"location":"weekly/module_week_9_color_accessibility/#learning-objectives","text":"Distinguish between sequential , diverging , and categorical color schemes. Select appropriate palettes based on data type and context. Apply color theory concepts (hue, saturation, luminance) to improve legibility. Use color tools to ensure accessibility for all users. Test visualizations for color blindness and accessibility compliance.","title":"\ud83d\udd0e Learning Objectives"},{"location":"weekly/module_week_9_color_accessibility/#readings-resources","text":"Fundamentals of Data Visualization \u2014 chapters on color and perception. ColorBrewer2 \u2014 tool for choosing effective color schemes. Colorcet - Perceptually accurate 256-color colormaps Adobe Color \u2014 create custom palettes. Coblis \u2014 Color Blindness Simulator Accessible Data Visualization Guide (W3C) Seaborn color palettes documentation Sample Data Sources: Gapminder dataset (for categorical and quantitative mapping) U.S. demographic data (for diverging and sequential maps) Simulated survey data (for categorical comparison)","title":"\ud83d\udcda Readings &amp; Resources"},{"location":"weekly/module_week_9_color_accessibility/#setup-checklist","text":"Ensure your environment includes: pip install seaborn matplotlib colorcet pandas Confirm you can load sample datasets and apply color palettes using Seaborn and Matplotlib.","title":"\ud83d\udee0\ufe0f Setup Checklist"},{"location":"weekly/module_week_9_color_accessibility/#lecture-outline","text":"","title":"\ud83e\udded Lecture Outline"},{"location":"weekly/module_week_9_color_accessibility/#session-1-theory-hands-on","text":"Introduction: Why color matters in visualization Color theory basics \u2014 hue, saturation, brightness Types of color schemes \u2014 sequential, diverging, categorical Color perception & accessibility \u2014 common pitfalls Experiment with Seaborn and Matplotlib color palettes Apply ColorBrewer and Colorcet palettes to the previous week\u2019s map visualizations Download the Jupyter Notebook and Data","title":"Session 1 (Theory + Hands-on)"},{"location":"weekly/module_week_9_color_accessibility/#starter-notebook-snippets","text":"","title":"\ud83d\udcbb Starter Notebook Snippets"},{"location":"weekly/module_week_9_color_accessibility/#using-seaborn-palettes","text":"import seaborn as sns import matplotlib.pyplot as plt # Sequential palette sns.palplot(sns.color_palette(\"Blues\", 8)) plt.title(\"Sequential palette example\") # Diverging palette sns.palplot(sns.diverging_palette(220, 20, n=8)) plt.title(\"Diverging palette example\") # Categorical palette sns.palplot(sns.color_palette(\"Set2\", 8)) plt.title(\"Categorical palette example\") plt.show()","title":"Using Seaborn palettes"},{"location":"weekly/module_week_9_color_accessibility/#applying-color-palettes-to-a-chart","text":"penguins = sns.load_dataset(\"penguins\").dropna() sns.scatterplot(data=penguins, x=\"flipper_length_mm\", y=\"body_mass_g\", hue=\"species\", palette=\"Set2\") plt.title(\"Categorical color palette example\") plt.show()","title":"Applying color palettes to a chart"},{"location":"weekly/module_week_9_color_accessibility/#testing-color-palettes-for-accessibility","text":"# Example: simulate grayscale or color blindness import matplotlib.colors as mcolors import numpy as np # Convert to grayscale to check luminance contrast img = np.linspace(0, 1, 256).reshape(1, -1) plt.imshow(img, cmap=\"viridis\", aspect=\"auto\") plt.title(\"Luminance contrast check (Viridis)\") plt.axis('off') plt.show()","title":"Testing color palettes for accessibility"},{"location":"weekly/module_week_9_color_accessibility/#in-class-activity","text":"Create 3 mini visualizations (one sequential, one diverging, one categorical) using Seaborn. Use ColorBrewer to test and adjust color schemes. Simulate color blindness and discuss readability. Redesign a prior week\u2019s map or chart with improved accessibility.","title":"\ud83e\uddea In-Class Activity"},{"location":"weekly/module_week_9_color_accessibility/#homework-due-next-monday-nov-3","text":"Choose one of your visualizations from a previous week and redesign it to improve color and accessibility. Include: One before-and-after comparison of color schemes. Discussion (150\u2013250 words) of how your new design improves clarity and inclusivity. Verification of color accessibility (using simulator or contrast tool). Submit .ipynb and .html . Rubric (10 pts) Appropriate use of color schemes (3) Accessibility testing and discussion (3) Clarity and improvement of redesigned visual (2) Reproducibility and documentation (2)","title":"\ud83c\udfe0 Homework (Due next Monday, Nov 3)"},{"location":"weekly/module_week_9_color_accessibility/#optional-extensions","text":"Explore colorcet for perceptually uniform colormaps. Create a color legend that works both in grayscale and color. Compare the performance of different palettes in color\u2011blind simulation.","title":"\ud83e\udde9 Optional Extensions"},{"location":"weekly/module_week_9_color_accessibility/#submission-checklist","text":"Before submitting, make sure: Your assignment has fulfilled all the basic requirements listed above. Use Quarto to render the notebook into HTML and zip the files for submission. Double-check the visualizations and your reflections in the HTML are properly organized and displayed.","title":"\u2705 Submission Checklist"},{"location":"weekly/week4/file_list/","text":"Week 4 file list A collection of files included in this lecture: Data Files nyc_taxi_sample.csv \u2013 Sample dataset of NYC taxi trips. taxi_zones.csv \u2013 New York taxi zones lookup table. covid_daily.csv ` \u2013 COVID-19 case counts dataset. Notebook week04_wrangle.ipynb \u2013 Starter Jupyter Notebook.","title":"Week 4 file list"},{"location":"weekly/week4/file_list/#week-4-file-list","text":"A collection of files included in this lecture:","title":"Week 4 file list"},{"location":"weekly/week4/file_list/#data-files","text":"nyc_taxi_sample.csv \u2013 Sample dataset of NYC taxi trips. taxi_zones.csv \u2013 New York taxi zones lookup table. covid_daily.csv ` \u2013 COVID-19 case counts dataset.","title":"Data Files"},{"location":"weekly/week4/file_list/#notebook","text":"week04_wrangle.ipynb \u2013 Starter Jupyter Notebook.","title":"Notebook"},{"location":"weekly/week6/file_list/","text":"File list for Week 6 chart demo with Jupyter Notebook A collection of files included in this lecture: Data Files gapminder_subset.csv \u2013 Synthesized sample data for working with Gapminder dataset. counts_population.csv \u2013 Synthesized population data. Notebook Week06_Comparisons_session1.ipynb \u2013 Jupyter Notebook for illustrating the visuals in the lectures charts_demo.ipynb \u2013 Jupyter Notebook for demos in the \"Chart cheat sheet\" slide","title":"File list for Week 6 chart demo with Jupyter Notebook"},{"location":"weekly/week6/file_list/#file-list-for-week-6-chart-demo-with-jupyter-notebook","text":"A collection of files included in this lecture:","title":"File list for Week 6 chart demo with Jupyter Notebook"},{"location":"weekly/week6/file_list/#data-files","text":"gapminder_subset.csv \u2013 Synthesized sample data for working with Gapminder dataset. counts_population.csv \u2013 Synthesized population data.","title":"Data Files"},{"location":"weekly/week6/file_list/#notebook","text":"Week06_Comparisons_session1.ipynb \u2013 Jupyter Notebook for illustrating the visuals in the lectures charts_demo.ipynb \u2013 Jupyter Notebook for demos in the \"Chart cheat sheet\" slide","title":"Notebook"}]}